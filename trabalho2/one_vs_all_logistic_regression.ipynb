{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gzip\n",
    "import os\n",
    "import copy\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #for training on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fashion_mnist.utils.mnist_reader import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_image, total_train_labels = load_mnist('./fashion_mnist/data/fashion/', kind='train')\n",
    "test_image, test_labels = load_mnist('./fashion_mnist/data/fashion/', kind='t10k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image, validation_image = train_test_split(total_train_image, test_size=0.15, random_state=0)\n",
    "train_labels, validation_labels = train_test_split(total_train_labels, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_image = np.reshape(train_image,(-1, 28, 28, 1)).astype('float32')\n",
    "#test_image = np.reshape(test_image,(-1, 28, 28, 1)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_onehot = pd.get_dummies(train_labels)\n",
    "validation_labels_onehot = pd.get_dummies(validation_labels)\n",
    "test_labels_onehot = pd.get_dummies(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function(z):\n",
    "    return 1 / (1 + tf.exp(-z))\n",
    "\n",
    "def loss_function(y, h):\n",
    "    return tf.reduce_mean((-y * tf.log(h) - (1 - y) * tf.log(1 - h)))\n",
    "\n",
    "def gradient_update(gradient,h):\n",
    "    return gradient.assign(tf.tensordot(tf.transpose(X), tf.subtract(h, y),1)/batch)\n",
    "\n",
    "def theta_update(theta, gradient):\n",
    "    return theta.assign(theta - lr * gradient)\n",
    "\n",
    "def pred_y(X,theta):\n",
    "    return tf.tensordot(X,theta, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "batch = train_image.shape[0]\n",
    "epochs = 100\n",
    "iterations = int(train_image.shape[0]/batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f34a083c7b8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_image[4].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape =([None,28*28]))\n",
    "y = tf.placeholder(tf.float32, shape =([None, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = tf.get_variable(\"theta0\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "theta1 = tf.get_variable(\"theta1\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "theta2 = tf.get_variable(\"theta2\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "theta3 = tf.get_variable(\"theta3\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "theta4 = tf.get_variable(\"theta4\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "theta5 = tf.get_variable(\"theta5\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "theta6 = tf.get_variable(\"theta6\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "theta7 = tf.get_variable(\"theta7\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "theta8 = tf.get_variable(\"theta8\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "theta9 = tf.get_variable(\"theta9\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient0 = tf.get_variable(\"gradient0\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "gradient1 = tf.get_variable(\"gradient1\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "gradient2 = tf.get_variable(\"gradient2\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "gradient3 = tf.get_variable(\"gradient3\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "gradient4 = tf.get_variable(\"gradient4\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "gradient5 = tf.get_variable(\"gradient5\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "gradient6 = tf.get_variable(\"gradient6\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "gradient7 = tf.get_variable(\"gradient7\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "gradient8 = tf.get_variable(\"gradient8\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "gradient9 = tf.get_variable(\"gradient9\", shape=(28*28,1), dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "z0 = pred_y(X,theta0)\n",
    "z1 = pred_y(X,theta1)\n",
    "z2 = pred_y(X,theta2)\n",
    "z3 = pred_y(X,theta3)\n",
    "z4 = pred_y(X,theta4)\n",
    "z5 = pred_y(X,theta5)\n",
    "z6 = pred_y(X,theta6)\n",
    "z7 = pred_y(X,theta7)\n",
    "z8 = pred_y(X,theta8)\n",
    "z9 = pred_y(X,theta9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = sigmoid_function(z0)\n",
    "h1 = sigmoid_function(z1)\n",
    "h2 = sigmoid_function(z2)\n",
    "h3 = sigmoid_function(z3)\n",
    "h4 = sigmoid_function(z4)\n",
    "h5 = sigmoid_function(z5)\n",
    "h6 = sigmoid_function(z6)\n",
    "h7 = sigmoid_function(z7)\n",
    "h8 = sigmoid_function(z8)\n",
    "h9 = sigmoid_function(z9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0_update = theta_update(theta0,gradient0)\n",
    "theta1_update = theta_update(theta0,gradient0)\n",
    "theta2_update = theta_update(theta0,gradient0)\n",
    "theta3_update = theta_update(theta0,gradient0)\n",
    "theta4_update = theta_update(theta0,gradient0)\n",
    "theta5_update = theta_update(theta0,gradient0)\n",
    "theta6_update = theta_update(theta0,gradient0)\n",
    "theta7_update = theta_update(theta0,gradient0)\n",
    "theta8_update = theta_update(theta0,gradient0)\n",
    "theta9_update = theta_update(theta0,gradient0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss0 = loss_function(y,h0)\n",
    "loss1 = loss_function(y,h0)\n",
    "loss2 = loss_function(y,h0)\n",
    "loss3 = loss_function(y,h0)\n",
    "loss4 = loss_function(y,h0)\n",
    "loss5 = loss_function(y,h0)\n",
    "loss6 = loss_function(y,h0)\n",
    "loss7 = loss_function(y,h0)\n",
    "loss8 = loss_function(y,h0)\n",
    "loss9 = loss_function(y,h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_X = tf.placeholder(tf.float32)\n",
    "tf_X_norm = tf.image.per_image_standardization(tf_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "train_image_norm = sess.run(tf_X_norm, feed_dict={tf_X: train_image})\n",
    "validation_image_norm = sess.run(tf_X_norm, feed_dict={tf_X: validation_image})\n",
    "test_image_norm = sess.run(tf_X_norm, feed_dict={tf_X: test_image})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.16268937]\n",
      " [0.32992256]\n",
      " [0.5562899 ]\n",
      " [0.03224988]]\n",
      "Train loss 0.5937\n",
      "Validation loss 0.5871\n",
      "Epoch 1\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.14686091]\n",
      " [0.26656437]\n",
      " [0.42878932]\n",
      " [0.03141721]]\n",
      "Train loss 0.5161\n",
      "Validation loss 0.5104\n",
      "Epoch 2\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.13616006]\n",
      " [0.22431943]\n",
      " [0.33585337]\n",
      " [0.03174287]]\n",
      "Train loss 0.4631\n",
      "Validation loss 0.4579\n",
      "Epoch 3\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.12831832]\n",
      " [0.19423619]\n",
      " [0.26909918]\n",
      " [0.03245232]]\n",
      "Train loss 0.4240\n",
      "Validation loss 0.4192\n",
      "Epoch 4\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.12210296]\n",
      " [0.17143805]\n",
      " [0.22026043]\n",
      " [0.03312087]]\n",
      "Train loss 0.3935\n",
      "Validation loss 0.3890\n",
      "Epoch 5\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.11683819]\n",
      " [0.15328084]\n",
      " [0.18358237]\n",
      " [0.03350969]]\n",
      "Train loss 0.3689\n",
      "Validation loss 0.3646\n",
      "Epoch 6\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.11215223]\n",
      " [0.13828033]\n",
      " [0.15533659]\n",
      " [0.03350258]]\n",
      "Train loss 0.3484\n",
      "Validation loss 0.3443\n",
      "Epoch 7\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.10784425]\n",
      " [0.12556647]\n",
      " [0.1331095 ]\n",
      " [0.03307243]]\n",
      "Train loss 0.3310\n",
      "Validation loss 0.3270\n",
      "Epoch 8\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.10381082]\n",
      " [0.1146035 ]\n",
      " [0.11530238]\n",
      " [0.03225408]]\n",
      "Train loss 0.3160\n",
      "Validation loss 0.3122\n",
      "Epoch 9\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.1000028 ]\n",
      " [0.10504265]\n",
      " [0.10082405]\n",
      " [0.03111877]]\n",
      "Train loss 0.3030\n",
      "Validation loss 0.2993\n",
      "Epoch 10\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0963992 ]\n",
      " [0.09664157]\n",
      " [0.08890585]\n",
      " [0.0297521 ]]\n",
      "Train loss 0.2915\n",
      "Validation loss 0.2879\n",
      "Epoch 11\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0929921 ]\n",
      " [0.08922087]\n",
      " [0.07899104]\n",
      " [0.02823803]]\n",
      "Train loss 0.2814\n",
      "Validation loss 0.2778\n",
      "Epoch 12\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.08977794]\n",
      " [0.08264019]\n",
      " [0.07066613]\n",
      " [0.02664958]]\n",
      "Train loss 0.2723\n",
      "Validation loss 0.2687\n",
      "Epoch 13\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.08675338]\n",
      " [0.07678495]\n",
      " [0.06361788]\n",
      " [0.02504476]]\n",
      "Train loss 0.2641\n",
      "Validation loss 0.2606\n",
      "Epoch 14\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.08391346]\n",
      " [0.07155905]\n",
      " [0.05760503]\n",
      " [0.0234663 ]]\n",
      "Train loss 0.2567\n",
      "Validation loss 0.2532\n",
      "Epoch 15\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.08125149]\n",
      " [0.06688081]\n",
      " [0.05243937]\n",
      " [0.02194354]]\n",
      "Train loss 0.2500\n",
      "Validation loss 0.2465\n",
      "Epoch 16\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0787591 ]\n",
      " [0.06268018]\n",
      " [0.04797236]\n",
      " [0.02049503]]\n",
      "Train loss 0.2438\n",
      "Validation loss 0.2404\n",
      "Epoch 17\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.07642684]\n",
      " [0.05889693]\n",
      " [0.04408581]\n",
      " [0.0191311 ]]\n",
      "Train loss 0.2382\n",
      "Validation loss 0.2348\n",
      "Epoch 18\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0742446 ]\n",
      " [0.05547926]\n",
      " [0.04068475]\n",
      " [0.01785615]]\n",
      "Train loss 0.2330\n",
      "Validation loss 0.2297\n",
      "Epoch 19\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0722022 ]\n",
      " [0.05238242]\n",
      " [0.03769242]\n",
      " [0.01667058]]\n",
      "Train loss 0.2283\n",
      "Validation loss 0.2249\n",
      "Epoch 20\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.07028954]\n",
      " [0.04956795]\n",
      " [0.03504629]\n",
      " [0.01557211]]\n",
      "Train loss 0.2239\n",
      "Validation loss 0.2205\n",
      "Epoch 21\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.06849693]\n",
      " [0.0470026 ]\n",
      " [0.03269508]\n",
      " [0.01455677]]\n",
      "Train loss 0.2198\n",
      "Validation loss 0.2165\n",
      "Epoch 22\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.06681515]\n",
      " [0.04465774]\n",
      " [0.03059656]\n",
      " [0.01361973]]\n",
      "Train loss 0.2160\n",
      "Validation loss 0.2127\n",
      "Epoch 23\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.06523561]\n",
      " [0.04250848]\n",
      " [0.02871559]\n",
      " [0.01275566]]\n",
      "Train loss 0.2125\n",
      "Validation loss 0.2092\n",
      "Epoch 24\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.06375035]\n",
      " [0.04053334]\n",
      " [0.02702293]\n",
      " [0.01195915]]\n",
      "Train loss 0.2092\n",
      "Validation loss 0.2059\n",
      "Epoch 25\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.06235192]\n",
      " [0.03871361]\n",
      " [0.02549398]\n",
      " [0.01122486]]\n",
      "Train loss 0.2061\n",
      "Validation loss 0.2028\n",
      "Epoch 26\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.06103359]\n",
      " [0.037033  ]\n",
      " [0.02410807]\n",
      " [0.01054769]]\n",
      "Train loss 0.2032\n",
      "Validation loss 0.1999\n",
      "Epoch 27\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.05978915]\n",
      " [0.03547728]\n",
      " [0.02284761]\n",
      " [0.00992282]]\n",
      "Train loss 0.2005\n",
      "Validation loss 0.1972\n",
      "Epoch 28\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.05861295]\n",
      " [0.034034  ]\n",
      " [0.02169764]\n",
      " [0.0093458 ]]\n",
      "Train loss 0.1979\n",
      "Validation loss 0.1946\n",
      "Epoch 29\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.05749976]\n",
      " [0.0326922 ]\n",
      " [0.02064535]\n",
      " [0.00881248]]\n",
      "Train loss 0.1955\n",
      "Validation loss 0.1922\n",
      "Epoch 30\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.05644486]\n",
      " [0.03144225]\n",
      " [0.01967976]\n",
      " [0.00831909]]\n",
      "Train loss 0.1932\n",
      "Validation loss 0.1899\n",
      "Epoch 31\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.05544395]\n",
      " [0.03027563]\n",
      " [0.01879137]\n",
      " [0.00786215]]\n",
      "Train loss 0.1911\n",
      "Validation loss 0.1878\n",
      "Epoch 32\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.05449309]\n",
      " [0.02918482]\n",
      " [0.01797195]\n",
      " [0.00743853]]\n",
      "Train loss 0.1890\n",
      "Validation loss 0.1857\n",
      "Epoch 33\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.05358866]\n",
      " [0.0281631 ]\n",
      " [0.01721433]\n",
      " [0.00704535]]\n",
      "Train loss 0.1871\n",
      "Validation loss 0.1838\n",
      "Epoch 34\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.05272737]\n",
      " [0.02720453]\n",
      " [0.01651228]\n",
      " [0.00668002]]\n",
      "Train loss 0.1853\n",
      "Validation loss 0.1820\n",
      "Epoch 35\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.05190628]\n",
      " [0.02630376]\n",
      " [0.01586034]\n",
      " [0.00634017]]\n",
      "Train loss 0.1835\n",
      "Validation loss 0.1802\n",
      "Epoch 36\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.05112253]\n",
      " [0.02545607]\n",
      " [0.01525368]\n",
      " [0.00602369]]\n",
      "Train loss 0.1819\n",
      "Validation loss 0.1786\n",
      "Epoch 37\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0503737 ]\n",
      " [0.02465716]\n",
      " [0.01468806]\n",
      " [0.00572862]]\n",
      "Train loss 0.1803\n",
      "Validation loss 0.1770\n",
      "Epoch 38\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04965741]\n",
      " [0.02390318]\n",
      " [0.01415971]\n",
      " [0.00545321]]\n",
      "Train loss 0.1788\n",
      "Validation loss 0.1755\n",
      "Epoch 39\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04897157]\n",
      " [0.02319069]\n",
      " [0.01366534]\n",
      " [0.00519587]]\n",
      "Train loss 0.1774\n",
      "Validation loss 0.1740\n",
      "Epoch 40\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04831418]\n",
      " [0.02251654]\n",
      " [0.01320196]\n",
      " [0.00495514]]\n",
      "Train loss 0.1760\n",
      "Validation loss 0.1727\n",
      "Epoch 41\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04768351]\n",
      " [0.02187792]\n",
      " [0.01276694]\n",
      " [0.00472972]]\n",
      "Train loss 0.1747\n",
      "Validation loss 0.1713\n",
      "Epoch 42\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04707783]\n",
      " [0.02127224]\n",
      " [0.01235792]\n",
      " [0.00451841]]\n",
      "Train loss 0.1734\n",
      "Validation loss 0.1701\n",
      "Epoch 43\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04649569]\n",
      " [0.02069717]\n",
      " [0.01197276]\n",
      " [0.00432012]]\n",
      "Train loss 0.1722\n",
      "Validation loss 0.1689\n",
      "Epoch 44\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04593559]\n",
      " [0.02015059]\n",
      " [0.01160958]\n",
      " [0.00413387]]\n",
      "Train loss 0.1711\n",
      "Validation loss 0.1677\n",
      "Epoch 45\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04539631]\n",
      " [0.01963055]\n",
      " [0.01126666]\n",
      " [0.00395875]]\n",
      "Train loss 0.1700\n",
      "Validation loss 0.1666\n",
      "Epoch 46\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04487658]\n",
      " [0.01913528]\n",
      " [0.01094245]\n",
      " [0.00379393]]\n",
      "Train loss 0.1689\n",
      "Validation loss 0.1655\n",
      "Epoch 47\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04437533]\n",
      " [0.01866318]\n",
      " [0.01063554]\n",
      " [0.00363867]]\n",
      "Train loss 0.1679\n",
      "Validation loss 0.1645\n",
      "Epoch 48\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04389146]\n",
      " [0.01821272]\n",
      " [0.01034466]\n",
      " [0.00349228]]\n",
      "Train loss 0.1669\n",
      "Validation loss 0.1635\n",
      "Epoch 49\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04342407]\n",
      " [0.01778254]\n",
      " [0.01006868]\n",
      " [0.00335412]]\n",
      "Train loss 0.1659\n",
      "Validation loss 0.1626\n",
      "Epoch 50\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04297222]\n",
      " [0.0173714 ]\n",
      " [0.00980653]\n",
      " [0.00322362]]\n",
      "Train loss 0.1650\n",
      "Validation loss 0.1616\n",
      "Epoch 51\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04253509]\n",
      " [0.01697814]\n",
      " [0.00955726]\n",
      " [0.00310025]]\n",
      "Train loss 0.1641\n",
      "Validation loss 0.1607\n",
      "Epoch 52\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04211187]\n",
      " [0.01660166]\n",
      " [0.00931998]\n",
      " [0.00298353]]\n",
      "Train loss 0.1633\n",
      "Validation loss 0.1599\n",
      "Epoch 53\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04170189]\n",
      " [0.016241  ]\n",
      " [0.00909392]\n",
      " [0.00287299]]\n",
      "Train loss 0.1625\n",
      "Validation loss 0.1591\n",
      "Epoch 54\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04130444]\n",
      " [0.01589525]\n",
      " [0.00887833]\n",
      " [0.00276824]]\n",
      "Train loss 0.1617\n",
      "Validation loss 0.1583\n",
      "Epoch 55\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04091889]\n",
      " [0.01556352]\n",
      " [0.00867254]\n",
      " [0.0026689 ]]\n",
      "Train loss 0.1609\n",
      "Validation loss 0.1575\n",
      "Epoch 56\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04054466]\n",
      " [0.01524506]\n",
      " [0.00847593]\n",
      " [0.0025746 ]]\n",
      "Train loss 0.1602\n",
      "Validation loss 0.1567\n",
      "Epoch 57\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.04018118]\n",
      " [0.01493913]\n",
      " [0.00828793]\n",
      " [0.00248504]]\n",
      "Train loss 0.1595\n",
      "Validation loss 0.1560\n",
      "Epoch 58\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03982794]\n",
      " [0.01464505]\n",
      " [0.00810802]\n",
      " [0.00239991]]\n",
      "Train loss 0.1588\n",
      "Validation loss 0.1553\n",
      "Epoch 59\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03948445]\n",
      " [0.01436219]\n",
      " [0.00793571]\n",
      " [0.00231894]]\n",
      "Train loss 0.1581\n",
      "Validation loss 0.1546\n",
      "Epoch 60\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03915025]\n",
      " [0.01408995]\n",
      " [0.00777056]\n",
      " [0.00224187]]\n",
      "Train loss 0.1574\n",
      "Validation loss 0.1540\n",
      "Epoch 61\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03882494]\n",
      " [0.01382779]\n",
      " [0.00761215]\n",
      " [0.00216846]]\n",
      "Train loss 0.1568\n",
      "Validation loss 0.1533\n",
      "Epoch 62\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03850807]\n",
      " [0.01357518]\n",
      " [0.0074601 ]\n",
      " [0.00209849]]\n",
      "Train loss 0.1562\n",
      "Validation loss 0.1527\n",
      "Epoch 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03819927]\n",
      " [0.01333166]\n",
      " [0.00731405]\n",
      " [0.00203177]]\n",
      "Train loss 0.1556\n",
      "Validation loss 0.1521\n",
      "Epoch 64\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03789823]\n",
      " [0.01309676]\n",
      " [0.00717367]\n",
      " [0.0019681 ]]\n",
      "Train loss 0.1550\n",
      "Validation loss 0.1515\n",
      "Epoch 65\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03760456]\n",
      " [0.01287006]\n",
      " [0.00703866]\n",
      " [0.0019073 ]]\n",
      "Train loss 0.1545\n",
      "Validation loss 0.1510\n",
      "Epoch 66\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03731797]\n",
      " [0.01265117]\n",
      " [0.00690871]\n",
      " [0.00184921]]\n",
      "Train loss 0.1539\n",
      "Validation loss 0.1504\n",
      "Epoch 67\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03703815]\n",
      " [0.01243973]\n",
      " [0.00678358]\n",
      " [0.00179367]]\n",
      "Train loss 0.1534\n",
      "Validation loss 0.1499\n",
      "Epoch 68\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0367648 ]\n",
      " [0.01223538]\n",
      " [0.006663  ]\n",
      " [0.00174055]]\n",
      "Train loss 0.1529\n",
      "Validation loss 0.1494\n",
      "Epoch 69\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0364977 ]\n",
      " [0.01203778]\n",
      " [0.00654675]\n",
      " [0.00168972]]\n",
      "Train loss 0.1524\n",
      "Validation loss 0.1489\n",
      "Epoch 70\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03623657]\n",
      " [0.01184665]\n",
      " [0.00643461]\n",
      " [0.00164104]]\n",
      "Train loss 0.1519\n",
      "Validation loss 0.1484\n",
      "Epoch 71\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03598116]\n",
      " [0.01166167]\n",
      " [0.00632637]\n",
      " [0.0015944 ]]\n",
      "Train loss 0.1514\n",
      "Validation loss 0.1479\n",
      "Epoch 72\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03573124]\n",
      " [0.01148258]\n",
      " [0.00622185]\n",
      " [0.00154969]]\n",
      "Train loss 0.1510\n",
      "Validation loss 0.1474\n",
      "Epoch 73\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03548664]\n",
      " [0.01130911]\n",
      " [0.00612085]\n",
      " [0.00150681]]\n",
      "Train loss 0.1505\n",
      "Validation loss 0.1470\n",
      "Epoch 74\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03524711]\n",
      " [0.01114103]\n",
      " [0.00602322]\n",
      " [0.00146567]]\n",
      "Train loss 0.1501\n",
      "Validation loss 0.1465\n",
      "Epoch 75\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03501247]\n",
      " [0.01097812]\n",
      " [0.00592881]\n",
      " [0.00142618]]\n",
      "Train loss 0.1497\n",
      "Validation loss 0.1461\n",
      "Epoch 76\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03478255]\n",
      " [0.01082012]\n",
      " [0.00583745]\n",
      " [0.00138824]]\n",
      "Train loss 0.1493\n",
      "Validation loss 0.1457\n",
      "Epoch 77\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03455717]\n",
      " [0.01066687]\n",
      " [0.00574901]\n",
      " [0.00135179]]\n",
      "Train loss 0.1489\n",
      "Validation loss 0.1453\n",
      "Epoch 78\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03433615]\n",
      " [0.01051814]\n",
      " [0.00566336]\n",
      " [0.00131675]]\n",
      "Train loss 0.1485\n",
      "Validation loss 0.1449\n",
      "Epoch 79\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03411935]\n",
      " [0.01037376]\n",
      " [0.00558036]\n",
      " [0.00128305]]\n",
      "Train loss 0.1481\n",
      "Validation loss 0.1445\n",
      "Epoch 80\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03390662]\n",
      " [0.01023356]\n",
      " [0.00549992]\n",
      " [0.00125062]]\n",
      "Train loss 0.1477\n",
      "Validation loss 0.1441\n",
      "Epoch 81\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03369781]\n",
      " [0.01009735]\n",
      " [0.00542192]\n",
      " [0.0012194 ]]\n",
      "Train loss 0.1473\n",
      "Validation loss 0.1437\n",
      "Epoch 82\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0334928 ]\n",
      " [0.00996501]\n",
      " [0.00534624]\n",
      " [0.00118935]]\n",
      "Train loss 0.1470\n",
      "Validation loss 0.1434\n",
      "Epoch 83\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03329145]\n",
      " [0.00983635]\n",
      " [0.0052728 ]\n",
      " [0.00116039]]\n",
      "Train loss 0.1466\n",
      "Validation loss 0.1430\n",
      "Epoch 84\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03309361]\n",
      " [0.00971125]\n",
      " [0.0052015 ]\n",
      " [0.00113248]]\n",
      "Train loss 0.1463\n",
      "Validation loss 0.1427\n",
      "Epoch 85\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03289921]\n",
      " [0.00958958]\n",
      " [0.00513226]\n",
      " [0.00110557]]\n",
      "Train loss 0.1460\n",
      "Validation loss 0.1423\n",
      "Epoch 86\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03270812]\n",
      " [0.00947119]\n",
      " [0.00506498]\n",
      " [0.00107961]]\n",
      "Train loss 0.1456\n",
      "Validation loss 0.1420\n",
      "Epoch 87\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0325202 ]\n",
      " [0.00935597]\n",
      " [0.00499959]\n",
      " [0.00105457]]\n",
      "Train loss 0.1453\n",
      "Validation loss 0.1417\n",
      "Epoch 88\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03233541]\n",
      " [0.0092438 ]\n",
      " [0.00493601]\n",
      " [0.00103039]]\n",
      "Train loss 0.1450\n",
      "Validation loss 0.1413\n",
      "Epoch 89\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0321536 ]\n",
      " [0.00913457]\n",
      " [0.00487418]\n",
      " [0.00100705]]\n",
      "Train loss 0.1447\n",
      "Validation loss 0.1410\n",
      "Epoch 90\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03197472]\n",
      " [0.00902817]\n",
      " [0.00481402]\n",
      " [0.0009845 ]]\n",
      "Train loss 0.1444\n",
      "Validation loss 0.1407\n",
      "Epoch 91\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03179864]\n",
      " [0.00892451]\n",
      " [0.00475548]\n",
      " [0.00096271]]\n",
      "Train loss 0.1441\n",
      "Validation loss 0.1404\n",
      "Epoch 92\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0316253 ]\n",
      " [0.00882348]\n",
      " [0.00469848]\n",
      " [0.00094165]]\n",
      "Train loss 0.1438\n",
      "Validation loss 0.1401\n",
      "Epoch 93\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03145462]\n",
      " [0.00872499]\n",
      " [0.00464297]\n",
      " [0.00092129]]\n",
      "Train loss 0.1436\n",
      "Validation loss 0.1398\n",
      "Epoch 94\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.0312865 ]\n",
      " [0.00862895]\n",
      " [0.00458891]\n",
      " [0.00090159]]\n",
      "Train loss 0.1433\n",
      "Validation loss 0.1396\n",
      "Epoch 95\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03112088]\n",
      " [0.00853529]\n",
      " [0.00453622]\n",
      " [0.00088253]]\n",
      "Train loss 0.1430\n",
      "Validation loss 0.1393\n",
      "Epoch 96\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03095769]\n",
      " [0.00844391]\n",
      " [0.00448487]\n",
      " [0.00086408]]\n",
      "Train loss 0.1428\n",
      "Validation loss 0.1390\n",
      "Epoch 97\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03079685]\n",
      " [0.00835474]\n",
      " [0.00443481]\n",
      " [0.00084622]]\n",
      "Train loss 0.1425\n",
      "Validation loss 0.1388\n",
      "Epoch 98\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03063829]\n",
      " [0.00826771]\n",
      " [0.00438598]\n",
      " [0.00082892]]\n",
      "Train loss 0.1423\n",
      "Validation loss 0.1385\n",
      "Epoch 99\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "[[0.03048199]\n",
      " [0.00818275]\n",
      " [0.00433835]\n",
      " [0.00081216]]\n",
      "Train loss 0.1420\n",
      "Validation loss 0.1382\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_epoch_loss_list = []\n",
    "validation_epoch_loss_list = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    batch_accumulate_loss0 = 0\n",
    "    \n",
    "    print('Epoch {}'.format(i))\n",
    "    for j in range(iterations):\n",
    "        index = j*batch\n",
    "\n",
    "        theta0_value = sess.run(theta_update(theta0,gradient0))\n",
    "        theta1_value = sess.run(theta_update(theta1,gradient1))\n",
    "        theta2_value = sess.run(theta_update(theta2,gradient2))\n",
    "        theta3_value = sess.run(theta_update(theta3,gradient3))\n",
    "        theta4_value = sess.run(theta_update(theta4,gradient4))\n",
    "        theta5_value = sess.run(theta_update(theta5,gradient5))\n",
    "        theta6_value = sess.run(theta_update(theta6,gradient6))\n",
    "        theta7_value = sess.run(theta_update(theta7,gradient7))\n",
    "        theta8_value = sess.run(theta_update(theta8,gradient8))\n",
    "        theta9_value = sess.run(theta_update(theta9,gradient9))\n",
    "\n",
    "        y_values0, h_values0, gradient_values0, train_loss_value0 = sess.run([y, h0, gradient_update(gradient0, h0), loss_function(y, h0)], feed_dict={X:train_image_norm[index:index+batch], y:train_labels_onehot.iloc[:][0][index:index+batch].values.reshape(batch,1)})\n",
    "        y_values1, h_values1, gradient_values1, train_loss_value1 = sess.run([y, h1, gradient_update(gradient1, h1), loss_function(y, h1)], feed_dict={X:train_image_norm[index:index+batch], y:train_labels_onehot.iloc[:][1][index:index+batch].values.reshape(batch,1)})\n",
    "        y_values2, h_values2, gradient_values2, train_loss_value2 = sess.run([y, h2, gradient_update(gradient2, h2), loss_function(y, h2)], feed_dict={X:train_image_norm[index:index+batch], y:train_labels_onehot.iloc[:][2][index:index+batch].values.reshape(batch,1)})\n",
    "        y_values3, h_values3, gradient_values3, train_loss_value3 = sess.run([y, h3, gradient_update(gradient3, h3), loss_function(y, h3)], feed_dict={X:train_image_norm[index:index+batch], y:train_labels_onehot.iloc[:][3][index:index+batch].values.reshape(batch,1)})\n",
    "        y_values4, h_values4, gradient_values4, train_loss_value4 = sess.run([y, h4, gradient_update(gradient4, h4), loss_function(y, h4)], feed_dict={X:train_image_norm[index:index+batch], y:train_labels_onehot.iloc[:][4][index:index+batch].values.reshape(batch,1)})\n",
    "        y_values5, h_values5, gradient_values5, train_loss_value5 = sess.run([y, h5, gradient_update(gradient5, h5), loss_function(y, h5)], feed_dict={X:train_image_norm[index:index+batch], y:train_labels_onehot.iloc[:][5][index:index+batch].values.reshape(batch,1)})\n",
    "        y_values6, h_values6, gradient_values6, train_loss_value6 = sess.run([y, h6, gradient_update(gradient6, h6), loss_function(y, h6)], feed_dict={X:train_image_norm[index:index+batch], y:train_labels_onehot.iloc[:][6][index:index+batch].values.reshape(batch,1)})\n",
    "        y_values7, h_values7, gradient_values7, train_loss_value7 = sess.run([y, h7, gradient_update(gradient7, h7), loss_function(y, h7)], feed_dict={X:train_image_norm[index:index+batch], y:train_labels_onehot.iloc[:][7][index:index+batch].values.reshape(batch,1)})\n",
    "        y_values8, h_values8, gradient_values8, train_loss_value8 = sess.run([y, h8, gradient_update(gradient8, h8), loss_function(y, h8)], feed_dict={X:train_image_norm[index:index+batch], y:train_labels_onehot.iloc[:][8][index:index+batch].values.reshape(batch,1)})\n",
    "        y_values9, h_values9, gradient_values9, train_loss_value9 = sess.run([y, h9, gradient_update(gradient9, h9), loss_function(y, h9)], feed_dict={X:train_image_norm[index:index+batch], y:train_labels_onehot.iloc[:][9][index:index+batch].values.reshape(batch,1)})\n",
    "\n",
    "        batch_accumulate_loss0 += train_loss_value0\n",
    "\n",
    "    train_epoch_loss0 = batch_accumulate_loss0/iterations\n",
    "    train_epoch_loss_list.append(train_epoch_loss0)\n",
    "    validation_loss_value0 = sess.run(loss0, feed_dict={X:validation_image_norm, y:validation_labels_onehot.iloc[:][0].values.reshape(-1,1)})\n",
    "    validation_epoch_loss_list.append(validation_loss_value0)\n",
    "\n",
    "    print('Train loss {0:.4f}'.format(train_loss_value0))\n",
    "    print('Validation loss {0:.4f}'.format(validation_loss_value0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(1)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0))\n",
    "plt.grid()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Average Cost')\n",
    "plt.plot(range(len(train_epoch_loss_list)),train_epoch_loss_list, '-bx')\n",
    "plt.plot(range(len(validation_epoch_loss_list)),validation_epoch_loss_list, '-r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_values0 = sess.run(h0, feed_dict={X:test_image_norm})\n",
    "h_values1 = sess.run(h1, feed_dict={X:test_image_norm})\n",
    "h_values2 = sess.run(h2, feed_dict={X:test_image_norm})\n",
    "h_values3 = sess.run(h3, feed_dict={X:test_image_norm})\n",
    "h_values4 = sess.run(h4, feed_dict={X:test_image_norm})\n",
    "h_values5 = sess.run(h5, feed_dict={X:test_image_norm})\n",
    "h_values6 = sess.run(h6, feed_dict={X:test_image_norm})\n",
    "h_values7 = sess.run(h7, feed_dict={X:test_image_norm})\n",
    "h_values8 = sess.run(h8, feed_dict={X:test_image_norm})\n",
    "h_values9 = sess.run(h9, feed_dict={X:test_image_norm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = np.maximum.reduce([h_values0,h_values1,h_values2,h_values3,h_values4,h_values5,h_values6,h_values7,h_values8,h_values9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0_index = h_values0 >= max_values\n",
    "h1_index = h_values1 >= max_values\n",
    "h2_index = h_values2 >= max_values\n",
    "h3_index = h_values3 >= max_values \n",
    "h4_index = h_values4 >= max_values\n",
    "h5_index = h_values5 >= max_values \n",
    "h6_index = h_values6 >= max_values\n",
    "h7_index = h_values7 >= max_values\n",
    "h8_index = h_values8 >= max_values\n",
    "h9_index = h_values9 >= max_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_labels = np.zeros_like(h0_index,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_labels[h1_index==1]=1\n",
    "result_labels[h2_index==1]=2\n",
    "result_labels[h3_index==1]=3\n",
    "result_labels[h4_index==1]=4\n",
    "result_labels[h5_index==1]=5\n",
    "result_labels[h6_index==1]=6\n",
    "result_labels[h7_index==1]=7\n",
    "result_labels[h8_index==1]=8\n",
    "result_labels[h9_index==1]=9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7246"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(test_labels,result_labels.ravel(), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted     0    1    2     3     4     5    6     7    8     9  __all__\n",
       "Actual                                                                    \n",
       "0           764   11   10   104    14    32   48     2   14     1     1000\n",
       "1            20  899   19    49     9     1    1     1    1     0     1000\n",
       "2            30    2  561    14   217    29  119     0   28     0     1000\n",
       "3            64   17    5   809    50     8   44     0    3     0     1000\n",
       "4             2    1  186    38   668    15   71     0   18     1     1000\n",
       "5             0    2    0     4     0   727    1   160   14    92     1000\n",
       "6           205    2  162    82   232    51  226     2   37     1     1000\n",
       "7             0    0    0     0     0    70    0   830    8    92     1000\n",
       "8             8    0   10    19    13    40   18    33  855     4     1000\n",
       "9             0    0    0     2     0    36    0    51    4   907     1000\n",
       "__all__    1093  934  953  1121  1203  1009  528  1079  982  1098    10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConfusionMatrix(test_labels,result_labels.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
