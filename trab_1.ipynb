{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diamonds.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = train_test_split(train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_hot_cut = pd.get_dummies(train['cut'])\n",
    "train_one_hot_color = pd.get_dummies(train['color'])\n",
    "train_one_hot_clarity = pd.get_dummies(train['clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_one_hot_cut = pd.get_dummies(validation['cut'])\n",
    "validation_one_hot_color = pd.get_dummies(validation['color'])\n",
    "validation_one_hot_clarity = pd.get_dummies(validation['clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_one_hot_cut = pd.get_dummies(test['cut'])\n",
    "test_one_hot_color = pd.get_dummies(test['color'])\n",
    "test_one_hot_clarity = pd.get_dummies(test['clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc[:,'price']\n",
    "y_validation = validation.loc[:,'price']\n",
    "y_test = test.loc[:,'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop('price', axis=1)\n",
    "x_validation = validation.drop('price', axis=1)\n",
    "x_test = test.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop('cut', axis=1)\n",
    "x_train = x_train.drop('color', axis=1)\n",
    "x_train = x_train.drop('clarity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation = x_validation.drop('cut', axis=1)\n",
    "x_validation = x_validation.drop('color', axis=1)\n",
    "x_validation = x_validation.drop('clarity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.drop('cut', axis=1)\n",
    "x_test = x_test.drop('color', axis=1)\n",
    "x_test = x_test.drop('clarity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = StandardScaler().fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15225</th>\n",
       "      <td>1.04</td>\n",
       "      <td>61.9</td>\n",
       "      <td>57.0</td>\n",
       "      <td>6.51</td>\n",
       "      <td>6.54</td>\n",
       "      <td>4.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25920</th>\n",
       "      <td>2.05</td>\n",
       "      <td>60.1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>8.19</td>\n",
       "      <td>4.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>1.15</td>\n",
       "      <td>62.4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.70</td>\n",
       "      <td>6.74</td>\n",
       "      <td>4.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33294</th>\n",
       "      <td>0.31</td>\n",
       "      <td>60.1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39353</th>\n",
       "      <td>0.52</td>\n",
       "      <td>63.3</td>\n",
       "      <td>55.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>5.10</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  depth  table     x     y     z\n",
       "15225   1.04   61.9   57.0  6.51  6.54  4.04\n",
       "25920   2.05   60.1   58.0  8.25  8.19  4.94\n",
       "10870   1.15   62.4   56.0  6.70  6.74  4.19\n",
       "33294   0.31   60.1   58.0  4.38  4.40  2.64\n",
       "39353   0.52   63.3   55.0  5.13  5.10  3.24"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46171</th>\n",
       "      <td>0.50</td>\n",
       "      <td>61.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.12</td>\n",
       "      <td>5.06</td>\n",
       "      <td>3.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9073</th>\n",
       "      <td>1.03</td>\n",
       "      <td>61.1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.50</td>\n",
       "      <td>6.56</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19600</th>\n",
       "      <td>1.57</td>\n",
       "      <td>62.4</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.51</td>\n",
       "      <td>7.40</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51753</th>\n",
       "      <td>0.70</td>\n",
       "      <td>60.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.71</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50636</th>\n",
       "      <td>0.23</td>\n",
       "      <td>61.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.99</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  depth  table     x     y     z\n",
       "46171   0.50   61.3   58.0  5.12  5.06  3.12\n",
       "9073    1.03   61.1   59.0  6.50  6.56  3.99\n",
       "19600   1.57   62.4   57.0  7.51  7.40  4.65\n",
       "51753   0.70   60.7   61.0  5.69  5.71  3.46\n",
       "50636   0.23   61.0   59.0  3.95  3.99  2.42"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = pd.DataFrame(x_scaler.transform(x_train), columns=x_train.columns, index=x_train.index)\n",
    "x_validation_norm = pd.DataFrame(x_scaler.transform(x_validation), columns=x_validation.columns, index=x_validation.index)\n",
    "x_test_norm = pd.DataFrame(x_scaler.transform(x_test), columns=x_test.columns, index=x_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15225</th>\n",
       "      <td>0.511974</td>\n",
       "      <td>0.105764</td>\n",
       "      <td>-0.202421</td>\n",
       "      <td>0.694728</td>\n",
       "      <td>0.698259</td>\n",
       "      <td>0.706089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25920</th>\n",
       "      <td>2.648343</td>\n",
       "      <td>-1.148395</td>\n",
       "      <td>0.246244</td>\n",
       "      <td>2.248009</td>\n",
       "      <td>2.131066</td>\n",
       "      <td>1.975421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>0.744648</td>\n",
       "      <td>0.454141</td>\n",
       "      <td>-0.651086</td>\n",
       "      <td>0.864339</td>\n",
       "      <td>0.871933</td>\n",
       "      <td>0.917644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33294</th>\n",
       "      <td>-1.032134</td>\n",
       "      <td>-1.148395</td>\n",
       "      <td>0.246244</td>\n",
       "      <td>-1.206701</td>\n",
       "      <td>-1.160047</td>\n",
       "      <td>-1.268427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39353</th>\n",
       "      <td>-0.587939</td>\n",
       "      <td>1.081220</td>\n",
       "      <td>-1.099751</td>\n",
       "      <td>-0.537184</td>\n",
       "      <td>-0.552190</td>\n",
       "      <td>-0.422206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          carat     depth     table         x         y         z\n",
       "15225  0.511974  0.105764 -0.202421  0.694728  0.698259  0.706089\n",
       "25920  2.648343 -1.148395  0.246244  2.248009  2.131066  1.975421\n",
       "10870  0.744648  0.454141 -0.651086  0.864339  0.871933  0.917644\n",
       "33294 -1.032134 -1.148395  0.246244 -1.206701 -1.160047 -1.268427\n",
       "39353 -0.587939  1.081220 -1.099751 -0.537184 -0.552190 -0.422206"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46171</th>\n",
       "      <td>-0.630243</td>\n",
       "      <td>-0.312289</td>\n",
       "      <td>0.246244</td>\n",
       "      <td>-0.546111</td>\n",
       "      <td>-0.586924</td>\n",
       "      <td>-0.591450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9073</th>\n",
       "      <td>0.490822</td>\n",
       "      <td>-0.451640</td>\n",
       "      <td>0.694908</td>\n",
       "      <td>0.685801</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.635571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19600</th>\n",
       "      <td>1.633039</td>\n",
       "      <td>0.454141</td>\n",
       "      <td>-0.202421</td>\n",
       "      <td>1.587418</td>\n",
       "      <td>1.445055</td>\n",
       "      <td>1.566414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51753</th>\n",
       "      <td>-0.207200</td>\n",
       "      <td>-0.730342</td>\n",
       "      <td>1.592238</td>\n",
       "      <td>-0.037278</td>\n",
       "      <td>-0.022486</td>\n",
       "      <td>-0.111925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50636</th>\n",
       "      <td>-1.201352</td>\n",
       "      <td>-0.521315</td>\n",
       "      <td>0.694908</td>\n",
       "      <td>-1.590558</td>\n",
       "      <td>-1.516078</td>\n",
       "      <td>-1.578708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          carat     depth     table         x         y         z\n",
       "46171 -0.630243 -0.312289  0.246244 -0.546111 -0.586924 -0.591450\n",
       "9073   0.490822 -0.451640  0.694908  0.685801  0.715627  0.635571\n",
       "19600  1.633039  0.454141 -0.202421  1.587418  1.445055  1.566414\n",
       "51753 -0.207200 -0.730342  1.592238 -0.037278 -0.022486 -0.111925\n",
       "50636 -1.201352 -0.521315  0.694908 -1.590558 -1.516078 -1.578708"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = x_train_norm.join(train_one_hot_cut)\n",
    "x_train_norm = x_train_norm.join(train_one_hot_color)\n",
    "x_train_norm = x_train_norm.join(train_one_hot_clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation_norm = x_validation_norm.join(validation_one_hot_cut)\n",
    "x_validation_norm = x_validation_norm.join(validation_one_hot_color)\n",
    "x_validation_norm = x_validation_norm.join(validation_one_hot_clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_norm = x_test_norm.join(test_one_hot_cut)\n",
    "x_test_norm = x_test_norm.join(test_one_hot_color)\n",
    "x_test_norm = x_test_norm.join(test_one_hot_clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Fair</th>\n",
       "      <th>Good</th>\n",
       "      <th>Ideal</th>\n",
       "      <th>Premium</th>\n",
       "      <th>...</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>I1</th>\n",
       "      <th>IF</th>\n",
       "      <th>SI1</th>\n",
       "      <th>SI2</th>\n",
       "      <th>VS1</th>\n",
       "      <th>VS2</th>\n",
       "      <th>VVS1</th>\n",
       "      <th>VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15225</th>\n",
       "      <td>0.511974</td>\n",
       "      <td>0.105764</td>\n",
       "      <td>-0.202421</td>\n",
       "      <td>0.694728</td>\n",
       "      <td>0.698259</td>\n",
       "      <td>0.706089</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25920</th>\n",
       "      <td>2.648343</td>\n",
       "      <td>-1.148395</td>\n",
       "      <td>0.246244</td>\n",
       "      <td>2.248009</td>\n",
       "      <td>2.131066</td>\n",
       "      <td>1.975421</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10870</th>\n",
       "      <td>0.744648</td>\n",
       "      <td>0.454141</td>\n",
       "      <td>-0.651086</td>\n",
       "      <td>0.864339</td>\n",
       "      <td>0.871933</td>\n",
       "      <td>0.917644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33294</th>\n",
       "      <td>-1.032134</td>\n",
       "      <td>-1.148395</td>\n",
       "      <td>0.246244</td>\n",
       "      <td>-1.206701</td>\n",
       "      <td>-1.160047</td>\n",
       "      <td>-1.268427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39353</th>\n",
       "      <td>-0.587939</td>\n",
       "      <td>1.081220</td>\n",
       "      <td>-1.099751</td>\n",
       "      <td>-0.537184</td>\n",
       "      <td>-0.552190</td>\n",
       "      <td>-0.422206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          carat     depth     table         x         y         z  Fair  Good  \\\n",
       "15225  0.511974  0.105764 -0.202421  0.694728  0.698259  0.706089     0     0   \n",
       "25920  2.648343 -1.148395  0.246244  2.248009  2.131066  1.975421     0     0   \n",
       "10870  0.744648  0.454141 -0.651086  0.864339  0.871933  0.917644     0     0   \n",
       "33294 -1.032134 -1.148395  0.246244 -1.206701 -1.160047 -1.268427     0     0   \n",
       "39353 -0.587939  1.081220 -1.099751 -0.537184 -0.552190 -0.422206     0     0   \n",
       "\n",
       "       Ideal  Premium  ...   I  J  I1  IF  SI1  SI2  VS1  VS2  VVS1  VVS2  \n",
       "15225      1        0  ...   0  0   0   0    1    0    0    0     0     0  \n",
       "25920      0        1  ...   0  1   0   0    0    0    1    0     0     0  \n",
       "10870      1        0  ...   0  0   0   0    0    1    0    0     0     0  \n",
       "33294      0        1  ...   0  0   0   0    0    1    0    0     0     0  \n",
       "39353      0        0  ...   1  0   0   0    1    0    0    0     0     0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Fair</th>\n",
       "      <th>Good</th>\n",
       "      <th>Ideal</th>\n",
       "      <th>Premium</th>\n",
       "      <th>...</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>I1</th>\n",
       "      <th>IF</th>\n",
       "      <th>SI1</th>\n",
       "      <th>SI2</th>\n",
       "      <th>VS1</th>\n",
       "      <th>VS2</th>\n",
       "      <th>VVS1</th>\n",
       "      <th>VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46171</th>\n",
       "      <td>-0.630243</td>\n",
       "      <td>-0.312289</td>\n",
       "      <td>0.246244</td>\n",
       "      <td>-0.546111</td>\n",
       "      <td>-0.586924</td>\n",
       "      <td>-0.591450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9073</th>\n",
       "      <td>0.490822</td>\n",
       "      <td>-0.451640</td>\n",
       "      <td>0.694908</td>\n",
       "      <td>0.685801</td>\n",
       "      <td>0.715627</td>\n",
       "      <td>0.635571</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19600</th>\n",
       "      <td>1.633039</td>\n",
       "      <td>0.454141</td>\n",
       "      <td>-0.202421</td>\n",
       "      <td>1.587418</td>\n",
       "      <td>1.445055</td>\n",
       "      <td>1.566414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51753</th>\n",
       "      <td>-0.207200</td>\n",
       "      <td>-0.730342</td>\n",
       "      <td>1.592238</td>\n",
       "      <td>-0.037278</td>\n",
       "      <td>-0.022486</td>\n",
       "      <td>-0.111925</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50636</th>\n",
       "      <td>-1.201352</td>\n",
       "      <td>-0.521315</td>\n",
       "      <td>0.694908</td>\n",
       "      <td>-1.590558</td>\n",
       "      <td>-1.516078</td>\n",
       "      <td>-1.578708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          carat     depth     table         x         y         z  Fair  Good  \\\n",
       "46171 -0.630243 -0.312289  0.246244 -0.546111 -0.586924 -0.591450     0     0   \n",
       "9073   0.490822 -0.451640  0.694908  0.685801  0.715627  0.635571     0     0   \n",
       "19600  1.633039  0.454141 -0.202421  1.587418  1.445055  1.566414     0     0   \n",
       "51753 -0.207200 -0.730342  1.592238 -0.037278 -0.022486 -0.111925     0     1   \n",
       "50636 -1.201352 -0.521315  0.694908 -1.590558 -1.516078 -1.578708     0     0   \n",
       "\n",
       "       Ideal  Premium  ...   I  J  I1  IF  SI1  SI2  VS1  VS2  VVS1  VVS2  \n",
       "46171      0        1  ...   0  0   0   0    0    0    0    1     0     0  \n",
       "9073       0        0  ...   0  0   0   0    1    0    0    0     0     0  \n",
       "19600      1        0  ...   0  1   0   0    1    0    0    0     0     0  \n",
       "51753      0        0  ...   0  0   0   0    0    1    0    0     0     0  \n",
       "50636      0        0  ...   0  0   0   0    0    0    0    1     0     0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_norm = np.dot(np.linalg.pinv(np.dot(np.transpose(x_train_norm),x_train_norm)),np.dot(np.transpose(x_train_norm),y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation_pred_normal = np.dot(theta_norm, np.transpose(x_validation_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9135950936380198"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_validation, y_validation_pred_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "752.9581500867752"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(y_validation, y_validation_pred_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0001\n",
    "iterations=75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDRegressor(eta0=learning_rate, max_iter=iterations,verbose=True, penalty=\"None\", loss=\"squared_loss\", learning_rate=\"constant\", tol=None, shuffle=False, fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_theta = np.zeros_like(theta_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 4970.23, NNZs: 26, Bias: 0.000000, T: 38971, Avg. loss: 3246386.645378\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5623.19, NNZs: 26, Bias: 0.000000, T: 77942, Avg. loss: 1238798.395733\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5990.10, NNZs: 26, Bias: 0.000000, T: 116913, Avg. loss: 1030389.456806\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6305.25, NNZs: 26, Bias: 0.000000, T: 155884, Avg. loss: 911154.754506\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 6580.56, NNZs: 26, Bias: 0.000000, T: 194855, Avg. loss: 835373.960025\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 6818.20, NNZs: 26, Bias: 0.000000, T: 233826, Avg. loss: 785182.759905\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 7022.28, NNZs: 26, Bias: 0.000000, T: 272797, Avg. loss: 750757.319156\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 7197.58, NNZs: 26, Bias: 0.000000, T: 311768, Avg. loss: 726359.658933\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7348.73, NNZs: 26, Bias: 0.000000, T: 350739, Avg. loss: 708517.213978\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7479.79, NNZs: 26, Bias: 0.000000, T: 389710, Avg. loss: 695072.685980\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7594.21, NNZs: 26, Bias: 0.000000, T: 428681, Avg. loss: 684656.082396\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 7694.83, NNZs: 26, Bias: 0.000000, T: 467652, Avg. loss: 676379.639664\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 7783.99, NNZs: 26, Bias: 0.000000, T: 506623, Avg. loss: 669656.633318\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 7863.59, NNZs: 26, Bias: 0.000000, T: 545594, Avg. loss: 664091.461113\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 7935.16, NNZs: 26, Bias: 0.000000, T: 584565, Avg. loss: 659411.782958\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 7999.94, NNZs: 26, Bias: 0.000000, T: 623536, Avg. loss: 655425.982464\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 8058.94, NNZs: 26, Bias: 0.000000, T: 662507, Avg. loss: 651996.132902\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 8112.97, NNZs: 26, Bias: 0.000000, T: 701478, Avg. loss: 649020.595474\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 8162.72, NNZs: 26, Bias: 0.000000, T: 740449, Avg. loss: 646422.679354\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 8208.72, NNZs: 26, Bias: 0.000000, T: 779420, Avg. loss: 644143.161167\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 8251.41, NNZs: 26, Bias: 0.000000, T: 818391, Avg. loss: 642135.288321\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 8291.18, NNZs: 26, Bias: 0.000000, T: 857362, Avg. loss: 640361.397292\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 8328.32, NNZs: 26, Bias: 0.000000, T: 896333, Avg. loss: 638790.592420\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 8363.11, NNZs: 26, Bias: 0.000000, T: 935304, Avg. loss: 637397.128085\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 8395.75, NNZs: 26, Bias: 0.000000, T: 974275, Avg. loss: 636159.262222\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 8426.43, NNZs: 26, Bias: 0.000000, T: 1013246, Avg. loss: 635058.429134\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 8455.32, NNZs: 26, Bias: 0.000000, T: 1052217, Avg. loss: 634078.631160\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 8482.55, NNZs: 26, Bias: 0.000000, T: 1091188, Avg. loss: 633205.982288\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 8508.24, NNZs: 26, Bias: 0.000000, T: 1130159, Avg. loss: 632428.358765\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8532.50, NNZs: 26, Bias: 0.000000, T: 1169130, Avg. loss: 631735.126217\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 8555.43, NNZs: 26, Bias: 0.000000, T: 1208101, Avg. loss: 631116.922409\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8577.11, NNZs: 26, Bias: 0.000000, T: 1247072, Avg. loss: 630565.481214\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 8597.62, NNZs: 26, Bias: 0.000000, T: 1286043, Avg. loss: 630073.487659\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8617.03, NNZs: 26, Bias: 0.000000, T: 1325014, Avg. loss: 629634.456866\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 8635.40, NNZs: 26, Bias: 0.000000, T: 1363985, Avg. loss: 629242.631728\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 8652.79, NNZs: 26, Bias: 0.000000, T: 1402956, Avg. loss: 628892.895524\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8669.26, NNZs: 26, Bias: 0.000000, T: 1441927, Avg. loss: 628580.696656\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 8684.85, NNZs: 26, Bias: 0.000000, T: 1480898, Avg. loss: 628301.983377\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 8699.63, NNZs: 26, Bias: 0.000000, T: 1519869, Avg. loss: 628053.146868\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 8713.62, NNZs: 26, Bias: 0.000000, T: 1558840, Avg. loss: 627830.971357\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 8726.87, NNZs: 26, Bias: 0.000000, T: 1597811, Avg. loss: 627632.590264\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 8739.42, NNZs: 26, Bias: 0.000000, T: 1636782, Avg. loss: 627455.447519\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 8751.31, NNZs: 26, Bias: 0.000000, T: 1675753, Avg. loss: 627297.263370\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 8762.56, NNZs: 26, Bias: 0.000000, T: 1714724, Avg. loss: 627156.004104\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 8773.23, NNZs: 26, Bias: 0.000000, T: 1753695, Avg. loss: 627029.855188\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 8783.33, NNZs: 26, Bias: 0.000000, T: 1792666, Avg. loss: 626917.197418\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 8792.89, NNZs: 26, Bias: 0.000000, T: 1831637, Avg. loss: 626816.585723\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 8801.95, NNZs: 26, Bias: 0.000000, T: 1870608, Avg. loss: 626726.730303\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 8810.52, NNZs: 26, Bias: 0.000000, T: 1909579, Avg. loss: 626646.479848\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 8818.64, NNZs: 26, Bias: 0.000000, T: 1948550, Avg. loss: 626574.806589\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 8826.33, NNZs: 26, Bias: 0.000000, T: 1987521, Avg. loss: 626510.792979\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 8833.61, NNZs: 26, Bias: 0.000000, T: 2026492, Avg. loss: 626453.619826\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 8840.50, NNZs: 26, Bias: 0.000000, T: 2065463, Avg. loss: 626402.555710\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 8847.02, NNZs: 26, Bias: 0.000000, T: 2104434, Avg. loss: 626356.947550\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 8853.19, NNZs: 26, Bias: 0.000000, T: 2143405, Avg. loss: 626316.212184\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 8859.04, NNZs: 26, Bias: 0.000000, T: 2182376, Avg. loss: 626279.828871\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 8864.57, NNZs: 26, Bias: 0.000000, T: 2221347, Avg. loss: 626247.332586\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 8869.80, NNZs: 26, Bias: 0.000000, T: 2260318, Avg. loss: 626218.308051\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 8874.76, NNZs: 26, Bias: 0.000000, T: 2299289, Avg. loss: 626192.384397\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 8879.44, NNZs: 26, Bias: 0.000000, T: 2338260, Avg. loss: 626169.230409\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 8883.88, NNZs: 26, Bias: 0.000000, T: 2377231, Avg. loss: 626148.550278\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 8888.08, NNZs: 26, Bias: 0.000000, T: 2416202, Avg. loss: 626130.079812\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 8892.05, NNZs: 26, Bias: 0.000000, T: 2455173, Avg. loss: 626113.583045\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 8895.81, NNZs: 26, Bias: 0.000000, T: 2494144, Avg. loss: 626098.849226\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 8899.36, NNZs: 26, Bias: 0.000000, T: 2533115, Avg. loss: 626085.690112\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 8902.73, NNZs: 26, Bias: 0.000000, T: 2572086, Avg. loss: 626073.937570\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 8905.91, NNZs: 26, Bias: 0.000000, T: 2611057, Avg. loss: 626063.441418\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 8908.92, NNZs: 26, Bias: 0.000000, T: 2650028, Avg. loss: 626054.067513\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 8911.77, NNZs: 26, Bias: 0.000000, T: 2688999, Avg. loss: 626045.696033\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 8914.46, NNZs: 26, Bias: 0.000000, T: 2727970, Avg. loss: 626038.219945\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 8917.01, NNZs: 26, Bias: 0.000000, T: 2766941, Avg. loss: 626031.543646\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 8919.42, NNZs: 26, Bias: 0.000000, T: 2805912, Avg. loss: 626025.581733\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 8921.70, NNZs: 26, Bias: 0.000000, T: 2844883, Avg. loss: 626020.257919\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 8923.86, NNZs: 26, Bias: 0.000000, T: 2883854, Avg. loss: 626015.504060\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 8925.90, NNZs: 26, Bias: 0.000000, T: 2922825, Avg. loss: 626011.259283\n",
      "Total training time: 0.31 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.0001,\n",
       "       fit_intercept=False, l1_ratio=0.15, learning_rate='constant',\n",
       "       loss='squared_loss', max_iter=75, n_iter=None, penalty='None',\n",
       "       power_t=0.25, random_state=None, shuffle=False, tol=None,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train_norm, y_train, coef_init=initial_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation_pred_SKlearn = clf.predict(x_validation_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9135686685828697"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_validation, y_validation_pred_SKlearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "751.0297973510636"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(y_validation, y_validation_pred_SKlearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "def SGD(theta, x, y, learning_rate, iterations):\n",
    "    m = x.shape[0]\n",
    "    iter_average_cost_list =[]\n",
    "    fig = plt.figure(1)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Average Cost')\n",
    "    plt.ion()\n",
    "    plt.show()\n",
    "    for i in range(1,iterations+1):\n",
    "        iter_total_cost = 0\n",
    "        for item,price in zip(x.values, y.values):\n",
    "            y_pred = np.dot(item, theta)\n",
    "            loss = y_pred - price\n",
    "            cost = np.sum(loss ** 2)/2\n",
    "            gradient = np.dot(item.transpose(), loss)\n",
    "            theta = theta - learning_rate * gradient\n",
    "            iter_total_cost += cost\n",
    "        iter_average_cost = iter_total_cost/m\n",
    "        iter_average_cost_list.append(iter_average_cost)\n",
    "        print(\"Epoch {}\".format(i))\n",
    "        print(\"Cost {}\".format(iter_average_cost))\n",
    "        plt.scatter(i,iter_average_cost, c='b')\n",
    "        fig.canvas.draw()\n",
    "        plt.pause(0.0001)\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_theta = np.zeros_like(theta_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Cost 3246386.645378153\n",
      "Epoch 2\n",
      "Cost 1238798.3957333039\n",
      "Epoch 3\n",
      "Cost 1030389.4568055258\n",
      "Epoch 4\n",
      "Cost 911154.7545059922\n",
      "Epoch 5\n",
      "Cost 835373.9600249743\n",
      "Epoch 6\n",
      "Cost 785182.7599053635\n",
      "Epoch 7\n",
      "Cost 750757.3191560082\n",
      "Epoch 8\n",
      "Cost 726359.6589327609\n",
      "Epoch 9\n",
      "Cost 708517.2139777249\n",
      "Epoch 10\n",
      "Cost 695072.6859800695\n",
      "Epoch 11\n",
      "Cost 684656.0823958575\n",
      "Epoch 12\n",
      "Cost 676379.6396642638\n",
      "Epoch 13\n",
      "Cost 669656.633317559\n",
      "Epoch 14\n",
      "Cost 664091.4611134426\n",
      "Epoch 15\n",
      "Cost 659411.7829576638\n",
      "Epoch 16\n",
      "Cost 655425.9824642227\n",
      "Epoch 17\n",
      "Cost 651996.1329022887\n",
      "Epoch 18\n",
      "Cost 649020.5954738858\n",
      "Epoch 19\n",
      "Cost 646422.6793539126\n",
      "Epoch 20\n",
      "Cost 644143.1611673773\n",
      "Epoch 21\n",
      "Cost 642135.2883210038\n",
      "Epoch 22\n",
      "Cost 640361.3972916703\n",
      "Epoch 23\n",
      "Cost 638790.5924197484\n",
      "Epoch 24\n",
      "Cost 637397.1280851429\n",
      "Epoch 25\n",
      "Cost 636159.262222449\n",
      "Epoch 26\n",
      "Cost 635058.429134287\n",
      "Epoch 27\n",
      "Cost 634078.6311595236\n",
      "Epoch 28\n",
      "Cost 633205.9822875559\n",
      "Epoch 29\n",
      "Cost 632428.3587651339\n",
      "Epoch 30\n",
      "Cost 631735.1262166755\n",
      "Epoch 31\n",
      "Cost 631116.9224087847\n",
      "Epoch 32\n",
      "Cost 630565.4812144802\n",
      "Epoch 33\n",
      "Cost 630073.4876591064\n",
      "Epoch 34\n",
      "Cost 629634.4568658106\n",
      "Epoch 35\n",
      "Cost 629242.6317281144\n",
      "Epoch 36\n",
      "Cost 628892.8955242067\n",
      "Epoch 37\n",
      "Cost 628580.6966558088\n",
      "Epoch 38\n",
      "Cost 628301.9833772391\n",
      "Epoch 39\n",
      "Cost 628053.146868198\n",
      "Epoch 40\n",
      "Cost 627830.9713574873\n",
      "Epoch 41\n",
      "Cost 627632.5902643544\n",
      "Epoch 42\n",
      "Cost 627455.4475188577\n",
      "Epoch 43\n",
      "Cost 627297.2633699349\n",
      "Epoch 44\n",
      "Cost 627156.0041041822\n",
      "Epoch 45\n",
      "Cost 627029.8551881311\n",
      "Epoch 46\n",
      "Cost 626917.1974184406\n",
      "Epoch 47\n",
      "Cost 626816.5857228104\n",
      "Epoch 48\n",
      "Cost 626726.7303026182\n",
      "Epoch 49\n",
      "Cost 626646.4798477811\n",
      "Epoch 50\n",
      "Cost 626574.8065888151\n",
      "Epoch 51\n",
      "Cost 626510.7929791886\n",
      "Epoch 52\n",
      "Cost 626453.6198263454\n",
      "Epoch 53\n",
      "Cost 626402.5557104826\n",
      "Epoch 54\n",
      "Cost 626356.9475495174\n",
      "Epoch 55\n",
      "Cost 626316.212184037\n",
      "Epoch 56\n",
      "Cost 626279.8288709089\n",
      "Epoch 57\n",
      "Cost 626247.3325864603\n",
      "Epoch 58\n",
      "Cost 626218.3080509892\n",
      "Epoch 59\n",
      "Cost 626192.3843966689\n",
      "Epoch 60\n",
      "Cost 626169.2304087899\n",
      "Epoch 61\n",
      "Cost 626148.550278471\n",
      "Epoch 62\n",
      "Cost 626130.0798116779\n",
      "Epoch 63\n",
      "Cost 626113.5830451734\n",
      "Epoch 64\n",
      "Cost 626098.8492255263\n",
      "Epoch 65\n",
      "Cost 626085.6901122248\n",
      "Epoch 66\n",
      "Cost 626073.9375698252\n",
      "Epoch 67\n",
      "Cost 626063.4414182499\n",
      "Epoch 68\n",
      "Cost 626054.0675132284\n",
      "Epoch 69\n",
      "Cost 626045.6960325023\n",
      "Epoch 70\n",
      "Cost 626038.219945287\n",
      "Epoch 71\n",
      "Cost 626031.5436457683\n",
      "Epoch 72\n",
      "Cost 626025.5817326066\n",
      "Epoch 73\n",
      "Cost 626020.2579191913\n",
      "Epoch 74\n",
      "Cost 626015.5040602484\n",
      "Epoch 75\n",
      "Cost 626011.2592826852\n"
     ]
    }
   ],
   "source": [
    "theta_sgd = SGD(initial_theta, x_train_norm, y_train, learning_rate, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation_pred_our = np.dot(theta_sgd, np.transpose(x_validation_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9126614704153672"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_validation, y_validation_pred_our)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748.3330012441908"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(y_validation, y_validation_pred_our)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_list = [10**i for i in range(-6,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1e-06, 1e-05, 0.0001, 0.001, 0.01]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_list = np.linspace(0, 200, 9)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25.,  50.,  75., 100., 125., 150., 175., 200.])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gridsearch = []\n",
    "for learning_rate in learning_rate_list:\n",
    "    for iteration in iterations_list:\n",
    "        clf = SGDRegressor(eta0=learning_rate, max_iter=iteration,verbose=False, penalty=\"None\", loss=\"squared_loss\", learning_rate=\"constant\", tol=None, shuffle=False, fit_intercept=False)\n",
    "        initial_theta = np.zeros_like(theta_norm)\n",
    "        clf.fit(x_train_norm, y_train, coef_init=initial_theta)\n",
    "        y_validation_pred_SKlearn = clf.predict(x_validation_norm)\n",
    "        r2_metric = metrics.r2_score(y_validation, y_validation_pred_SKlearn)\n",
    "        mae_metric = metrics.mean_absolute_error(y_validation, y_validation_pred_SKlearn)\n",
    "        results_gridsearch.append([learning_rate,iteration,r2_metric,mae_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = np.array(results_gridsearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_idx = results[:,3].argsort()\n",
    "results = results[result_idx]\n",
    "results = results[results[..., 2] >= 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000000e-03 2.50000000e+01 9.12661470e-01 7.48333001e+02]\n",
      " [1.00000000e-03 5.00000000e+01 9.12661474e-01 7.48333026e+02]\n",
      " [1.00000000e-03 1.25000000e+02 9.12661474e-01 7.48333026e+02]\n",
      " [1.00000000e-03 1.00000000e+02 9.12661474e-01 7.48333026e+02]\n",
      " [1.00000000e-03 1.50000000e+02 9.12661474e-01 7.48333026e+02]\n",
      " [1.00000000e-03 1.75000000e+02 9.12661474e-01 7.48333026e+02]\n",
      " [1.00000000e-03 7.50000000e+01 9.12661474e-01 7.48333026e+02]\n",
      " [1.00000000e-03 2.00000000e+02 9.12661474e-01 7.48333026e+02]\n",
      " [1.00000000e-04 7.50000000e+01 9.13568669e-01 7.51029797e+02]\n",
      " [1.00000000e-04 1.00000000e+02 9.13586927e-01 7.51032898e+02]\n",
      " [1.00000000e-04 1.25000000e+02 9.13591395e-01 7.51045008e+02]\n",
      " [1.00000000e-04 1.50000000e+02 9.13592604e-01 7.51050502e+02]\n",
      " [1.00000000e-04 1.75000000e+02 9.13592935e-01 7.51052442e+02]\n",
      " [1.00000000e-04 2.00000000e+02 9.13593026e-01 7.51053060e+02]\n",
      " [1.00000000e-04 5.00000000e+01 9.13462458e-01 7.51368167e+02]\n",
      " [1.00000000e-04 2.50000000e+01 9.12348796e-01 7.56844978e+02]\n",
      " [1.00000000e-05 2.00000000e+02 9.11455192e-01 7.64454571e+02]\n",
      " [1.00000000e-05 1.75000000e+02 9.10735515e-01 7.68453298e+02]\n",
      " [1.00000000e-05 1.50000000e+02 9.09693930e-01 7.74120843e+02]\n",
      " [1.00000000e-05 1.25000000e+02 9.08105453e-01 7.82916512e+02]\n",
      " [1.00000000e-05 1.00000000e+02 9.05493022e-01 7.99227565e+02]\n",
      " [1.00000000e-05 7.50000000e+01 9.00715491e-01 8.30181909e+02]\n",
      " [1.00000000e-05 5.00000000e+01 8.90618083e-01 8.91760956e+02]\n",
      " [1.00000000e-05 2.50000000e+01 8.64614976e-01 1.02635896e+03]\n",
      " [1.00000000e-06 2.00000000e+02 8.54860544e-01 1.06891688e+03]\n",
      " [1.00000000e-06 1.75000000e+02 8.48880563e-01 1.09261684e+03]\n",
      " [1.00000000e-06 1.50000000e+02 8.41795577e-01 1.11816161e+03]\n",
      " [1.00000000e-06 1.25000000e+02 8.32785238e-01 1.14679523e+03]\n",
      " [1.00000000e-06 1.00000000e+02 8.19375019e-01 1.18454552e+03]\n",
      " [1.00000000e-06 7.50000000e+01 7.93446699e-01 1.25946422e+03]\n",
      " [1.00000000e-06 5.00000000e+01 7.27186543e-01 1.47264373e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(results[:,0],results[:,3],'.')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carat' 'Good' 'Ideal' 'Premium' 'Very Good' 'D' 'E' 'F' 'G' 'I1' 'IF'\n",
      " 'VS1' 'VVS1' 'VVS2']\n"
     ]
    }
   ],
   "source": [
    "model_sfm = SelectFromModel(clf, prefit=True)\n",
    "feature_mask = model_sfm.get_support()\n",
    "feature_name = np.array(x_train_norm.columns)\n",
    "print(np.array(feature_name)[feature_mask==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_selected = model_sfm.transform(x_train_norm)\n",
    "x_test_selected = model_sfm.transform(x_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 6112.56, NNZs: 14, Bias: 0.000000, T: 38971, Avg. loss: 4203252.211560\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 6927.98, NNZs: 14, Bias: 0.000000, T: 77942, Avg. loss: 1117473.269640\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 7147.16, NNZs: 14, Bias: 0.000000, T: 116913, Avg. loss: 986297.078003\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 7257.19, NNZs: 14, Bias: 0.000000, T: 155884, Avg. loss: 947529.769231\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 7335.66, NNZs: 14, Bias: 0.000000, T: 194855, Avg. loss: 926049.468025\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 7399.49, NNZs: 14, Bias: 0.000000, T: 233826, Avg. loss: 911909.152757\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 7454.28, NNZs: 14, Bias: 0.000000, T: 272797, Avg. loss: 901753.586048\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 7502.66, NNZs: 14, Bias: 0.000000, T: 311768, Avg. loss: 894051.089843\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 7546.18, NNZs: 14, Bias: 0.000000, T: 350739, Avg. loss: 887994.181305\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 7585.80, NNZs: 14, Bias: 0.000000, T: 389710, Avg. loss: 883111.769258\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 7622.20, NNZs: 14, Bias: 0.000000, T: 428681, Avg. loss: 879105.613840\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 7655.85, NNZs: 14, Bias: 0.000000, T: 467652, Avg. loss: 875774.138568\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 7687.10, NNZs: 14, Bias: 0.000000, T: 506623, Avg. loss: 872974.113478\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 7716.23, NNZs: 14, Bias: 0.000000, T: 545594, Avg. loss: 870599.943887\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 7743.45, NNZs: 14, Bias: 0.000000, T: 584565, Avg. loss: 868571.657613\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 7768.95, NNZs: 14, Bias: 0.000000, T: 623536, Avg. loss: 866827.464901\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 7792.86, NNZs: 14, Bias: 0.000000, T: 662507, Avg. loss: 865318.882004\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 7815.32, NNZs: 14, Bias: 0.000000, T: 701478, Avg. loss: 864007.386169\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 7836.45, NNZs: 14, Bias: 0.000000, T: 740449, Avg. loss: 862862.039913\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 7856.35, NNZs: 14, Bias: 0.000000, T: 779420, Avg. loss: 861857.759522\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 7875.10, NNZs: 14, Bias: 0.000000, T: 818391, Avg. loss: 860974.028641\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 7892.79, NNZs: 14, Bias: 0.000000, T: 857362, Avg. loss: 860193.928586\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 7909.48, NNZs: 14, Bias: 0.000000, T: 896333, Avg. loss: 859503.398997\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 7925.26, NNZs: 14, Bias: 0.000000, T: 935304, Avg. loss: 858890.668819\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 7940.17, NNZs: 14, Bias: 0.000000, T: 974275, Avg. loss: 858345.814786\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 7954.27, NNZs: 14, Bias: 0.000000, T: 1013246, Avg. loss: 857860.416304\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 7967.62, NNZs: 14, Bias: 0.000000, T: 1052217, Avg. loss: 857427.283813\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 7980.26, NNZs: 14, Bias: 0.000000, T: 1091188, Avg. loss: 857040.243535\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 7992.24, NNZs: 14, Bias: 0.000000, T: 1130159, Avg. loss: 856693.965777\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 8003.58, NNZs: 14, Bias: 0.000000, T: 1169130, Avg. loss: 856383.827060\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 8014.34, NNZs: 14, Bias: 0.000000, T: 1208101, Avg. loss: 856105.798686\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 8024.55, NNZs: 14, Bias: 0.000000, T: 1247072, Avg. loss: 855856.356044\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 8034.23, NNZs: 14, Bias: 0.000000, T: 1286043, Avg. loss: 855632.404333\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 8043.42, NNZs: 14, Bias: 0.000000, T: 1325014, Avg. loss: 855431.217293\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 8052.14, NNZs: 14, Bias: 0.000000, T: 1363985, Avg. loss: 855250.386345\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 8060.42, NNZs: 14, Bias: 0.000000, T: 1402956, Avg. loss: 855087.778090\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 8068.28, NNZs: 14, Bias: 0.000000, T: 1441927, Avg. loss: 854941.498565\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 8075.74, NNZs: 14, Bias: 0.000000, T: 1480898, Avg. loss: 854809.863004\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 8082.84, NNZs: 14, Bias: 0.000000, T: 1519869, Avg. loss: 854691.370084\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 8089.57, NNZs: 14, Bias: 0.000000, T: 1558840, Avg. loss: 854584.679894\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 8095.97, NNZs: 14, Bias: 0.000000, T: 1597811, Avg. loss: 854488.594967\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 8102.06, NNZs: 14, Bias: 0.000000, T: 1636782, Avg. loss: 854402.043879\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 8107.84, NNZs: 14, Bias: 0.000000, T: 1675753, Avg. loss: 854324.067004\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 8113.33, NNZs: 14, Bias: 0.000000, T: 1714724, Avg. loss: 854253.804080\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 8118.55, NNZs: 14, Bias: 0.000000, T: 1753695, Avg. loss: 854190.483326\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 8123.51, NNZs: 14, Bias: 0.000000, T: 1792666, Avg. loss: 854133.411877\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 8128.22, NNZs: 14, Bias: 0.000000, T: 1831637, Avg. loss: 854081.967351\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 8132.71, NNZs: 14, Bias: 0.000000, T: 1870608, Avg. loss: 854035.590398\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 8136.97, NNZs: 14, Bias: 0.000000, T: 1909579, Avg. loss: 853993.778095\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 8141.01, NNZs: 14, Bias: 0.000000, T: 1948550, Avg. loss: 853956.078084\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 8144.86, NNZs: 14, Bias: 0.000000, T: 1987521, Avg. loss: 853922.083348\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 8148.52, NNZs: 14, Bias: 0.000000, T: 2026492, Avg. loss: 853891.427569\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 8152.00, NNZs: 14, Bias: 0.000000, T: 2065463, Avg. loss: 853863.780972\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 8155.30, NNZs: 14, Bias: 0.000000, T: 2104434, Avg. loss: 853838.846613\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 8158.44, NNZs: 14, Bias: 0.000000, T: 2143405, Avg. loss: 853816.357064\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 8161.43, NNZs: 14, Bias: 0.000000, T: 2182376, Avg. loss: 853796.071439\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 8164.26, NNZs: 14, Bias: 0.000000, T: 2221347, Avg. loss: 853777.772725\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 8166.96, NNZs: 14, Bias: 0.000000, T: 2260318, Avg. loss: 853761.265396\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 8169.52, NNZs: 14, Bias: 0.000000, T: 2299289, Avg. loss: 853746.373260\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 8171.96, NNZs: 14, Bias: 0.000000, T: 2338260, Avg. loss: 853732.937539\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 8174.27, NNZs: 14, Bias: 0.000000, T: 2377231, Avg. loss: 853720.815127\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 8176.47, NNZs: 14, Bias: 0.000000, T: 2416202, Avg. loss: 853709.877041\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 8178.56, NNZs: 14, Bias: 0.000000, T: 2455173, Avg. loss: 853700.007014\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 8180.55, NNZs: 14, Bias: 0.000000, T: 2494144, Avg. loss: 853691.100237\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 8182.44, NNZs: 14, Bias: 0.000000, T: 2533115, Avg. loss: 853683.062222\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 8184.23, NNZs: 14, Bias: 0.000000, T: 2572086, Avg. loss: 853675.807786\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 8185.93, NNZs: 14, Bias: 0.000000, T: 2611057, Avg. loss: 853669.260127\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 8187.55, NNZs: 14, Bias: 0.000000, T: 2650028, Avg. loss: 853663.349996\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 8189.09, NNZs: 14, Bias: 0.000000, T: 2688999, Avg. loss: 853658.014955\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 8190.55, NNZs: 14, Bias: 0.000000, T: 2727970, Avg. loss: 853653.198704\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 8191.94, NNZs: 14, Bias: 0.000000, T: 2766941, Avg. loss: 853648.850471\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 8193.26, NNZs: 14, Bias: 0.000000, T: 2805912, Avg. loss: 853644.924477\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 8194.52, NNZs: 14, Bias: 0.000000, T: 2844883, Avg. loss: 853641.379432\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 8195.71, NNZs: 14, Bias: 0.000000, T: 2883854, Avg. loss: 853638.178105\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 8196.84, NNZs: 14, Bias: 0.000000, T: 2922825, Avg. loss: 853635.286915\n",
      "Total training time: 0.20 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.0001,\n",
       "       fit_intercept=False, l1_ratio=0.15, learning_rate='constant',\n",
       "       loss='squared_loss', max_iter=75, n_iter=None, penalty='None',\n",
       "       power_t=0.25, random_state=None, shuffle=False, tol=None,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89370375135579"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
