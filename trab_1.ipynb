{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diamonds.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat      cut color clarity  depth  table  price     x     y     z\n",
       "1   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "2   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "3   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "4   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "5   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validation = train_test_split(train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one_hot_cut = pd.get_dummies(train['cut'])\n",
    "train_one_hot_color = pd.get_dummies(train['color'])\n",
    "train_one_hot_clarity = pd.get_dummies(train['clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_one_hot_cut = pd.get_dummies(validation['cut'])\n",
    "validation_one_hot_color = pd.get_dummies(validation['color'])\n",
    "validation_one_hot_clarity = pd.get_dummies(validation['clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_one_hot_cut = pd.get_dummies(test['cut'])\n",
    "test_one_hot_color = pd.get_dummies(test['color'])\n",
    "test_one_hot_clarity = pd.get_dummies(test['clarity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.loc[:,'price']\n",
    "y_validation = validation.loc[:,'price']\n",
    "y_test = test.loc[:,'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop('price', axis=1)\n",
    "x_validation = validation.drop('price', axis=1)\n",
    "x_test = test.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop('cut', axis=1)\n",
    "x_train = x_train.drop('color', axis=1)\n",
    "x_train = x_train.drop('clarity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation = x_validation.drop('cut', axis=1)\n",
    "x_validation = x_validation.drop('color', axis=1)\n",
    "x_validation = x_validation.drop('clarity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.drop('cut', axis=1)\n",
    "x_test = x_test.drop('color', axis=1)\n",
    "x_test = x_test.drop('clarity', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = StandardScaler().fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12648</th>\n",
       "      <td>1.01</td>\n",
       "      <td>62.7</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.39</td>\n",
       "      <td>6.37</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643</th>\n",
       "      <td>1.60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>7.35</td>\n",
       "      <td>7.26</td>\n",
       "      <td>4.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31804</th>\n",
       "      <td>0.37</td>\n",
       "      <td>61.9</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>4.66</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48190</th>\n",
       "      <td>0.72</td>\n",
       "      <td>65.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>5.51</td>\n",
       "      <td>5.58</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30852</th>\n",
       "      <td>0.33</td>\n",
       "      <td>61.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.46</td>\n",
       "      <td>2.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  depth  table     x     y     z\n",
       "12648   1.01   62.7   58.0  6.39  6.37  4.00\n",
       "15643   1.60   65.0   56.0  7.35  7.26  4.80\n",
       "31804   0.37   61.9   55.0  4.60  4.66  2.86\n",
       "48190   0.72   65.8   59.0  5.51  5.58  3.65\n",
       "30852   0.33   61.2   55.0  4.49  4.46  2.74"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>0.32</td>\n",
       "      <td>61.5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.40</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12528</th>\n",
       "      <td>1.25</td>\n",
       "      <td>62.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.87</td>\n",
       "      <td>4.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25688</th>\n",
       "      <td>0.36</td>\n",
       "      <td>63.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.52</td>\n",
       "      <td>4.49</td>\n",
       "      <td>2.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14710</th>\n",
       "      <td>0.30</td>\n",
       "      <td>63.8</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>1.31</td>\n",
       "      <td>62.2</td>\n",
       "      <td>57.0</td>\n",
       "      <td>7.00</td>\n",
       "      <td>7.03</td>\n",
       "      <td>4.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat  depth  table     x     y     z\n",
       "2067    0.32   61.5   58.0  4.35  4.40  2.69\n",
       "12528   1.25   62.0   59.0  6.90  6.87  4.27\n",
       "25688   0.36   63.0   59.0  4.52  4.49  2.84\n",
       "14710   0.30   63.8   55.0  4.25  4.28  2.72\n",
       "18897   1.31   62.2   57.0  7.00  7.03  4.36"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = pd.DataFrame(x_scaler.transform(x_train), columns=x_train.columns, index=x_train.index)\n",
    "x_validation_norm = pd.DataFrame(x_scaler.transform(x_validation), columns=x_validation.columns, index=x_validation.index)\n",
    "x_test_norm = pd.DataFrame(x_scaler.transform(x_test), columns=x_test.columns, index=x_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12648</th>\n",
       "      <td>0.442320</td>\n",
       "      <td>0.661360</td>\n",
       "      <td>0.244274</td>\n",
       "      <td>0.582797</td>\n",
       "      <td>0.550741</td>\n",
       "      <td>0.644971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643</th>\n",
       "      <td>1.684171</td>\n",
       "      <td>2.261176</td>\n",
       "      <td>-0.656073</td>\n",
       "      <td>1.437909</td>\n",
       "      <td>1.327262</td>\n",
       "      <td>1.771001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31804</th>\n",
       "      <td>-0.904774</td>\n",
       "      <td>0.104902</td>\n",
       "      <td>-1.106246</td>\n",
       "      <td>-1.011631</td>\n",
       "      <td>-0.941228</td>\n",
       "      <td>-0.959621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48190</th>\n",
       "      <td>-0.168082</td>\n",
       "      <td>2.817633</td>\n",
       "      <td>0.694447</td>\n",
       "      <td>-0.201056</td>\n",
       "      <td>-0.138531</td>\n",
       "      <td>0.152333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30852</th>\n",
       "      <td>-0.988967</td>\n",
       "      <td>-0.381998</td>\n",
       "      <td>-1.106246</td>\n",
       "      <td>-1.109613</td>\n",
       "      <td>-1.115727</td>\n",
       "      <td>-1.128526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          carat     depth     table         x         y         z\n",
       "12648  0.442320  0.661360  0.244274  0.582797  0.550741  0.644971\n",
       "15643  1.684171  2.261176 -0.656073  1.437909  1.327262  1.771001\n",
       "31804 -0.904774  0.104902 -1.106246 -1.011631 -0.941228 -0.959621\n",
       "48190 -0.168082  2.817633  0.694447 -0.201056 -0.138531  0.152333\n",
       "30852 -0.988967 -0.381998 -1.106246 -1.109613 -1.115727 -1.128526"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>-1.010015</td>\n",
       "      <td>-0.173326</td>\n",
       "      <td>0.244274</td>\n",
       "      <td>-1.234317</td>\n",
       "      <td>-1.168077</td>\n",
       "      <td>-1.198903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12528</th>\n",
       "      <td>0.947480</td>\n",
       "      <td>0.174460</td>\n",
       "      <td>0.694447</td>\n",
       "      <td>1.037075</td>\n",
       "      <td>0.986989</td>\n",
       "      <td>1.025006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25688</th>\n",
       "      <td>-0.925822</td>\n",
       "      <td>0.870032</td>\n",
       "      <td>0.694447</td>\n",
       "      <td>-1.082891</td>\n",
       "      <td>-1.089552</td>\n",
       "      <td>-0.987772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14710</th>\n",
       "      <td>-1.052112</td>\n",
       "      <td>1.426489</td>\n",
       "      <td>-1.106246</td>\n",
       "      <td>-1.323391</td>\n",
       "      <td>-1.272776</td>\n",
       "      <td>-1.156676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>1.073770</td>\n",
       "      <td>0.313574</td>\n",
       "      <td>-0.205900</td>\n",
       "      <td>1.126149</td>\n",
       "      <td>1.126588</td>\n",
       "      <td>1.151684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          carat     depth     table         x         y         z\n",
       "2067  -1.010015 -0.173326  0.244274 -1.234317 -1.168077 -1.198903\n",
       "12528  0.947480  0.174460  0.694447  1.037075  0.986989  1.025006\n",
       "25688 -0.925822  0.870032  0.694447 -1.082891 -1.089552 -0.987772\n",
       "14710 -1.052112  1.426489 -1.106246 -1.323391 -1.272776 -1.156676\n",
       "18897  1.073770  0.313574 -0.205900  1.126149  1.126588  1.151684"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = x_train_norm.join(train_one_hot_cut)\n",
    "x_train_norm = x_train_norm.join(train_one_hot_color)\n",
    "x_train_norm = x_train_norm.join(train_one_hot_clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation_norm = x_validation_norm.join(validation_one_hot_cut)\n",
    "x_validation_norm = x_validation_norm.join(validation_one_hot_color)\n",
    "x_validation_norm = x_validation_norm.join(validation_one_hot_clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_norm = x_test_norm.join(test_one_hot_cut)\n",
    "x_test_norm = x_test_norm.join(test_one_hot_color)\n",
    "x_test_norm = x_test_norm.join(test_one_hot_clarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Fair</th>\n",
       "      <th>Good</th>\n",
       "      <th>Ideal</th>\n",
       "      <th>Premium</th>\n",
       "      <th>...</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>I1</th>\n",
       "      <th>IF</th>\n",
       "      <th>SI1</th>\n",
       "      <th>SI2</th>\n",
       "      <th>VS1</th>\n",
       "      <th>VS2</th>\n",
       "      <th>VVS1</th>\n",
       "      <th>VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12648</th>\n",
       "      <td>0.442320</td>\n",
       "      <td>0.661360</td>\n",
       "      <td>0.244274</td>\n",
       "      <td>0.582797</td>\n",
       "      <td>0.550741</td>\n",
       "      <td>0.644971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643</th>\n",
       "      <td>1.684171</td>\n",
       "      <td>2.261176</td>\n",
       "      <td>-0.656073</td>\n",
       "      <td>1.437909</td>\n",
       "      <td>1.327262</td>\n",
       "      <td>1.771001</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31804</th>\n",
       "      <td>-0.904774</td>\n",
       "      <td>0.104902</td>\n",
       "      <td>-1.106246</td>\n",
       "      <td>-1.011631</td>\n",
       "      <td>-0.941228</td>\n",
       "      <td>-0.959621</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48190</th>\n",
       "      <td>-0.168082</td>\n",
       "      <td>2.817633</td>\n",
       "      <td>0.694447</td>\n",
       "      <td>-0.201056</td>\n",
       "      <td>-0.138531</td>\n",
       "      <td>0.152333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30852</th>\n",
       "      <td>-0.988967</td>\n",
       "      <td>-0.381998</td>\n",
       "      <td>-1.106246</td>\n",
       "      <td>-1.109613</td>\n",
       "      <td>-1.115727</td>\n",
       "      <td>-1.128526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          carat     depth     table         x         y         z  Fair  Good  \\\n",
       "12648  0.442320  0.661360  0.244274  0.582797  0.550741  0.644971     0     0   \n",
       "15643  1.684171  2.261176 -0.656073  1.437909  1.327262  1.771001     1     0   \n",
       "31804 -0.904774  0.104902 -1.106246 -1.011631 -0.941228 -0.959621     0     0   \n",
       "48190 -0.168082  2.817633  0.694447 -0.201056 -0.138531  0.152333     0     1   \n",
       "30852 -0.988967 -0.381998 -1.106246 -1.109613 -1.115727 -1.128526     0     0   \n",
       "\n",
       "       Ideal  Premium  ...   I  J  I1  IF  SI1  SI2  VS1  VS2  VVS1  VVS2  \n",
       "12648      0        1  ...   0  0   0   0    0    0    1    0     0     0  \n",
       "15643      0        0  ...   0  0   0   0    0    1    0    0     0     0  \n",
       "31804      0        0  ...   0  0   0   0    0    0    0    0     1     0  \n",
       "48190      0        0  ...   0  0   0   0    0    1    0    0     0     0  \n",
       "30852      1        0  ...   0  0   0   0    0    0    0    1     0     0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>Fair</th>\n",
       "      <th>Good</th>\n",
       "      <th>Ideal</th>\n",
       "      <th>Premium</th>\n",
       "      <th>...</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>I1</th>\n",
       "      <th>IF</th>\n",
       "      <th>SI1</th>\n",
       "      <th>SI2</th>\n",
       "      <th>VS1</th>\n",
       "      <th>VS2</th>\n",
       "      <th>VVS1</th>\n",
       "      <th>VVS2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>-1.010015</td>\n",
       "      <td>-0.173326</td>\n",
       "      <td>0.244274</td>\n",
       "      <td>-1.234317</td>\n",
       "      <td>-1.168077</td>\n",
       "      <td>-1.198903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12528</th>\n",
       "      <td>0.947480</td>\n",
       "      <td>0.174460</td>\n",
       "      <td>0.694447</td>\n",
       "      <td>1.037075</td>\n",
       "      <td>0.986989</td>\n",
       "      <td>1.025006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25688</th>\n",
       "      <td>-0.925822</td>\n",
       "      <td>0.870032</td>\n",
       "      <td>0.694447</td>\n",
       "      <td>-1.082891</td>\n",
       "      <td>-1.089552</td>\n",
       "      <td>-0.987772</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14710</th>\n",
       "      <td>-1.052112</td>\n",
       "      <td>1.426489</td>\n",
       "      <td>-1.106246</td>\n",
       "      <td>-1.323391</td>\n",
       "      <td>-1.272776</td>\n",
       "      <td>-1.156676</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>1.073770</td>\n",
       "      <td>0.313574</td>\n",
       "      <td>-0.205900</td>\n",
       "      <td>1.126149</td>\n",
       "      <td>1.126588</td>\n",
       "      <td>1.151684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          carat     depth     table         x         y         z  Fair  Good  \\\n",
       "2067  -1.010015 -0.173326  0.244274 -1.234317 -1.168077 -1.198903     0     0   \n",
       "12528  0.947480  0.174460  0.694447  1.037075  0.986989  1.025006     0     0   \n",
       "25688 -0.925822  0.870032  0.694447 -1.082891 -1.089552 -0.987772     0     0   \n",
       "14710 -1.052112  1.426489 -1.106246 -1.323391 -1.272776 -1.156676     0     1   \n",
       "18897  1.073770  0.313574 -0.205900  1.126149  1.126588  1.151684     0     0   \n",
       "\n",
       "       Ideal  Premium  ...   I  J  I1  IF  SI1  SI2  VS1  VS2  VVS1  VVS2  \n",
       "2067       0        1  ...   0  0   0   0    0    0    0    1     0     0  \n",
       "12528      0        1  ...   0  1   0   0    0    0    0    1     0     0  \n",
       "25688      0        1  ...   0  0   0   0    0    1    0    0     0     0  \n",
       "14710      0        0  ...   0  0   0   0    0    0    1    0     0     0  \n",
       "18897      1        0  ...   1  0   0   0    0    0    1    0     0     0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_norm = np.dot(np.linalg.pinv(np.dot(np.transpose(x_train_norm),x_train_norm)),np.dot(np.transpose(x_train_norm),y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation_pred_normal = np.dot(theta_norm, np.transpose(x_validation_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9214854791961604"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_validation, y_validation_pred_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737.8968017848838"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(y_validation, y_validation_pred_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.001\n",
    "iterations=100\n",
    "initial_theta = np.zeros_like(theta_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDRegressor(eta0=learning_rate, max_iter=iterations,verbose=True, penalty=\"None\", loss=\"squared_loss\", learning_rate=\"constant\", tol=None, shuffle=False, fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 9025.27, NNZs: 26, Bias: 0.000000, T: 38971, Avg. loss: 647550.783251\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 9025.27, NNZs: 26, Bias: 0.000000, T: 77942, Avg. loss: 647546.605103\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 9025.32, NNZs: 26, Bias: 0.000000, T: 116913, Avg. loss: 647547.079885\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 9025.34, NNZs: 26, Bias: 0.000000, T: 155884, Avg. loss: 647547.093292\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 9025.35, NNZs: 26, Bias: 0.000000, T: 194855, Avg. loss: 647547.172694\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 9025.36, NNZs: 26, Bias: 0.000000, T: 233826, Avg. loss: 647547.198539\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 272797, Avg. loss: 647547.213976\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 311768, Avg. loss: 647547.220717\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 350739, Avg. loss: 647547.223960\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 389710, Avg. loss: 647547.225426\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 428681, Avg. loss: 647547.226092\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 467652, Avg. loss: 647547.226388\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 506623, Avg. loss: 647547.226517\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 545594, Avg. loss: 647547.226573\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 584565, Avg. loss: 647547.226596\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 623536, Avg. loss: 647547.226605\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 662507, Avg. loss: 647547.226608\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 701478, Avg. loss: 647547.226609\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 740449, Avg. loss: 647547.226609\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 779420, Avg. loss: 647547.226609\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 818391, Avg. loss: 647547.226609\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 857362, Avg. loss: 647547.226609\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 896333, Avg. loss: 647547.226609\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 935304, Avg. loss: 647547.226608\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 974275, Avg. loss: 647547.226608\n",
      "Total training time: 0.10 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1013246, Avg. loss: 647547.226608\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1052217, Avg. loss: 647547.226608\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1091188, Avg. loss: 647547.226608\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1130159, Avg. loss: 647547.226608\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1169130, Avg. loss: 647547.226608\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1208101, Avg. loss: 647547.226608\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1247072, Avg. loss: 647547.226608\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1286043, Avg. loss: 647547.226608\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1325014, Avg. loss: 647547.226608\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1363985, Avg. loss: 647547.226608\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1402956, Avg. loss: 647547.226608\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1441927, Avg. loss: 647547.226608\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1480898, Avg. loss: 647547.226608\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1519869, Avg. loss: 647547.226608\n",
      "Total training time: 0.15 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1558840, Avg. loss: 647547.226608\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1597811, Avg. loss: 647547.226608\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1636782, Avg. loss: 647547.226608\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1675753, Avg. loss: 647547.226608\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1714724, Avg. loss: 647547.226608\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1753695, Avg. loss: 647547.226608\n",
      "Total training time: 0.17 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1792666, Avg. loss: 647547.226608\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1831637, Avg. loss: 647547.226608\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1870608, Avg. loss: 647547.226608\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1909579, Avg. loss: 647547.226608\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1948550, Avg. loss: 647547.226608\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 1987521, Avg. loss: 647547.226608\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2026492, Avg. loss: 647547.226608\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2065463, Avg. loss: 647547.226608\n",
      "Total training time: 0.20 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2104434, Avg. loss: 647547.226608\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2143405, Avg. loss: 647547.226608\n",
      "Total training time: 0.21 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2182376, Avg. loss: 647547.226608\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2221347, Avg. loss: 647547.226608\n",
      "Total training time: 0.22 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2260318, Avg. loss: 647547.226608\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2299289, Avg. loss: 647547.226608\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2338260, Avg. loss: 647547.226608\n",
      "Total training time: 0.23 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2377231, Avg. loss: 647547.226608\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2416202, Avg. loss: 647547.226608\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2455173, Avg. loss: 647547.226608\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2494144, Avg. loss: 647547.226608\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2533115, Avg. loss: 647547.226608\n",
      "Total training time: 0.25 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2572086, Avg. loss: 647547.226608\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2611057, Avg. loss: 647547.226608\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2650028, Avg. loss: 647547.226608\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2688999, Avg. loss: 647547.226608\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2727970, Avg. loss: 647547.226608\n",
      "Total training time: 0.27 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2766941, Avg. loss: 647547.226608\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2805912, Avg. loss: 647547.226608\n",
      "Total training time: 0.28 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2844883, Avg. loss: 647547.226608\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2883854, Avg. loss: 647547.226608\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2922825, Avg. loss: 647547.226608\n",
      "Total training time: 0.29 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 2961796, Avg. loss: 647547.226608\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3000767, Avg. loss: 647547.226608\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3039738, Avg. loss: 647547.226608\n",
      "Total training time: 0.30 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3078709, Avg. loss: 647547.226608\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3117680, Avg. loss: 647547.226608\n",
      "Total training time: 0.31 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3156651, Avg. loss: 647547.226608\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3195622, Avg. loss: 647547.226608\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3234593, Avg. loss: 647547.226608\n",
      "Total training time: 0.32 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3273564, Avg. loss: 647547.226608\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3312535, Avg. loss: 647547.226608\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3351506, Avg. loss: 647547.226608\n",
      "Total training time: 0.33 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3390477, Avg. loss: 647547.226608\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3429448, Avg. loss: 647547.226608\n",
      "Total training time: 0.34 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3468419, Avg. loss: 647547.226608\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3507390, Avg. loss: 647547.226608\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3546361, Avg. loss: 647547.226608\n",
      "Total training time: 0.35 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3585332, Avg. loss: 647547.226608\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3624303, Avg. loss: 647547.226608\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3663274, Avg. loss: 647547.226608\n",
      "Total training time: 0.36 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3702245, Avg. loss: 647547.226608\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3741216, Avg. loss: 647547.226608\n",
      "Total training time: 0.37 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3780187, Avg. loss: 647547.226608\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3819158, Avg. loss: 647547.226608\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3858129, Avg. loss: 647547.226608\n",
      "Total training time: 0.38 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 9025.37, NNZs: 26, Bias: 0.000000, T: 3897100, Avg. loss: 647547.226608\n",
      "Total training time: 0.39 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.001,\n",
       "       fit_intercept=False, l1_ratio=0.15, learning_rate='constant',\n",
       "       loss='squared_loss', max_iter=100, n_iter=None, penalty='None',\n",
       "       power_t=0.25, random_state=None, shuffle=False, tol=None,\n",
       "       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train_norm, y_train, coef_init=initial_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation_pred_SKlearn = clf.predict(x_validation_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.921402156170207"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_validation, y_validation_pred_SKlearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744.1835304252023"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(y_validation, y_validation_pred_SKlearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "def SGD(theta, x, y, learning_rate, iterations):\n",
    "    m = x.shape[0]\n",
    "    fig = plt.figure(1)\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Average Cost')\n",
    "    plt.ion()\n",
    "    plt.show()\n",
    "    for i in range(1,iterations+1):\n",
    "        iter_total_cost = 0\n",
    "        for item,price in zip(x.values, y.values):\n",
    "            y_pred = np.dot(item, theta)\n",
    "            loss = y_pred - price\n",
    "            cost = np.sum(loss ** 2)/2\n",
    "            gradient = np.dot(item.transpose(), loss)\n",
    "            theta = theta - learning_rate * gradient\n",
    "            iter_total_cost += cost\n",
    "        iter_average_cost = iter_total_cost/m\n",
    "        print(\"Epoch {}\".format(i))\n",
    "        print(iter_average_cost)\n",
    "        plt.scatter(i,iter_average_cost, c='b')\n",
    "        fig.canvas.draw()\n",
    "        plt.pause(0.0001)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "631767.6484996347\n",
      "Epoch 2\n",
      "630459.2046998414\n",
      "Epoch 3\n",
      "630143.1666578399\n",
      "Epoch 4\n",
      "630015.0712351819\n",
      "Epoch 5\n",
      "629941.4009434943\n",
      "Epoch 6\n",
      "629888.386126996\n",
      "Epoch 7\n",
      "629845.2440409795\n",
      "Epoch 8\n",
      "629807.7946975959\n",
      "Epoch 9\n",
      "629774.081457055\n",
      "Epoch 10\n",
      "629743.0305123472\n",
      "Epoch 11\n",
      "629713.9840586449\n",
      "Epoch 12\n",
      "629686.5105479095\n",
      "Epoch 13\n",
      "629660.3139383305\n",
      "Epoch 14\n",
      "629635.1841255666\n",
      "Epoch 15\n",
      "629610.9674447296\n",
      "Epoch 16\n",
      "629587.5482564488\n",
      "Epoch 17\n",
      "629564.8371457098\n",
      "Epoch 18\n",
      "629542.7632286806\n",
      "Epoch 19\n",
      "629521.2690617691\n",
      "Epoch 20\n",
      "629500.3072160615\n",
      "Epoch 21\n",
      "629479.8379254126\n",
      "Epoch 22\n",
      "629459.8274326269\n",
      "Epoch 23\n",
      "629440.2467946174\n",
      "Epoch 24\n",
      "629421.0709941913\n",
      "Epoch 25\n",
      "629402.2782609423\n",
      "Epoch 26\n",
      "629383.849538435\n",
      "Epoch 27\n",
      "629365.7680567506\n",
      "Epoch 28\n",
      "629348.018983298\n",
      "Epoch 29\n",
      "629330.5891336162\n",
      "Epoch 30\n",
      "629313.4667293406\n",
      "Epoch 31\n",
      "629296.641194253\n",
      "Epoch 32\n",
      "629280.1029815715\n",
      "Epoch 33\n",
      "629263.843427253\n",
      "Epoch 34\n",
      "629247.8546252493\n",
      "Epoch 35\n",
      "629232.1293212608\n",
      "Epoch 36\n",
      "629216.6608222916\n",
      "Epoch 37\n",
      "629201.4429196521\n",
      "Epoch 38\n",
      "629186.4698234495\n",
      "Epoch 39\n",
      "629171.7361068408\n",
      "Epoch 40\n",
      "629157.2366586698\n",
      "Epoch 41\n",
      "629142.9666432207\n",
      "Epoch 42\n",
      "629128.9214660334\n",
      "Epoch 43\n",
      "629115.09674487\n",
      "Epoch 44\n",
      "629101.4882850532\n",
      "Epoch 45\n",
      "629088.0920585564\n",
      "Epoch 46\n",
      "629074.9041861942\n",
      "Epoch 47\n",
      "629061.9209225082\n",
      "Epoch 48\n",
      "629049.1386428934\n",
      "Epoch 49\n",
      "629036.5538326234\n",
      "Epoch 50\n",
      "629024.1630774925\n",
      "Epoch 51\n",
      "629011.9630558081\n",
      "Epoch 52\n",
      "628999.9505315125\n",
      "Epoch 53\n",
      "628988.1223482746\n",
      "Epoch 54\n",
      "628976.4754244024\n",
      "Epoch 55\n",
      "628965.0067484013\n",
      "Epoch 56\n",
      "628953.713375158\n",
      "Epoch 57\n",
      "628942.5924225502\n",
      "Epoch 58\n",
      "628931.641068513\n",
      "Epoch 59\n",
      "628920.8565484086\n",
      "Epoch 60\n",
      "628910.2361527099\n",
      "Epoch 61\n",
      "628899.7772249307\n",
      "Epoch 62\n",
      "628889.4771597201\n",
      "Epoch 63\n",
      "628879.3334012077\n",
      "Epoch 64\n",
      "628869.3434414093\n",
      "Epoch 65\n",
      "628859.5048188391\n",
      "Epoch 66\n",
      "628849.815117164\n",
      "Epoch 67\n",
      "628840.2719640097\n",
      "Epoch 68\n",
      "628830.87302978\n",
      "Epoch 69\n",
      "628821.6160266224\n",
      "Epoch 70\n",
      "628812.4987073847\n",
      "Epoch 71\n",
      "628803.5188646577\n",
      "Epoch 72\n",
      "628794.6743298639\n",
      "Epoch 73\n",
      "628785.9629723831\n",
      "Epoch 74\n",
      "628777.3826987024\n",
      "Epoch 75\n",
      "628768.9314516297\n",
      "Epoch 76\n",
      "628760.6072094785\n",
      "Epoch 77\n",
      "628752.4079853706\n",
      "Epoch 78\n",
      "628744.331826461\n",
      "Epoch 79\n",
      "628736.3768132695\n",
      "Epoch 80\n",
      "628728.5410589695\n",
      "Epoch 81\n",
      "628720.8227087543\n",
      "Epoch 82\n",
      "628713.2199391795\n",
      "Epoch 83\n",
      "628705.7309575361\n",
      "Epoch 84\n",
      "628698.3540012464\n",
      "Epoch 85\n",
      "628691.0873372636\n",
      "Epoch 86\n",
      "628683.9292614959\n",
      "Epoch 87\n",
      "628676.878098254\n",
      "Epoch 88\n",
      "628669.9321996775\n",
      "Epoch 89\n",
      "628663.0899452225\n",
      "Epoch 90\n",
      "628656.3497411205\n",
      "Epoch 91\n",
      "628649.7100198786\n",
      "Epoch 92\n",
      "628643.169239776\n",
      "Epoch 93\n",
      "628636.7258843682\n",
      "Epoch 94\n",
      "628630.3784620302\n",
      "Epoch 95\n",
      "628624.1255054644\n",
      "Epoch 96\n",
      "628617.9655712877\n",
      "Epoch 97\n",
      "628611.8972395342\n",
      "Epoch 98\n",
      "628605.9191132609\n",
      "Epoch 99\n",
      "628600.0298181119\n",
      "Epoch 100\n",
      "628594.2280018991\n"
     ]
    }
   ],
   "source": [
    "theta_sgd = SGD(initial_theta, x_validation_norm, y_validation,learning_rate, iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation_pred_our = np.dot(theta_sgd, np.transpose(x_validation_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9221993843447939"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.r2_score(y_validation, y_validation_pred_our)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739.938566964176"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_absolute_error(y_validation, y_validation_pred_our)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sfm = SelectFromModel(clf, prefit=True)\n",
    "feature_mask = model_sfm.get_support()\n",
    "feature_name = np.array(x_train_norm.columns)\n",
    "print(np.array(feature_name)[feature_mask==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_selected = model_sfm.transform(x_train_norm)\n",
    "x_test_selected = model_sfm.transform(x_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(x_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test_selected, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
