{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorflow version: 1.12.0-rc0\n",
    "scikit-learn version: 0.17\n",
    "keras version: 2.2.4\n",
    "tensorboard version: 1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "In this assignment, we will use the weights of a network pre-trained in a particular problem as starting point to train our CNN to a different problem. As training a network from scratch is time-consuming and demands a lot of data, this is a frequent strategy, specially if both datasets (the one used for pre-training and the target) shares similar structures/elements/concepts. \n",
    "\n",
    "This is specially true when working with images. Most filters learned in initial convolutional layers will detect low-level elements, such as borders, corners and color blobs, which are common to most problems in the image domain. \n",
    "\n",
    "In this notebook, we will load the SqueezeNet architecture trained in the ImageNet dataset and fine-tune it to CIFAR-10.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "#Utility to plot\n",
    "def plotImages(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "        \n",
    "        \n",
    "def plotImage(img):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.imshow(np.uint8(img), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.callbacks as callbacks\n",
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./tensorboard/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SqueezeNet definition\n",
    "These methods define our architecture and load the weights obtained using ImageNet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Module Definition\n",
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "#SqueezeNet model definition\n",
    "def SqueezeNet(input_shape):\n",
    "    img_input = Input(shape=input_shape) #placeholder\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(1000, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    # Download and load ImageNet weights\n",
    "    model.load_weights('./squeezenet_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The class are **airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val data. X:  (50000, 32, 32, 3) , Y:  (50000, 1)\n",
      "Test data. X:  (10000, 32, 32, 3) , Y:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "(trainVal_data, trainVal_label), (X_test, y_test) = cifar10.load_data()\n",
    "print(\"Train/Val data. X: \", trainVal_data.shape, \", Y: \", trainVal_label.shape)\n",
    "print(\"Test data. X: \", X_test.shape, \", Y: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainVal_label = to_categorical(trainVal_label)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainVal_data, trainVal_label, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## SqueezeNet with frozen layers\n",
    "Our initial attempt will be to remove SqueezeNet's top layers --- responsible for the classification into ImageNet classes --- and train a new set of layers to our CIFAR-10 classes. We will also freeze the layers before `drop9`. Our architecture will be like this:\n",
    "\n",
    "<img src=\"frozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezeNetModel = SqueezeNet((32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new classification layers\n",
    "x = squeezeNetModel.layers[-5].output\n",
    "x = Convolution2D(10, (1, 1), padding='valid', name='new_conv10')(x)\n",
    "x = Activation('relu', name='new_relu_conv10')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='new_loss')(x)\n",
    "\n",
    "#new Model\n",
    "model = Model(squeezeNetModel.inputs, x, name='squeezenet_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "new_conv10 (Conv2D)             (None, 1, 1, 10)     5130        drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "new_relu_conv10 (Activation)    (None, 1, 1, 10)     0           new_conv10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 10)           0           new_relu_conv10[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "new_loss (Activation)           (None, 10)           0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 727,626\n",
      "Trainable params: 727,626\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "conv1 False\n",
      "relu_conv1 False\n",
      "pool1 False\n",
      "fire2/squeeze1x1 False\n",
      "fire2/relu_squeeze1x1 False\n",
      "fire2/expand1x1 False\n",
      "fire2/expand3x3 False\n",
      "fire2/relu_expand1x1 False\n",
      "fire2/relu_expand3x3 False\n",
      "fire2/concat False\n",
      "fire3/squeeze1x1 False\n",
      "fire3/relu_squeeze1x1 False\n",
      "fire3/expand1x1 False\n",
      "fire3/expand3x3 False\n",
      "fire3/relu_expand1x1 False\n",
      "fire3/relu_expand3x3 False\n",
      "fire3/concat False\n",
      "pool3 False\n",
      "fire4/squeeze1x1 False\n",
      "fire4/relu_squeeze1x1 False\n",
      "fire4/expand1x1 False\n",
      "fire4/expand3x3 False\n",
      "fire4/relu_expand1x1 False\n",
      "fire4/relu_expand3x3 False\n",
      "fire4/concat False\n",
      "fire5/squeeze1x1 False\n",
      "fire5/relu_squeeze1x1 False\n",
      "fire5/expand1x1 False\n",
      "fire5/expand3x3 False\n",
      "fire5/relu_expand1x1 False\n",
      "fire5/relu_expand3x3 False\n",
      "fire5/concat False\n",
      "pool5 False\n",
      "fire6/squeeze1x1 False\n",
      "fire6/relu_squeeze1x1 False\n",
      "fire6/expand1x1 False\n",
      "fire6/expand3x3 False\n",
      "fire6/relu_expand1x1 False\n",
      "fire6/relu_expand3x3 False\n",
      "fire6/concat False\n",
      "fire7/squeeze1x1 False\n",
      "fire7/relu_squeeze1x1 False\n",
      "fire7/expand1x1 False\n",
      "fire7/expand3x3 False\n",
      "fire7/relu_expand1x1 False\n",
      "fire7/relu_expand3x3 False\n",
      "fire7/concat False\n",
      "fire8/squeeze1x1 False\n",
      "fire8/relu_squeeze1x1 False\n",
      "fire8/expand1x1 False\n",
      "fire8/expand3x3 False\n",
      "fire8/relu_expand1x1 False\n",
      "fire8/relu_expand3x3 False\n",
      "fire8/concat False\n",
      "fire9/squeeze1x1 False\n",
      "fire9/relu_squeeze1x1 False\n",
      "fire9/expand1x1 False\n",
      "fire9/expand3x3 False\n",
      "fire9/relu_expand1x1 False\n",
      "fire9/relu_expand3x3 False\n",
      "fire9/concat False\n",
      "drop9 True\n",
      "conv10 True\n",
      "relu_conv10 True\n",
      "global_average_pooling2d_1 True\n",
      "loss True\n"
     ]
    }
   ],
   "source": [
    "#freeze layers\n",
    "for layer in model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in squeezeNetModel.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeezeNetModel.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "# squeezeNetModel.fit(trainVal_data, trainVal_label, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1000)\n",
      "(?, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'drop9'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(squeezeNetModel.output.shape)\n",
    "print(model.output.shape)\n",
    "squeezeNetModel.layers[-5].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-4].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1094/1093 [==============================] - 19s 18ms/step - loss: 2.2950 - acc: 0.1486 - val_loss: 2.1986 - val_acc: 0.2600\n",
      "Epoch 2/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.1629 - acc: 0.2338 - val_loss: 2.0264 - val_acc: 0.3125\n",
      "Epoch 3/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0405 - acc: 0.2776 - val_loss: 1.9241 - val_acc: 0.3570\n",
      "Epoch 4/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.9666 - acc: 0.3097 - val_loss: 1.8429 - val_acc: 0.3795\n",
      "Epoch 5/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.8980 - acc: 0.3285 - val_loss: 1.7885 - val_acc: 0.3963\n",
      "Epoch 6/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.8614 - acc: 0.3370 - val_loss: 1.7574 - val_acc: 0.4037\n",
      "Epoch 7/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.8388 - acc: 0.3484 - val_loss: 1.7352 - val_acc: 0.4103\n",
      "Epoch 8/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.8210 - acc: 0.3510 - val_loss: 1.7187 - val_acc: 0.4155\n",
      "Epoch 9/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.8076 - acc: 0.3557 - val_loss: 1.7045 - val_acc: 0.4132\n",
      "Epoch 10/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7995 - acc: 0.3587 - val_loss: 1.6940 - val_acc: 0.4179\n",
      "Epoch 11/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7861 - acc: 0.3643 - val_loss: 1.6805 - val_acc: 0.4229\n",
      "Epoch 12/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7779 - acc: 0.3675 - val_loss: 1.6780 - val_acc: 0.4219\n",
      "Epoch 13/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7743 - acc: 0.3702 - val_loss: 1.6699 - val_acc: 0.4247\n",
      "Epoch 14/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7658 - acc: 0.3720 - val_loss: 1.6627 - val_acc: 0.4269\n",
      "Epoch 15/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7635 - acc: 0.3734 - val_loss: 1.6548 - val_acc: 0.4287\n",
      "Epoch 16/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7602 - acc: 0.3734 - val_loss: 1.6528 - val_acc: 0.4283\n",
      "Epoch 17/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7545 - acc: 0.3702 - val_loss: 1.6491 - val_acc: 0.4287\n",
      "Epoch 18/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7562 - acc: 0.3766 - val_loss: 1.6460 - val_acc: 0.4270\n",
      "Epoch 19/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7502 - acc: 0.3760 - val_loss: 1.6388 - val_acc: 0.4357\n",
      "Epoch 20/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7441 - acc: 0.3781 - val_loss: 1.6360 - val_acc: 0.4339\n",
      "Epoch 21/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7466 - acc: 0.3769 - val_loss: 1.6323 - val_acc: 0.4319\n",
      "Epoch 22/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7450 - acc: 0.3794 - val_loss: 1.6341 - val_acc: 0.4304\n",
      "Epoch 23/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7432 - acc: 0.3799 - val_loss: 1.6315 - val_acc: 0.4320\n",
      "Epoch 24/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7400 - acc: 0.3789 - val_loss: 1.6288 - val_acc: 0.4311\n",
      "Epoch 25/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7373 - acc: 0.3809 - val_loss: 1.6277 - val_acc: 0.4359\n",
      "Epoch 26/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7368 - acc: 0.3841 - val_loss: 1.6224 - val_acc: 0.4357\n",
      "Epoch 27/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7396 - acc: 0.3803 - val_loss: 1.6202 - val_acc: 0.4369\n",
      "Epoch 28/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7355 - acc: 0.3809 - val_loss: 1.6173 - val_acc: 0.4371\n",
      "Epoch 29/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7332 - acc: 0.3807 - val_loss: 1.6204 - val_acc: 0.4325\n",
      "Epoch 30/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7325 - acc: 0.3826 - val_loss: 1.6177 - val_acc: 0.4319\n",
      "Epoch 31/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7276 - acc: 0.3852 - val_loss: 1.6155 - val_acc: 0.4367\n",
      "Epoch 32/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7293 - acc: 0.3809 - val_loss: 1.6145 - val_acc: 0.4359\n",
      "Epoch 33/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7340 - acc: 0.3811 - val_loss: 1.6152 - val_acc: 0.4393\n",
      "Epoch 34/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7272 - acc: 0.3841 - val_loss: 1.6113 - val_acc: 0.4372\n",
      "Epoch 35/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7279 - acc: 0.3853 - val_loss: 1.6088 - val_acc: 0.4387\n",
      "Epoch 36/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7294 - acc: 0.3828 - val_loss: 1.6096 - val_acc: 0.4403\n",
      "Epoch 37/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7222 - acc: 0.3849 - val_loss: 1.6085 - val_acc: 0.4397\n",
      "Epoch 38/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7245 - acc: 0.3859 - val_loss: 1.6075 - val_acc: 0.4425\n",
      "Epoch 39/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7238 - acc: 0.3852 - val_loss: 1.6070 - val_acc: 0.4373\n",
      "Epoch 40/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7260 - acc: 0.3821 - val_loss: 1.6049 - val_acc: 0.4407\n",
      "Epoch 41/100\n",
      "1094/1093 [==============================] - 14s 13ms/step - loss: 1.7205 - acc: 0.3857 - val_loss: 1.6075 - val_acc: 0.4371\n",
      "Epoch 42/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7233 - acc: 0.3860 - val_loss: 1.6053 - val_acc: 0.4396\n",
      "Epoch 43/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7272 - acc: 0.3838 - val_loss: 1.6048 - val_acc: 0.4425\n",
      "Epoch 44/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7209 - acc: 0.3842 - val_loss: 1.6016 - val_acc: 0.4372\n",
      "Epoch 45/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7259 - acc: 0.3836 - val_loss: 1.6026 - val_acc: 0.4401\n",
      "Epoch 46/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7179 - acc: 0.3839 - val_loss: 1.6018 - val_acc: 0.4417\n",
      "Epoch 47/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7190 - acc: 0.3854 - val_loss: 1.6009 - val_acc: 0.4431\n",
      "Epoch 48/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7221 - acc: 0.3873 - val_loss: 1.6002 - val_acc: 0.4399\n",
      "Epoch 49/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7157 - acc: 0.3867 - val_loss: 1.5979 - val_acc: 0.4408\n",
      "Epoch 50/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7140 - acc: 0.3871 - val_loss: 1.5994 - val_acc: 0.4433\n",
      "Epoch 51/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7157 - acc: 0.3878 - val_loss: 1.5995 - val_acc: 0.4421\n",
      "Epoch 52/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7166 - acc: 0.3876 - val_loss: 1.5984 - val_acc: 0.4443\n",
      "Epoch 53/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7155 - acc: 0.3867 - val_loss: 1.5980 - val_acc: 0.4439\n",
      "Epoch 54/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7131 - acc: 0.3841 - val_loss: 1.5970 - val_acc: 0.4409\n",
      "Epoch 55/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7188 - acc: 0.3839 - val_loss: 1.5964 - val_acc: 0.4429\n",
      "Epoch 56/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7201 - acc: 0.3851 - val_loss: 1.5945 - val_acc: 0.4445\n",
      "Epoch 57/100\n",
      "1094/1093 [==============================] - 16s 15ms/step - loss: 1.7180 - acc: 0.3880 - val_loss: 1.5951 - val_acc: 0.4436\n",
      "Epoch 58/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7148 - acc: 0.3856 - val_loss: 1.5928 - val_acc: 0.4451\n",
      "Epoch 59/100\n",
      "1094/1093 [==============================] - 17s 15ms/step - loss: 1.7109 - acc: 0.3861 - val_loss: 1.5921 - val_acc: 0.4450\n",
      "Epoch 60/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7170 - acc: 0.3874 - val_loss: 1.5940 - val_acc: 0.4450\n",
      "Epoch 61/100\n",
      "1094/1093 [==============================] - 17s 15ms/step - loss: 1.7156 - acc: 0.3877 - val_loss: 1.5918 - val_acc: 0.4468\n",
      "Epoch 62/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7108 - acc: 0.3896 - val_loss: 1.5960 - val_acc: 0.4429\n",
      "Epoch 63/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7175 - acc: 0.3859 - val_loss: 1.5948 - val_acc: 0.4421\n",
      "Epoch 64/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7130 - acc: 0.3873 - val_loss: 1.5960 - val_acc: 0.4399\n",
      "Epoch 65/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7131 - acc: 0.3879 - val_loss: 1.5937 - val_acc: 0.4437\n",
      "Epoch 66/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7175 - acc: 0.3863 - val_loss: 1.5961 - val_acc: 0.4387\n",
      "Epoch 67/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7169 - acc: 0.3875 - val_loss: 1.5936 - val_acc: 0.4444\n",
      "Epoch 68/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7084 - acc: 0.3893 - val_loss: 1.5935 - val_acc: 0.4420\n",
      "Epoch 69/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7119 - acc: 0.3903 - val_loss: 1.5939 - val_acc: 0.4421\n",
      "Epoch 70/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7132 - acc: 0.3889 - val_loss: 1.5927 - val_acc: 0.4415\n",
      "Epoch 71/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7128 - acc: 0.3889 - val_loss: 1.5925 - val_acc: 0.4433\n",
      "Epoch 72/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7146 - acc: 0.3888 - val_loss: 1.5856 - val_acc: 0.4431\n",
      "Epoch 73/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7155 - acc: 0.3870 - val_loss: 1.5905 - val_acc: 0.4427\n",
      "Epoch 74/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7118 - acc: 0.3895 - val_loss: 1.5914 - val_acc: 0.4423\n",
      "Epoch 75/100\n",
      "1094/1093 [==============================] - 17s 15ms/step - loss: 1.7131 - acc: 0.3857 - val_loss: 1.5881 - val_acc: 0.4459\n",
      "Epoch 76/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7128 - acc: 0.3869 - val_loss: 1.5917 - val_acc: 0.4454\n",
      "Epoch 77/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7093 - acc: 0.3886 - val_loss: 1.5875 - val_acc: 0.4444\n",
      "Epoch 78/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7096 - acc: 0.3881 - val_loss: 1.5904 - val_acc: 0.4434\n",
      "Epoch 79/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7093 - acc: 0.3878 - val_loss: 1.5897 - val_acc: 0.4443\n",
      "Epoch 80/100\n",
      "1094/1093 [==============================] - 17s 15ms/step - loss: 1.7100 - acc: 0.3884 - val_loss: 1.5884 - val_acc: 0.4445\n",
      "Epoch 81/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7089 - acc: 0.3893 - val_loss: 1.5871 - val_acc: 0.4445\n",
      "Epoch 82/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7111 - acc: 0.3870 - val_loss: 1.5910 - val_acc: 0.4423\n",
      "Epoch 83/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7106 - acc: 0.3918 - val_loss: 1.5889 - val_acc: 0.4467\n",
      "Epoch 84/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7104 - acc: 0.3862 - val_loss: 1.5876 - val_acc: 0.4463\n",
      "Epoch 85/100\n",
      "1094/1093 [==============================] - 17s 15ms/step - loss: 1.7024 - acc: 0.3934 - val_loss: 1.5850 - val_acc: 0.4471\n",
      "Epoch 86/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7136 - acc: 0.3872 - val_loss: 1.5844 - val_acc: 0.4459\n",
      "Epoch 87/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7112 - acc: 0.3889 - val_loss: 1.5867 - val_acc: 0.4430\n",
      "Epoch 88/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 1.7038 - acc: 0.3907 - val_loss: 1.5889 - val_acc: 0.4413\n",
      "Epoch 89/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 1.7119 - acc: 0.3894 - val_loss: 1.5885 - val_acc: 0.4421\n",
      "Epoch 90/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 1.7110 - acc: 0.3882 - val_loss: 1.5842 - val_acc: 0.4445\n",
      "Epoch 91/100\n",
      "1094/1093 [==============================] - 13s 11ms/step - loss: 1.7123 - acc: 0.3864 - val_loss: 1.5872 - val_acc: 0.4447\n",
      "Epoch 92/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 1.7066 - acc: 0.3894 - val_loss: 1.5872 - val_acc: 0.4485\n",
      "Epoch 93/100\n",
      "1094/1093 [==============================] - 13s 11ms/step - loss: 1.7058 - acc: 0.3883 - val_loss: 1.5860 - val_acc: 0.4448\n",
      "Epoch 94/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 1.7100 - acc: 0.3879 - val_loss: 1.5898 - val_acc: 0.4419\n",
      "Epoch 95/100\n",
      "1094/1093 [==============================] - 13s 11ms/step - loss: 1.7088 - acc: 0.3906 - val_loss: 1.5834 - val_acc: 0.4481\n",
      "Epoch 96/100\n",
      "1094/1093 [==============================] - 13s 11ms/step - loss: 1.7112 - acc: 0.3861 - val_loss: 1.5846 - val_acc: 0.4479\n",
      "Epoch 97/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 1.7096 - acc: 0.3906 - val_loss: 1.5864 - val_acc: 0.4453\n",
      "Epoch 98/100\n",
      "1094/1093 [==============================] - 13s 11ms/step - loss: 1.7090 - acc: 0.3888 - val_loss: 1.5877 - val_acc: 0.4461\n",
      "Epoch 99/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 1.7033 - acc: 0.3886 - val_loss: 1.5837 - val_acc: 0.4468\n",
      "Epoch 100/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 1.7071 - acc: 0.3889 - val_loss: 1.5866 - val_acc: 0.4455\n"
     ]
    }
   ],
   "source": [
    "# Compile model and train it.\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr = 0.0001), metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size_val), validation_data=datagen.flow(X_val, y_val, batch_size=batch_size_val), steps_per_epoch=len(X_train) / batch_size_val, epochs=100, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.5857155921300252, 0.44633333331743874]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation:\n",
    "# ...\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate_generator(datagen.flow(X_val, y_val, batch_size=batch_size_val), steps=len(X_val)/batch_size_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
