{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorflow version: 1.12.0-rc0\n",
    "scikit-learn version: 0.17\n",
    "keras version: 2.2.4\n",
    "tensorboard version: 1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "In this assignment, we will use the weights of a network pre-trained in a particular problem as starting point to train our CNN to a different problem. As training a network from scratch is time-consuming and demands a lot of data, this is a frequent strategy, specially if both datasets (the one used for pre-training and the target) shares similar structures/elements/concepts. \n",
    "\n",
    "This is specially true when working with images. Most filters learned in initial convolutional layers will detect low-level elements, such as borders, corners and color blobs, which are common to most problems in the image domain. \n",
    "\n",
    "In this notebook, we will load the SqueezeNet architecture trained in the ImageNet dataset and fine-tune it to CIFAR-10.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "#Utility to plot\n",
    "def plotImages(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "        \n",
    "        \n",
    "def plotImage(img):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.imshow(np.uint8(img), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.callbacks as callbacks\n",
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./tensorboard/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SqueezeNet definition\n",
    "These methods define our architecture and load the weights obtained using ImageNet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Module Definition\n",
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "#SqueezeNet model definition\n",
    "def SqueezeNet(input_shape):\n",
    "    img_input = Input(shape=input_shape) #placeholder\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(1000, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    # Download and load ImageNet weights\n",
    "    model.load_weights('./squeezenet_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The class are **airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val data. X:  (50000, 32, 32, 3) , Y:  (50000, 1)\n",
      "Test data. X:  (10000, 32, 32, 3) , Y:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "(trainVal_data, trainVal_label), (X_test, y_test) = cifar10.load_data()\n",
    "print(\"Train/Val data. X: \", trainVal_data.shape, \", Y: \", trainVal_label.shape)\n",
    "print(\"Test data. X: \", X_test.shape, \", Y: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainVal_label = to_categorical(trainVal_label)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainVal_data, trainVal_label, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## SqueezeNet with frozen layers\n",
    "Our initial attempt will be to remove SqueezeNet's top layers --- responsible for the classification into ImageNet classes --- and train a new set of layers to our CIFAR-10 classes. We will also freeze the layers before `drop9`. Our architecture will be like this:\n",
    "\n",
    "<img src=\"frozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezeNetModel = SqueezeNet((32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new classification layers\n",
    "x = squeezeNetModel.layers[-5].output\n",
    "x = Convolution2D(10, (1, 1), padding='valid', name='new_conv10')(x)\n",
    "x = Activation('relu', name='new_relu_conv10')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='new_loss')(x)\n",
    "\n",
    "#new Model\n",
    "model = Model(squeezeNetModel.inputs, x, name='squeezenet_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "new_conv10 (Conv2D)             (None, 1, 1, 10)     5130        drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "new_relu_conv10 (Activation)    (None, 1, 1, 10)     0           new_conv10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 10)           0           new_relu_conv10[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "new_loss (Activation)           (None, 10)           0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 727,626\n",
      "Trainable params: 727,626\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "conv1 False\n",
      "relu_conv1 False\n",
      "pool1 False\n",
      "fire2/squeeze1x1 False\n",
      "fire2/relu_squeeze1x1 False\n",
      "fire2/expand1x1 False\n",
      "fire2/expand3x3 False\n",
      "fire2/relu_expand1x1 False\n",
      "fire2/relu_expand3x3 False\n",
      "fire2/concat False\n",
      "fire3/squeeze1x1 False\n",
      "fire3/relu_squeeze1x1 False\n",
      "fire3/expand1x1 False\n",
      "fire3/expand3x3 False\n",
      "fire3/relu_expand1x1 False\n",
      "fire3/relu_expand3x3 False\n",
      "fire3/concat False\n",
      "pool3 False\n",
      "fire4/squeeze1x1 False\n",
      "fire4/relu_squeeze1x1 False\n",
      "fire4/expand1x1 False\n",
      "fire4/expand3x3 False\n",
      "fire4/relu_expand1x1 False\n",
      "fire4/relu_expand3x3 False\n",
      "fire4/concat False\n",
      "fire5/squeeze1x1 False\n",
      "fire5/relu_squeeze1x1 False\n",
      "fire5/expand1x1 False\n",
      "fire5/expand3x3 False\n",
      "fire5/relu_expand1x1 False\n",
      "fire5/relu_expand3x3 False\n",
      "fire5/concat False\n",
      "pool5 False\n",
      "fire6/squeeze1x1 False\n",
      "fire6/relu_squeeze1x1 False\n",
      "fire6/expand1x1 False\n",
      "fire6/expand3x3 False\n",
      "fire6/relu_expand1x1 False\n",
      "fire6/relu_expand3x3 False\n",
      "fire6/concat False\n",
      "fire7/squeeze1x1 False\n",
      "fire7/relu_squeeze1x1 False\n",
      "fire7/expand1x1 False\n",
      "fire7/expand3x3 False\n",
      "fire7/relu_expand1x1 False\n",
      "fire7/relu_expand3x3 False\n",
      "fire7/concat False\n",
      "fire8/squeeze1x1 False\n",
      "fire8/relu_squeeze1x1 False\n",
      "fire8/expand1x1 False\n",
      "fire8/expand3x3 False\n",
      "fire8/relu_expand1x1 False\n",
      "fire8/relu_expand3x3 False\n",
      "fire8/concat False\n",
      "fire9/squeeze1x1 False\n",
      "fire9/relu_squeeze1x1 False\n",
      "fire9/expand1x1 False\n",
      "fire9/expand3x3 False\n",
      "fire9/relu_expand1x1 False\n",
      "fire9/relu_expand3x3 False\n",
      "fire9/concat False\n",
      "drop9 True\n",
      "conv10 True\n",
      "relu_conv10 True\n",
      "global_average_pooling2d_1 True\n",
      "loss True\n"
     ]
    }
   ],
   "source": [
    "#freeze layers\n",
    "for layer in model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in squeezeNetModel.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeezeNetModel.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "# squeezeNetModel.fit(trainVal_data, trainVal_label, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1000)\n",
      "(?, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'drop9'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(squeezeNetModel.output.shape)\n",
    "print(model.output.shape)\n",
    "squeezeNetModel.layers[-5].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-4].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1094/1093 [==============================] - 15s 13ms/step - loss: 2.2946 - acc: 0.1465 - val_loss: 2.2277 - val_acc: 0.2440\n",
      "Epoch 2/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.2051 - acc: 0.2242 - val_loss: 2.1429 - val_acc: 0.2809\n",
      "Epoch 3/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.1537 - acc: 0.2541 - val_loss: 2.0883 - val_acc: 0.3006\n",
      "Epoch 4/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.1258 - acc: 0.2678 - val_loss: 2.0594 - val_acc: 0.3157\n",
      "Epoch 5/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.1000 - acc: 0.2809 - val_loss: 2.0381 - val_acc: 0.3225\n",
      "Epoch 6/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0836 - acc: 0.2892 - val_loss: 2.0255 - val_acc: 0.3289\n",
      "Epoch 7/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0725 - acc: 0.2965 - val_loss: 2.0200 - val_acc: 0.3299\n",
      "Epoch 8/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0681 - acc: 0.2951 - val_loss: 2.0086 - val_acc: 0.3348\n",
      "Epoch 9/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0627 - acc: 0.2984 - val_loss: 2.0047 - val_acc: 0.3351\n",
      "Epoch 10/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0555 - acc: 0.3004 - val_loss: 2.0000 - val_acc: 0.3349\n",
      "Epoch 11/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0519 - acc: 0.3048 - val_loss: 1.9947 - val_acc: 0.3375\n",
      "Epoch 12/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0558 - acc: 0.3018 - val_loss: 1.9931 - val_acc: 0.3359\n",
      "Epoch 13/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0422 - acc: 0.3080 - val_loss: 1.9896 - val_acc: 0.3367\n",
      "Epoch 14/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0499 - acc: 0.3052 - val_loss: 1.9859 - val_acc: 0.3395\n",
      "Epoch 15/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0433 - acc: 0.3078 - val_loss: 1.9843 - val_acc: 0.3393\n",
      "Epoch 16/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0373 - acc: 0.3079 - val_loss: 1.9831 - val_acc: 0.3421\n",
      "Epoch 17/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0410 - acc: 0.3078 - val_loss: 1.9817 - val_acc: 0.3413\n",
      "Epoch 18/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0392 - acc: 0.3114 - val_loss: 1.9798 - val_acc: 0.3401\n",
      "Epoch 19/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0377 - acc: 0.3095 - val_loss: 1.9784 - val_acc: 0.3431\n",
      "Epoch 20/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0315 - acc: 0.3131 - val_loss: 1.9741 - val_acc: 0.3461\n",
      "Epoch 21/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0358 - acc: 0.3088 - val_loss: 1.9756 - val_acc: 0.3425\n",
      "Epoch 22/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0356 - acc: 0.3115 - val_loss: 1.9744 - val_acc: 0.3425\n",
      "Epoch 23/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0329 - acc: 0.3121 - val_loss: 1.9745 - val_acc: 0.3413\n",
      "Epoch 24/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0307 - acc: 0.3152 - val_loss: 1.9745 - val_acc: 0.3425\n",
      "Epoch 25/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0326 - acc: 0.3103 - val_loss: 1.9737 - val_acc: 0.3425\n",
      "Epoch 26/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0297 - acc: 0.3137 - val_loss: 1.9684 - val_acc: 0.3449\n",
      "Epoch 27/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0327 - acc: 0.3107 - val_loss: 1.9720 - val_acc: 0.3422\n",
      "Epoch 28/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0279 - acc: 0.3129 - val_loss: 1.9725 - val_acc: 0.3419\n",
      "Epoch 29/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0308 - acc: 0.3101 - val_loss: 1.9717 - val_acc: 0.3438\n",
      "Epoch 30/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0279 - acc: 0.3156 - val_loss: 1.9697 - val_acc: 0.3428\n",
      "Epoch 31/100\n",
      "1094/1093 [==============================] - 13s 11ms/step - loss: 2.0317 - acc: 0.3116 - val_loss: 1.9687 - val_acc: 0.3438\n",
      "Epoch 32/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 2.0312 - acc: 0.3124 - val_loss: 1.9666 - val_acc: 0.3434\n",
      "Epoch 33/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 2.0272 - acc: 0.3138 - val_loss: 1.9731 - val_acc: 0.3406\n",
      "Epoch 34/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 2.0292 - acc: 0.3140 - val_loss: 1.9710 - val_acc: 0.3402\n",
      "Epoch 35/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0316 - acc: 0.3123 - val_loss: 1.9695 - val_acc: 0.3414\n",
      "Epoch 36/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0273 - acc: 0.3123 - val_loss: 1.9650 - val_acc: 0.3437\n",
      "Epoch 37/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0293 - acc: 0.3140 - val_loss: 1.9719 - val_acc: 0.3396\n",
      "Epoch 38/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 2.0296 - acc: 0.3123 - val_loss: 1.9673 - val_acc: 0.3415\n",
      "Epoch 39/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 2.0256 - acc: 0.3143 - val_loss: 1.9675 - val_acc: 0.3421\n",
      "Epoch 40/100\n",
      "1094/1093 [==============================] - 10s 9ms/step - loss: 2.0258 - acc: 0.3127 - val_loss: 1.9672 - val_acc: 0.3417\n",
      "Epoch 41/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 2.0250 - acc: 0.3168 - val_loss: 1.9713 - val_acc: 0.3393\n",
      "Epoch 42/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 2.0242 - acc: 0.3162 - val_loss: 1.9691 - val_acc: 0.3421\n",
      "Epoch 43/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 2.0271 - acc: 0.3127 - val_loss: 1.9702 - val_acc: 0.3406\n",
      "Epoch 44/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 2.0282 - acc: 0.3116 - val_loss: 1.9674 - val_acc: 0.3421\n",
      "Epoch 45/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 2.0267 - acc: 0.3135 - val_loss: 1.9661 - val_acc: 0.3414\n",
      "Epoch 46/100\n",
      "1094/1093 [==============================] - 8s 8ms/step - loss: 2.0264 - acc: 0.3145 - val_loss: 1.9666 - val_acc: 0.3405\n",
      "Epoch 47/100\n",
      "1094/1093 [==============================] - 11s 10ms/step - loss: 2.0256 - acc: 0.3125 - val_loss: 1.9679 - val_acc: 0.3386\n",
      "Epoch 48/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0288 - acc: 0.3096 - val_loss: 1.9663 - val_acc: 0.3393\n",
      "Epoch 49/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0323 - acc: 0.3098 - val_loss: 1.9662 - val_acc: 0.3398\n",
      "Epoch 50/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 2.0291 - acc: 0.3104 - val_loss: 1.9683 - val_acc: 0.3393\n",
      "Epoch 51/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 2.0294 - acc: 0.3099 - val_loss: 1.9662 - val_acc: 0.3411\n",
      "Epoch 52/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 2.0301 - acc: 0.3129 - val_loss: 1.9648 - val_acc: 0.3418\n",
      "Epoch 53/100\n",
      "1094/1093 [==============================] - 13s 11ms/step - loss: 2.0261 - acc: 0.3110 - val_loss: 1.9670 - val_acc: 0.3399\n",
      "Epoch 54/100\n",
      "1094/1093 [==============================] - 12s 11ms/step - loss: 2.0305 - acc: 0.3117 - val_loss: 1.9663 - val_acc: 0.3417\n",
      "Epoch 55/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0291 - acc: 0.3104 - val_loss: 1.9658 - val_acc: 0.3424\n",
      "Epoch 56/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0242 - acc: 0.3117 - val_loss: 1.9666 - val_acc: 0.3401\n",
      "Epoch 57/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0272 - acc: 0.3128 - val_loss: 1.9659 - val_acc: 0.3403\n",
      "Epoch 58/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0278 - acc: 0.3113 - val_loss: 1.9652 - val_acc: 0.3386\n",
      "Epoch 59/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0305 - acc: 0.3091 - val_loss: 1.9672 - val_acc: 0.3404\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0289 - acc: 0.3114 - val_loss: 1.9676 - val_acc: 0.3388\n",
      "Epoch 61/100\n",
      "1094/1093 [==============================] - 14s 13ms/step - loss: 2.0263 - acc: 0.3131 - val_loss: 1.9655 - val_acc: 0.3397\n",
      "Epoch 62/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0269 - acc: 0.3121 - val_loss: 1.9658 - val_acc: 0.3384\n",
      "Epoch 63/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0315 - acc: 0.3087 - val_loss: 1.9679 - val_acc: 0.3385\n",
      "Epoch 64/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0309 - acc: 0.3102 - val_loss: 1.9673 - val_acc: 0.3403\n",
      "Epoch 65/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0229 - acc: 0.3150 - val_loss: 1.9639 - val_acc: 0.3401\n",
      "Epoch 66/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0303 - acc: 0.3092 - val_loss: 1.9675 - val_acc: 0.3387\n",
      "Epoch 67/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0315 - acc: 0.3113 - val_loss: 1.9699 - val_acc: 0.3385\n",
      "Epoch 68/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0286 - acc: 0.3116 - val_loss: 1.9705 - val_acc: 0.3370\n",
      "Epoch 69/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0273 - acc: 0.3119 - val_loss: 1.9687 - val_acc: 0.3374\n",
      "Epoch 70/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0254 - acc: 0.3093 - val_loss: 1.9632 - val_acc: 0.3419\n",
      "Epoch 71/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0323 - acc: 0.3089 - val_loss: 1.9667 - val_acc: 0.3387\n",
      "Epoch 72/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0289 - acc: 0.3101 - val_loss: 1.9689 - val_acc: 0.3366\n",
      "Epoch 73/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0317 - acc: 0.3098 - val_loss: 1.9694 - val_acc: 0.3380\n",
      "Epoch 74/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0307 - acc: 0.3086 - val_loss: 1.9686 - val_acc: 0.3366\n",
      "Epoch 75/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0262 - acc: 0.3132 - val_loss: 1.9693 - val_acc: 0.3353\n",
      "Epoch 76/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0285 - acc: 0.3112 - val_loss: 1.9670 - val_acc: 0.3376\n",
      "Epoch 77/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0289 - acc: 0.3105 - val_loss: 1.9679 - val_acc: 0.3377\n",
      "Epoch 78/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0293 - acc: 0.3127 - val_loss: 1.9697 - val_acc: 0.3393\n",
      "Epoch 79/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0299 - acc: 0.3100 - val_loss: 1.9652 - val_acc: 0.3365\n",
      "Epoch 80/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0321 - acc: 0.3081 - val_loss: 1.9695 - val_acc: 0.3369\n",
      "Epoch 81/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0311 - acc: 0.3089 - val_loss: 1.9693 - val_acc: 0.3368\n",
      "Epoch 82/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0288 - acc: 0.3099 - val_loss: 1.9701 - val_acc: 0.3363\n",
      "Epoch 83/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0361 - acc: 0.3061 - val_loss: 1.9714 - val_acc: 0.3360\n",
      "Epoch 84/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0306 - acc: 0.3102 - val_loss: 1.9696 - val_acc: 0.3362\n",
      "Epoch 85/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0309 - acc: 0.3098 - val_loss: 1.9703 - val_acc: 0.3353\n",
      "Epoch 86/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0307 - acc: 0.3078 - val_loss: 1.9700 - val_acc: 0.3367\n",
      "Epoch 87/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0304 - acc: 0.3097 - val_loss: 1.9657 - val_acc: 0.3393\n",
      "Epoch 88/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0310 - acc: 0.3085 - val_loss: 1.9708 - val_acc: 0.3349\n",
      "Epoch 89/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0314 - acc: 0.3084 - val_loss: 1.9717 - val_acc: 0.3342\n",
      "Epoch 90/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0314 - acc: 0.3094 - val_loss: 1.9690 - val_acc: 0.3367\n",
      "Epoch 91/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0317 - acc: 0.3085 - val_loss: 1.9700 - val_acc: 0.3361\n",
      "Epoch 92/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0303 - acc: 0.3083 - val_loss: 1.9712 - val_acc: 0.3338\n",
      "Epoch 93/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0324 - acc: 0.3080 - val_loss: 1.9699 - val_acc: 0.3379\n",
      "Epoch 94/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0320 - acc: 0.3076 - val_loss: 1.9731 - val_acc: 0.3334\n",
      "Epoch 95/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0345 - acc: 0.3078 - val_loss: 1.9703 - val_acc: 0.3361\n",
      "Epoch 96/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0323 - acc: 0.3091 - val_loss: 1.9710 - val_acc: 0.3344\n",
      "Epoch 97/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0338 - acc: 0.3071 - val_loss: 1.9712 - val_acc: 0.3352\n",
      "Epoch 98/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0343 - acc: 0.3078 - val_loss: 1.9723 - val_acc: 0.3322\n",
      "Epoch 99/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0318 - acc: 0.3082 - val_loss: 1.9739 - val_acc: 0.3341\n",
      "Epoch 100/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 2.0307 - acc: 0.3085 - val_loss: 1.9729 - val_acc: 0.3330\n"
     ]
    }
   ],
   "source": [
    "# Compile model and train it.\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.RMSprop(lr = 0.0001), metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size_val), validation_data=datagen.flow(X_val, y_val, batch_size=batch_size_val), steps_per_epoch=len(X_train) / batch_size_val, epochs=100, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.970839817237854, 0.3353333333492279]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation:\n",
    "# ...\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate_generator(datagen.flow(X_val, y_val, batch_size=batch_size_val), steps=len(X_val)/batch_size_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
