{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorflow version: 1.12.0-rc0\n",
    "scikit-learn version: 0.17\n",
    "keras version: 2.2.4\n",
    "tensorboard version: 1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "In this assignment, we will use the weights of a network pre-trained in a particular problem as starting point to train our CNN to a different problem. As training a network from scratch is time-consuming and demands a lot of data, this is a frequent strategy, specially if both datasets (the one used for pre-training and the target) shares similar structures/elements/concepts. \n",
    "\n",
    "This is specially true when working with images. Most filters learned in initial convolutional layers will detect low-level elements, such as borders, corners and color blobs, which are common to most problems in the image domain. \n",
    "\n",
    "In this notebook, we will load the SqueezeNet architecture trained in the ImageNet dataset and fine-tune it to CIFAR-10.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Utility to plot\n",
    "def plotImages(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "        \n",
    "        \n",
    "def plotImage(img):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.imshow(np.uint8(img), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SqueezeNet definition\n",
    "These methods define our architecture and load the weights obtained using ImageNet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Module Definition\n",
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "#SqueezeNet model definition\n",
    "def SqueezeNet(input_shape):\n",
    "    img_input = Input(shape=input_shape) #placeholder\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(1000, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    # Download and load ImageNet weights\n",
    "    model.load_weights('./squeezenet_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The class are **airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val data. X:  (50000, 32, 32, 3) , Y:  (50000, 32, 32, 3)\n",
      "Test data. X:  (10000, 32, 32, 3) , Y:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "(trainVal_data, trainVal_label), (X_test, y_test) = cifar10.load_data()\n",
    "print(\"Train/Val data. X: \", trainVal_data.shape, \", Y: \", trainVal_data.shape)\n",
    "print(\"Test data. X: \", X_test.shape, \", Y: \", y_test.shape)\n",
    "\n",
    "# Prepare the data\n",
    "# ...\n",
    "train_x, val_x, train_labels, val_labels = train_test_split(trainVal_data, trainVal_label, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## SqueezeNet with frozen layers\n",
    "Our initial attempt will be to remove SqueezeNet's top layers --- responsible for the classification into ImageNet classes --- and train a new set of layers to our CIFAR-10 classes. We will also freeze the layers before `drop9`. Our architecture will be like this:\n",
    "\n",
    "<img src=\"frozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "#freeze layers\n",
    "for layer in squeezeNetModel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Add new classification layers\n",
    "x = squeezeNetModel.layers[-5].output\n",
    "x = Convolution2D(10, (1, 1), padding='valid', name='new_conv10')(x)\n",
    "x = Activation('relu', name='new_relu_conv10')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='new_loss')(x)\n",
    "\n",
    "#new Model\n",
    "model = Model(squeezeNetModel.inputs, x, name='squeezenet_new')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-4].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)\n",
    "\n",
    "datagen.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 2.3025 - acc: 0.1325 - val_loss: 2.2575 - val_acc: 0.1753\n",
      "Epoch 2/30\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 2.2553 - acc: 0.1708 - val_loss: 2.2066 - val_acc: 0.2184\n",
      "Epoch 3/30\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 2.2156 - acc: 0.1997 - val_loss: 2.1532 - val_acc: 0.2601\n",
      "Epoch 4/30\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 2.1715 - acc: 0.2223 - val_loss: 2.0884 - val_acc: 0.2808\n",
      "Epoch 5/30\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 2.1157 - acc: 0.2462 - val_loss: 2.0089 - val_acc: 0.3128\n",
      "Epoch 6/30\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 2.0609 - acc: 0.2623 - val_loss: 1.9336 - val_acc: 0.3434\n",
      "Epoch 7/30\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 2.0083 - acc: 0.2812 - val_loss: 1.8860 - val_acc: 0.3623\n",
      "Epoch 8/30\n",
      "1250/1250 [==============================] - 17s 14ms/step - loss: 1.9748 - acc: 0.2918 - val_loss: 1.8595 - val_acc: 0.3684\n",
      "Epoch 9/30\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 1.9516 - acc: 0.3005 - val_loss: 1.8343 - val_acc: 0.3855\n",
      "Epoch 10/30\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.9259 - acc: 0.3119 - val_loss: 1.8203 - val_acc: 0.3816\n",
      "Epoch 11/30\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 1.9140 - acc: 0.3157 - val_loss: 1.8034 - val_acc: 0.3886\n",
      "Epoch 12/30\n",
      "1250/1250 [==============================] - 18s 15ms/step - loss: 1.8953 - acc: 0.3215 - val_loss: 1.7906 - val_acc: 0.3905\n",
      "Epoch 13/30\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.8874 - acc: 0.3259 - val_loss: 1.7809 - val_acc: 0.3911\n",
      "Epoch 14/30\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.8790 - acc: 0.3287 - val_loss: 1.7746 - val_acc: 0.3920\n",
      "Epoch 15/30\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.8710 - acc: 0.3333 - val_loss: 1.7663 - val_acc: 0.3960\n",
      "Epoch 16/30\n",
      "1250/1250 [==============================] - 16s 13ms/step - loss: 1.8613 - acc: 0.3347 - val_loss: 1.7612 - val_acc: 0.3952\n",
      "Epoch 17/30\n",
      "1250/1250 [==============================] - 17s 13ms/step - loss: 1.8540 - acc: 0.3391 - val_loss: 1.7542 - val_acc: 0.4031\n",
      "Epoch 18/30\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.8480 - acc: 0.3407 - val_loss: 1.7460 - val_acc: 0.4030\n",
      "Epoch 19/30\n",
      "1250/1250 [==============================] - 18s 14ms/step - loss: 1.8489 - acc: 0.3369 - val_loss: 1.7433 - val_acc: 0.4043\n",
      "Epoch 20/30\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.8414 - acc: 0.3454 - val_loss: 1.7370 - val_acc: 0.4045\n",
      "Epoch 21/30\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 1.8393 - acc: 0.3460 - val_loss: 1.7335 - val_acc: 0.4106\n",
      "Epoch 22/30\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.8351 - acc: 0.3431 - val_loss: 1.7303 - val_acc: 0.4123\n",
      "Epoch 23/30\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.8318 - acc: 0.3465 - val_loss: 1.7244 - val_acc: 0.4100\n",
      "Epoch 24/30\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.8277 - acc: 0.3487 - val_loss: 1.7242 - val_acc: 0.4114\n",
      "Epoch 25/30\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.8282 - acc: 0.3502 - val_loss: 1.7170 - val_acc: 0.4141\n",
      "Epoch 26/30\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.8220 - acc: 0.3481 - val_loss: 1.7162 - val_acc: 0.4104\n",
      "Epoch 27/30\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.8170 - acc: 0.3522 - val_loss: 1.7158 - val_acc: 0.4131\n",
      "Epoch 28/30\n",
      "1250/1250 [==============================] - 19s 16ms/step - loss: 1.8191 - acc: 0.3502 - val_loss: 1.7105 - val_acc: 0.4114\n",
      "Epoch 29/30\n",
      "1250/1250 [==============================] - 19s 15ms/step - loss: 1.8115 - acc: 0.3513 - val_loss: 1.7075 - val_acc: 0.4137\n",
      "Epoch 30/30\n",
      "1250/1250 [==============================] - 20s 16ms/step - loss: 1.8136 - acc: 0.3487 - val_loss: 1.7095 - val_acc: 0.4128\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "BATCHSIZE = 32\n",
    "\n",
    "#Compile model\n",
    "# ...\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizers.SGD(lr = 0.0001, momentum=0.9, nesterov=True), metrics=[\"accuracy\"])\n",
    "\n",
    "#Tensorboard callback\n",
    "#tbCallBack = TensorBoard(log_dir=\"./logs/rafa\", write_graph=True)\n",
    "tbCallBack = TensorBoard(log_dir=\"/TransferLearning/logs/{}\".format(time()), write_graph=True)\n",
    "\n",
    "#Train model\n",
    "# ...\n",
    "\n",
    "history = model.fit_generator(datagen.flow(train_x, train_labels, batch_size=BATCHSIZE),\n",
    "                    validation_data=datagen.flow(val_x, val_labels, batch_size=BATCHSIZE),\n",
    "                    validation_steps=len(val_x)/BATCHSIZE,\n",
    "                    steps_per_epoch=len(train_x)/BATCHSIZE, \n",
    "                    epochs=30, use_multiprocessing=True,\n",
    "                    initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.7015583415985107, 0.4135]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation:\n",
    "# ...\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate_generator(datagen.flow(val_x, val_labels, batch_size=BATCHSIZE), steps=len(val_x)/BATCHSIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "-----------------\n",
    "\n",
    "# Training last 2 Fire Modules + classification layers\n",
    "As we could see, the frozen network performed very poorly. By freezing most layers, we do not allow SqueezeNet to adapt its weights to features present in CIFAR-10.\n",
    "\n",
    "Let's try to unfreeze the last two fire modules and train once more. The architecture will be:\n",
    "<img src=\"partFrozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "#freeze the mentioned layers\n",
    "# ...\n",
    "for layer in squeezeNetModel.layers[:-19]:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Add new classification layers\n",
    "# ...\n",
    "x = squeezeNetModel.layers[-5].output\n",
    "x = Convolution2D(1000, (1, 1), padding='valid', name='new_conv10')(x)\n",
    "x = Activation('relu', name='new_relu_conv10')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='new_loss')(x)\n",
    "\n",
    "#new Model\n",
    "model = Model(squeezeNetModel.inputs, x, name='squeezenet_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "new_conv10 (Conv2D)             (None, 1, 1, 1000)   513000      drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "new_relu_conv10 (Activation)    (None, 1, 1, 1000)   0           new_conv10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 1000)         0           new_relu_conv10[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "new_loss (Activation)           (None, 1000)         0           global_average_pooling2d_4[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,235,496\n",
      "Trainable params: 899,176\n",
      "Non-trainable params: 336,320\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-20].trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1250/1250 [==============================] - 57s 45ms/step - loss: 3.1215 - acc: 0.1767 - val_loss: 1.8806 - val_acc: 0.3539\n",
      "Epoch 2/30\n",
      "1250/1250 [==============================] - 33s 26ms/step - loss: 1.8929 - acc: 0.3125 - val_loss: 1.6998 - val_acc: 0.4006\n",
      "Epoch 3/30\n",
      "1250/1250 [==============================] - 33s 26ms/step - loss: 1.7503 - acc: 0.3604 - val_loss: 1.6204 - val_acc: 0.4174\n",
      "Epoch 4/30\n",
      "1250/1250 [==============================] - 33s 26ms/step - loss: 1.6892 - acc: 0.3865 - val_loss: 1.5823 - val_acc: 0.4393\n",
      "Epoch 5/30\n",
      "1250/1250 [==============================] - 32s 25ms/step - loss: 1.6530 - acc: 0.4006 - val_loss: 1.5497 - val_acc: 0.4492\n",
      "Epoch 6/30\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 1.6197 - acc: 0.4143 - val_loss: 1.5310 - val_acc: 0.4479\n",
      "Epoch 7/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.5969 - acc: 0.4225 - val_loss: 1.5179 - val_acc: 0.4514\n",
      "Epoch 8/30\n",
      "1250/1250 [==============================] - 31s 24ms/step - loss: 1.5818 - acc: 0.4287 - val_loss: 1.4891 - val_acc: 0.4642\n",
      "Epoch 9/30\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 1.5634 - acc: 0.4367 - val_loss: 1.4787 - val_acc: 0.4711\n",
      "Epoch 10/30\n",
      "1250/1250 [==============================] - 34s 27ms/step - loss: 1.5543 - acc: 0.4391 - val_loss: 1.4786 - val_acc: 0.4699\n",
      "Epoch 11/30\n",
      "1250/1250 [==============================] - 33s 26ms/step - loss: 1.5439 - acc: 0.4467 - val_loss: 1.4584 - val_acc: 0.4765\n",
      "Epoch 12/30\n",
      "1250/1250 [==============================] - 33s 26ms/step - loss: 1.5320 - acc: 0.4525 - val_loss: 1.4523 - val_acc: 0.4813\n",
      "Epoch 13/30\n",
      "1250/1250 [==============================] - 33s 26ms/step - loss: 1.5227 - acc: 0.4534 - val_loss: 1.4506 - val_acc: 0.4772\n",
      "Epoch 14/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.5181 - acc: 0.4526 - val_loss: 1.4388 - val_acc: 0.4789\n",
      "Epoch 15/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.5065 - acc: 0.4583 - val_loss: 1.4391 - val_acc: 0.4850\n",
      "Epoch 16/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.5013 - acc: 0.4628 - val_loss: 1.4208 - val_acc: 0.4890\n",
      "Epoch 17/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4886 - acc: 0.4668 - val_loss: 1.4230 - val_acc: 0.4934\n",
      "Epoch 18/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4852 - acc: 0.4684 - val_loss: 1.4246 - val_acc: 0.4883\n",
      "Epoch 19/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4814 - acc: 0.4700 - val_loss: 1.4083 - val_acc: 0.4997\n",
      "Epoch 20/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4776 - acc: 0.4711 - val_loss: 1.4088 - val_acc: 0.4927\n",
      "Epoch 21/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4675 - acc: 0.4741 - val_loss: 1.4136 - val_acc: 0.4891\n",
      "Epoch 22/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4672 - acc: 0.4763 - val_loss: 1.4051 - val_acc: 0.4953\n",
      "Epoch 23/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4647 - acc: 0.4764 - val_loss: 1.3911 - val_acc: 0.5015\n",
      "Epoch 24/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4606 - acc: 0.4774 - val_loss: 1.3942 - val_acc: 0.4994\n",
      "Epoch 25/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4571 - acc: 0.4783 - val_loss: 1.3952 - val_acc: 0.5023\n",
      "Epoch 26/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4534 - acc: 0.4797 - val_loss: 1.3986 - val_acc: 0.5008\n",
      "Epoch 27/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4516 - acc: 0.4781 - val_loss: 1.3856 - val_acc: 0.5084\n",
      "Epoch 28/30\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 1.4455 - acc: 0.4829 - val_loss: 1.3799 - val_acc: 0.5094\n",
      "Epoch 29/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4378 - acc: 0.4853 - val_loss: 1.3794 - val_acc: 0.5084\n",
      "Epoch 30/30\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 1.4383 - acc: 0.4886 - val_loss: 1.3774 - val_acc: 0.5108\n",
      "Epoch 1/30\n",
      "Epoch 1/30\n"
     ]
    }
   ],
   "source": [
    "#Compile model and train it\n",
    "# ...\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)\n",
    "\n",
    "datagen.fit(train_x)\n",
    "\n",
    "BATCHSIZE = 32\n",
    "\n",
    "#Compile model\n",
    "# ...\n",
    "model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizers.SGD(lr = 0.0001, momentum=0.9, nesterov=True), metrics=[\"accuracy\"])\n",
    "\n",
    "#Train model\n",
    "# ...\n",
    "\n",
    "history = model.fit_generator(datagen.flow(train_x, train_labels, batch_size=BATCHSIZE),\n",
    "                    validation_data=datagen.flow(val_x, val_labels, batch_size=BATCHSIZE),\n",
    "                    validation_steps=len(val_x)/BATCHSIZE,\n",
    "                    steps_per_epoch=len(train_x)/BATCHSIZE, \n",
    "                    epochs=30, use_multiprocessing=True,\n",
    "                    initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.3927965339660644, 0.501]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation:\n",
    "# ...\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate_generator(datagen.flow(val_x, val_labels, batch_size=BATCHSIZE), steps=len(val_x)/BATCHSIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "# Tensorboard\n",
    "\n",
    "Tensorboard is a visualization tool for Tensorflow. Among other things, it allows us to monitor the progress of our training, plot metrics per epochs, visualize the architecture's schematics. \n",
    "\n",
    "Just like for Early Stopping, we will use the [Tensorboard callback](https://keras.io/callbacks/#tensorboard) to log the information about our training. An example of usage, would be:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Just an example, DON'T RUN! \n",
    "### You will need to change <<LOG_DIR>>\n",
    "import keras.callbacks as callbacks\n",
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./<<LOG_DIR>>\")\n",
    "model.fit(..., callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your training progresses, Keras will log the metrics (e.g., loss, accuracy) to `<<LOG_DIR>>` (**make sure `<<LOG_DIR>>` is a valid directory)**. On your terminal, you will need to run Tensorboard, assign a port and access it via browser (just like jupyter).\n",
    "\n",
    "#### ----> MAKE SURE YOU USE A DIFFERENT PORT FOR JUPYTER AND TENSORBOARD <----\n",
    "\n",
    "### Docker\n",
    "For those using docker, open a new terminal and create a new container (using the same image) running Tensorboard:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ docker run -it -p <<port_host>>:<<port_container>>\n",
    "            --volume=<<LOG_DIR>>:<<LOG_DIR>>\n",
    "            --name=<<container_name>> <<docker_image>> \n",
    "            tensorboard --logdir=<<LOG_DIR>> --port=<<port_container>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "$ docker run -it -p 8887:8887\n",
    "            --volume=/your/path/ml2018/:/ml2018\n",
    "            --name=mdc_container_tensorboard mdc-keras:cpu\n",
    "            tensorboard --logdir=/ml2018/logs --port=8887"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After starting Tensorboard, access it via browser on `http://localhost:<<port_container>>`.\n",
    "\n",
    "### Anaconda\n",
    "$ tensorboard --logdir=<<LOG_DIR>> --port=<<port>>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After starting Tensorboard, access it via browser on `http://localhost:<<port>>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "-----------\n",
    "-----------\n",
    "\n",
    "# Fine-tuning all layers\n",
    "\n",
    "What if we fine-tune all layers of SqueezeNet?\n",
    "<img src=\"unfrozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "for layer in squeezeNetModel.layers:\n",
    "    layer.trainable = True       #by default they are all trainable, but just for clarification\n",
    "\n",
    "#Add new classification layers\n",
    "# ...\n",
    "x = squeezeNetModel.layers[-5].output\n",
    "x = Convolution2D(10, (1, 1), padding='valid', name='new_conv10')(x)\n",
    "x = Activation('relu', name='new_relu_conv10')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='new_loss')(x)\n",
    "\n",
    "#new Model\n",
    "model_adam = Model(squeezeNetModel.inputs, x, name='squeezenet_new_adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 39s 395ms/step - loss: 1.6779 - acc: 0.4136 - val_loss: 1.1770 - val_acc: 0.6020\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 1.0857 - acc: 0.6359 - val_loss: 0.9879 - val_acc: 0.6674\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 13s 132ms/step - loss: 0.9130 - acc: 0.6965 - val_loss: 0.8335 - val_acc: 0.7153\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 13s 128ms/step - loss: 0.8314 - acc: 0.7226 - val_loss: 0.8026 - val_acc: 0.7333\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 13s 131ms/step - loss: 0.7696 - acc: 0.7423 - val_loss: 0.7862 - val_acc: 0.7410\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 0.7293 - acc: 0.7555 - val_loss: 0.7585 - val_acc: 0.7445\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.6848 - acc: 0.7729 - val_loss: 0.7184 - val_acc: 0.7598\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 0.6479 - acc: 0.7827 - val_loss: 0.7247 - val_acc: 0.7531\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 14s 136ms/step - loss: 0.6193 - acc: 0.7952 - val_loss: 0.7018 - val_acc: 0.7657\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 14s 137ms/step - loss: 0.5864 - acc: 0.8059 - val_loss: 0.6750 - val_acc: 0.7732\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 14s 135ms/step - loss: 0.5735 - acc: 0.8079 - val_loss: 0.7262 - val_acc: 0.7619\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.5594 - acc: 0.8124 - val_loss: 0.6786 - val_acc: 0.7697\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.5346 - acc: 0.8224 - val_loss: 0.6762 - val_acc: 0.7779\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 13s 134ms/step - loss: 0.5094 - acc: 0.8294 - val_loss: 0.6628 - val_acc: 0.7745\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 0.4829 - acc: 0.8379 - val_loss: 0.7082 - val_acc: 0.7688\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 13s 135ms/step - loss: 0.4686 - acc: 0.8439 - val_loss: 0.6822 - val_acc: 0.7772\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import keras.callbacks as callbacks\n",
    "BATCHSIZE = 400\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)\n",
    "\n",
    "datagen.fit(train_x)\n",
    "\n",
    "#Compile model\n",
    "# ...\n",
    "model_adam.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizers.Adam(), metrics=[\"accuracy\"])\n",
    "\n",
    "#Tensorboard callback\n",
    "#tbCallBack = TensorBoard(log_dir=\"./logs/rafa\", write_graph=True)\n",
    "# tbCallBack = TensorBoard(log_dir=\"./monitor\".format(time()), write_graph=True)\n",
    "tbCallBack = callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "#Train model\n",
    "# ...\n",
    "\n",
    "history = model_adam.fit_generator(datagen.flow(train_x, train_labels, batch_size=BATCHSIZE),\n",
    "                    validation_data=datagen.flow(val_x, val_labels, batch_size=BATCHSIZE),\n",
    "                    validation_steps=len(val_x)/BATCHSIZE,\n",
    "                    steps_per_epoch=len(train_x)/BATCHSIZE, \n",
    "                    epochs=100, use_multiprocessing=True,\n",
    "                    initial_epoch=0,\n",
    "                    callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezeNetModel = SqueezeNet((32,32,3))\n",
    "\n",
    "for layer in squeezeNetModel.layers:\n",
    "    layer.trainable = True       #by default they are all trainable, but just for clarification\n",
    "\n",
    "#Add new classification layers\n",
    "# ...\n",
    "x = squeezeNetModel.layers[-5].output\n",
    "x = Convolution2D(10, (1, 1), padding='valid', name='new_conv10')(x)\n",
    "x = Activation('relu', name='new_relu_conv10')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='new_loss')(x)\n",
    "\n",
    "#new Model\n",
    "model_sgd = Model(squeezeNetModel.inputs, x, name='squeezenet_new_sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1250/1250 [==============================] - 64s 51ms/step - loss: 2.0079 - acc: 0.2782 - val_loss: 1.5645 - val_acc: 0.4571\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 1.5412 - acc: 0.4484 - val_loss: 1.2906 - val_acc: 0.5447\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 1.3551 - acc: 0.5256 - val_loss: 1.1827 - val_acc: 0.5893\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 1.2488 - acc: 0.5639 - val_loss: 1.1070 - val_acc: 0.6075\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 1.1749 - acc: 0.5924 - val_loss: 1.0586 - val_acc: 0.6341\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 1.1223 - acc: 0.6146 - val_loss: 1.0202 - val_acc: 0.6497\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 1.0756 - acc: 0.6317 - val_loss: 0.9779 - val_acc: 0.6569\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 1.0451 - acc: 0.6435 - val_loss: 0.9575 - val_acc: 0.6639\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 1.0058 - acc: 0.6583 - val_loss: 0.9259 - val_acc: 0.6777\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.9754 - acc: 0.6665 - val_loss: 0.9024 - val_acc: 0.6961\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.9521 - acc: 0.6753 - val_loss: 0.8936 - val_acc: 0.6958\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.9274 - acc: 0.6855 - val_loss: 0.8715 - val_acc: 0.7022\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.9047 - acc: 0.6929 - val_loss: 0.8668 - val_acc: 0.7047\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.8870 - acc: 0.6997 - val_loss: 0.8489 - val_acc: 0.7110\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.8681 - acc: 0.7072 - val_loss: 0.8621 - val_acc: 0.7067\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.8576 - acc: 0.7101 - val_loss: 0.8531 - val_acc: 0.7078\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.8358 - acc: 0.7193 - val_loss: 0.8142 - val_acc: 0.7250\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.8252 - acc: 0.7221 - val_loss: 0.8104 - val_acc: 0.7215\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.8174 - acc: 0.7238 - val_loss: 0.8150 - val_acc: 0.7253\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 41s 32ms/step - loss: 0.7971 - acc: 0.7321 - val_loss: 0.8113 - val_acc: 0.7218\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 39s 31ms/step - loss: 0.7894 - acc: 0.7353 - val_loss: 0.7945 - val_acc: 0.7307\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.7759 - acc: 0.7403 - val_loss: 0.7785 - val_acc: 0.7319\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.7649 - acc: 0.7439 - val_loss: 0.7835 - val_acc: 0.7309\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.7533 - acc: 0.7460 - val_loss: 0.7677 - val_acc: 0.7385\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.7468 - acc: 0.7489 - val_loss: 0.7558 - val_acc: 0.7411\n",
      "Epoch 26/100\n",
      " 210/1250 [====>.........................] - ETA: 29s - loss: 0.6986 - acc: 0.7673"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "BATCHSIZE=32\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)\n",
    "\n",
    "datagen.fit(train_x)\n",
    "\n",
    "#Compile model\n",
    "# ...\n",
    "model_sgd.compile(loss = \"sparse_categorical_crossentropy\", optimizer = optimizers.SGD(lr = 0.0001, momentum=0.9, nesterov=True), metrics=[\"accuracy\"])\n",
    "\n",
    "#Tensorboard callback\n",
    "#tbCallBack = TensorBoard(log_dir=\"./logs/rafa\", write_graph=True)\n",
    "tbCallBack = callbacks.EarlyStopping(monitor='val_acc', min_delta=0, patience=3, verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "#Train model\n",
    "# ...\n",
    "history = model_sgd.fit_generator(datagen.flow(train_x, train_labels, batch_size=BATCHSIZE),\n",
    "                    validation_data=datagen.flow(val_x, val_labels, batch_size=BATCHSIZE),\n",
    "                    validation_steps=len(val_x)/BATCHSIZE,\n",
    "                    steps_per_epoch=len(train_x)/BATCHSIZE, \n",
    "                    epochs=100, use_multiprocessing=True,\n",
    "                    initial_epoch=0,\n",
    "                    callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation\n",
    "# ...\n",
    "\n",
    "print(model_sgd.metrics_names)\n",
    "print(model_sgd.evaluate_generator(datagen.flow(val_x, val_labels, batch_size=BATCHSIZE), steps=len(val_x)/BATCHSIZE))\n",
    "\n",
    "print(model_adam.metrics_names)\n",
    "print(model_adam.evaluate_generator(datagen.flow(val_x, val_labels, batch_size=BATCHSIZE), steps=len(val_x)/BATCHSIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate your best model on test\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "Now that we are working on more complex tasks and our trainings are starting to take more time it is usually a good idea to save the trained model from time to time. [Keras has a lot of ways of saving and loading the model](https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model), but in this exercise we will use the simplest of them all: `model.save()`. It saves the architecture, the weights, the choice of loss function/optimizer/metrics and even the current state of the training, so you can resume your training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a model\n",
    "Once we have our model trained, we can load it using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "del model  # Will delete model, only to check if load_model is working\n",
    "\n",
    "# returns a compiled model identical to the previous one\n",
    "model = load_model('my_model.h5')\n",
    "\n",
    "# evaluate test set again... should give us the same result\n",
    "# ...\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy (NORMALIZED):', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
