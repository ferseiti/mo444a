{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorflow version: 1.12.0-rc0\n",
    "scikit-learn version: 0.17\n",
    "keras version: 2.2.4\n",
    "tensorboard version: 1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "In this assignment, we will use the weights of a network pre-trained in a particular problem as starting point to train our CNN to a different problem. As training a network from scratch is time-consuming and demands a lot of data, this is a frequent strategy, specially if both datasets (the one used for pre-training and the target) shares similar structures/elements/concepts. \n",
    "\n",
    "This is specially true when working with images. Most filters learned in initial convolutional layers will detect low-level elements, such as borders, corners and color blobs, which are common to most problems in the image domain. \n",
    "\n",
    "In this notebook, we will load the SqueezeNet architecture trained in the ImageNet dataset and fine-tune it to CIFAR-10.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "#Utility to plot\n",
    "def plotImages(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "        \n",
    "        \n",
    "def plotImage(img):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.imshow(np.uint8(img), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.callbacks as callbacks\n",
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./tensorboard/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SqueezeNet definition\n",
    "These methods define our architecture and load the weights obtained using ImageNet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Module Definition\n",
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "#SqueezeNet model definition\n",
    "def SqueezeNet(input_shape):\n",
    "    img_input = Input(shape=input_shape) #placeholder\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(1000, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    # Download and load ImageNet weights\n",
    "    model.load_weights('./squeezenet_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The class are **airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val data. X:  (50000, 32, 32, 3) , Y:  (50000, 1)\n",
      "Test data. X:  (10000, 32, 32, 3) , Y:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "(trainVal_data, trainVal_label), (X_test, y_test) = cifar10.load_data()\n",
    "print(\"Train/Val data. X: \", trainVal_data.shape, \", Y: \", trainVal_label.shape)\n",
    "print(\"Test data. X: \", X_test.shape, \", Y: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainVal_label = to_categorical(trainVal_label)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainVal_data, trainVal_label, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## SqueezeNet with frozen layers\n",
    "Our initial attempt will be to remove SqueezeNet's top layers --- responsible for the classification into ImageNet classes --- and train a new set of layers to our CIFAR-10 classes. We will also freeze the layers before `drop9`. Our architecture will be like this:\n",
    "\n",
    "<img src=\"frozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezeNetModel = SqueezeNet((32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new classification layers\n",
    "x = squeezeNetModel.layers[-5].output\n",
    "x = Convolution2D(10, (1, 1), padding='valid', name='new_conv10')(x)\n",
    "x = Activation('relu', name='new_relu_conv10')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='new_loss')(x)\n",
    "\n",
    "#new Model\n",
    "model = Model(squeezeNetModel.inputs, x, name='squeezenet_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "new_conv10 (Conv2D)             (None, 1, 1, 10)     5130        drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "new_relu_conv10 (Activation)    (None, 1, 1, 10)     0           new_conv10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 10)           0           new_relu_conv10[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "new_loss (Activation)           (None, 10)           0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 727,626\n",
      "Trainable params: 727,626\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "conv1 False\n",
      "relu_conv1 False\n",
      "pool1 False\n",
      "fire2/squeeze1x1 False\n",
      "fire2/relu_squeeze1x1 False\n",
      "fire2/expand1x1 False\n",
      "fire2/expand3x3 False\n",
      "fire2/relu_expand1x1 False\n",
      "fire2/relu_expand3x3 False\n",
      "fire2/concat False\n",
      "fire3/squeeze1x1 False\n",
      "fire3/relu_squeeze1x1 False\n",
      "fire3/expand1x1 False\n",
      "fire3/expand3x3 False\n",
      "fire3/relu_expand1x1 False\n",
      "fire3/relu_expand3x3 False\n",
      "fire3/concat False\n",
      "pool3 False\n",
      "fire4/squeeze1x1 False\n",
      "fire4/relu_squeeze1x1 False\n",
      "fire4/expand1x1 False\n",
      "fire4/expand3x3 False\n",
      "fire4/relu_expand1x1 False\n",
      "fire4/relu_expand3x3 False\n",
      "fire4/concat False\n",
      "fire5/squeeze1x1 False\n",
      "fire5/relu_squeeze1x1 False\n",
      "fire5/expand1x1 False\n",
      "fire5/expand3x3 False\n",
      "fire5/relu_expand1x1 False\n",
      "fire5/relu_expand3x3 False\n",
      "fire5/concat False\n",
      "pool5 False\n",
      "fire6/squeeze1x1 False\n",
      "fire6/relu_squeeze1x1 False\n",
      "fire6/expand1x1 False\n",
      "fire6/expand3x3 False\n",
      "fire6/relu_expand1x1 False\n",
      "fire6/relu_expand3x3 False\n",
      "fire6/concat False\n",
      "fire7/squeeze1x1 False\n",
      "fire7/relu_squeeze1x1 False\n",
      "fire7/expand1x1 False\n",
      "fire7/expand3x3 False\n",
      "fire7/relu_expand1x1 False\n",
      "fire7/relu_expand3x3 False\n",
      "fire7/concat False\n",
      "fire8/squeeze1x1 False\n",
      "fire8/relu_squeeze1x1 False\n",
      "fire8/expand1x1 False\n",
      "fire8/expand3x3 False\n",
      "fire8/relu_expand1x1 False\n",
      "fire8/relu_expand3x3 False\n",
      "fire8/concat False\n",
      "fire9/squeeze1x1 False\n",
      "fire9/relu_squeeze1x1 False\n",
      "fire9/expand1x1 False\n",
      "fire9/expand3x3 False\n",
      "fire9/relu_expand1x1 False\n",
      "fire9/relu_expand3x3 False\n",
      "fire9/concat False\n",
      "drop9 True\n",
      "conv10 True\n",
      "relu_conv10 True\n",
      "global_average_pooling2d_1 True\n",
      "loss True\n"
     ]
    }
   ],
   "source": [
    "#freeze layers\n",
    "for layer in model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in squeezeNetModel.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeezeNetModel.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "# squeezeNetModel.fit(trainVal_data, trainVal_label, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1000)\n",
      "(?, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'drop9'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(squeezeNetModel.output.shape)\n",
    "print(model.output.shape)\n",
    "squeezeNetModel.layers[-5].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-4].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1094/1093 [==============================] - 14s 13ms/step - loss: 2.3254 - acc: 0.1148 - val_loss: 2.2621 - val_acc: 0.2023\n",
      "Epoch 2/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.2582 - acc: 0.1716 - val_loss: 2.2093 - val_acc: 0.2487\n",
      "Epoch 3/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.2199 - acc: 0.2088 - val_loss: 2.1644 - val_acc: 0.2655\n",
      "Epoch 4/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.1899 - acc: 0.2273 - val_loss: 2.1272 - val_acc: 0.2868\n",
      "Epoch 5/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.1689 - acc: 0.2406 - val_loss: 2.1015 - val_acc: 0.2901\n",
      "Epoch 6/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.1469 - acc: 0.2473 - val_loss: 2.0801 - val_acc: 0.2993\n",
      "Epoch 7/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.1215 - acc: 0.2604 - val_loss: 2.0423 - val_acc: 0.3171\n",
      "Epoch 8/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0944 - acc: 0.2658 - val_loss: 2.0118 - val_acc: 0.3270\n",
      "Epoch 9/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0588 - acc: 0.2759 - val_loss: 1.9569 - val_acc: 0.3346\n",
      "Epoch 10/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0277 - acc: 0.2825 - val_loss: 1.9286 - val_acc: 0.3483\n",
      "Epoch 11/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 2.0062 - acc: 0.2923 - val_loss: 1.9090 - val_acc: 0.3595\n",
      "Epoch 12/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.9915 - acc: 0.2992 - val_loss: 1.8944 - val_acc: 0.3647\n",
      "Epoch 13/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.9781 - acc: 0.3059 - val_loss: 1.8841 - val_acc: 0.3699\n",
      "Epoch 14/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.9705 - acc: 0.3096 - val_loss: 1.8751 - val_acc: 0.3751\n",
      "Epoch 15/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.9614 - acc: 0.3147 - val_loss: 1.8665 - val_acc: 0.3770\n",
      "Epoch 16/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.9530 - acc: 0.3183 - val_loss: 1.8603 - val_acc: 0.3789\n",
      "Epoch 17/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.9513 - acc: 0.3180 - val_loss: 1.8539 - val_acc: 0.3789\n",
      "Epoch 18/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.9436 - acc: 0.3190 - val_loss: 1.8451 - val_acc: 0.3871\n",
      "Epoch 19/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.9361 - acc: 0.3256 - val_loss: 1.8405 - val_acc: 0.3857\n",
      "Epoch 20/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.9316 - acc: 0.3266 - val_loss: 1.8382 - val_acc: 0.3843\n",
      "Epoch 21/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.9294 - acc: 0.3235 - val_loss: 1.8350 - val_acc: 0.3893\n",
      "Epoch 22/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.9237 - acc: 0.3269 - val_loss: 1.8285 - val_acc: 0.3899\n",
      "Epoch 23/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.9078 - acc: 0.3319 - val_loss: 1.7942 - val_acc: 0.3929\n",
      "Epoch 24/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8877 - acc: 0.3347 - val_loss: 1.7763 - val_acc: 0.3955\n",
      "Epoch 25/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8764 - acc: 0.3337 - val_loss: 1.7651 - val_acc: 0.4003\n",
      "Epoch 26/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8679 - acc: 0.3348 - val_loss: 1.7571 - val_acc: 0.3993\n",
      "Epoch 27/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8641 - acc: 0.3358 - val_loss: 1.7516 - val_acc: 0.4017\n",
      "Epoch 28/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8558 - acc: 0.3396 - val_loss: 1.7449 - val_acc: 0.4010\n",
      "Epoch 29/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8531 - acc: 0.3400 - val_loss: 1.7429 - val_acc: 0.4045\n",
      "Epoch 30/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8478 - acc: 0.3436 - val_loss: 1.7336 - val_acc: 0.4048\n",
      "Epoch 31/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8473 - acc: 0.3425 - val_loss: 1.7309 - val_acc: 0.4069\n",
      "Epoch 32/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8458 - acc: 0.3415 - val_loss: 1.7286 - val_acc: 0.4080\n",
      "Epoch 33/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8405 - acc: 0.3422 - val_loss: 1.7233 - val_acc: 0.4115\n",
      "Epoch 34/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8392 - acc: 0.3431 - val_loss: 1.7214 - val_acc: 0.4079\n",
      "Epoch 35/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8366 - acc: 0.3436 - val_loss: 1.7205 - val_acc: 0.4111\n",
      "Epoch 36/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8302 - acc: 0.3472 - val_loss: 1.7163 - val_acc: 0.4115\n",
      "Epoch 37/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8325 - acc: 0.3455 - val_loss: 1.7185 - val_acc: 0.4098\n",
      "Epoch 38/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8299 - acc: 0.3470 - val_loss: 1.7112 - val_acc: 0.4114\n",
      "Epoch 39/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8261 - acc: 0.3502 - val_loss: 1.7107 - val_acc: 0.4102\n",
      "Epoch 40/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8265 - acc: 0.3489 - val_loss: 1.7086 - val_acc: 0.4160\n",
      "Epoch 41/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8244 - acc: 0.3486 - val_loss: 1.7070 - val_acc: 0.4142\n",
      "Epoch 42/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8172 - acc: 0.3522 - val_loss: 1.7097 - val_acc: 0.4095\n",
      "Epoch 43/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8229 - acc: 0.3492 - val_loss: 1.7037 - val_acc: 0.4119\n",
      "Epoch 44/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8229 - acc: 0.3481 - val_loss: 1.6996 - val_acc: 0.4145\n",
      "Epoch 45/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8153 - acc: 0.3552 - val_loss: 1.7013 - val_acc: 0.4122\n",
      "Epoch 46/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8142 - acc: 0.3531 - val_loss: 1.6993 - val_acc: 0.4157\n",
      "Epoch 47/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8145 - acc: 0.3543 - val_loss: 1.6956 - val_acc: 0.4154\n",
      "Epoch 48/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8149 - acc: 0.3513 - val_loss: 1.6967 - val_acc: 0.4183\n",
      "Epoch 49/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8110 - acc: 0.3514 - val_loss: 1.6916 - val_acc: 0.4192\n",
      "Epoch 50/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8133 - acc: 0.3492 - val_loss: 1.6932 - val_acc: 0.4139\n",
      "Epoch 51/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8057 - acc: 0.3564 - val_loss: 1.6910 - val_acc: 0.4186\n",
      "Epoch 52/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8084 - acc: 0.3567 - val_loss: 1.6886 - val_acc: 0.4192\n",
      "Epoch 53/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8077 - acc: 0.3565 - val_loss: 1.6888 - val_acc: 0.4177\n",
      "Epoch 54/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8065 - acc: 0.3569 - val_loss: 1.6895 - val_acc: 0.4184\n",
      "Epoch 55/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7976 - acc: 0.3580 - val_loss: 1.6856 - val_acc: 0.4187\n",
      "Epoch 56/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8061 - acc: 0.3579 - val_loss: 1.6825 - val_acc: 0.4233\n",
      "Epoch 57/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7954 - acc: 0.3594 - val_loss: 1.6869 - val_acc: 0.4177\n",
      "Epoch 58/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8013 - acc: 0.3571 - val_loss: 1.6847 - val_acc: 0.4196\n",
      "Epoch 59/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7970 - acc: 0.3583 - val_loss: 1.6814 - val_acc: 0.4215\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8013 - acc: 0.3601 - val_loss: 1.6822 - val_acc: 0.4163\n",
      "Epoch 61/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7979 - acc: 0.3636 - val_loss: 1.6785 - val_acc: 0.4219\n",
      "Epoch 62/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7962 - acc: 0.3609 - val_loss: 1.6780 - val_acc: 0.4229\n",
      "Epoch 63/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7990 - acc: 0.3584 - val_loss: 1.6783 - val_acc: 0.4171\n",
      "Epoch 64/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7974 - acc: 0.3614 - val_loss: 1.6791 - val_acc: 0.4194\n",
      "Epoch 65/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7939 - acc: 0.3635 - val_loss: 1.6778 - val_acc: 0.4203\n",
      "Epoch 66/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7969 - acc: 0.3606 - val_loss: 1.6763 - val_acc: 0.4218\n",
      "Epoch 67/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7902 - acc: 0.3625 - val_loss: 1.6764 - val_acc: 0.4215\n",
      "Epoch 68/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7894 - acc: 0.3612 - val_loss: 1.6741 - val_acc: 0.4199\n",
      "Epoch 69/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7900 - acc: 0.3596 - val_loss: 1.6760 - val_acc: 0.4220\n",
      "Epoch 70/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7870 - acc: 0.3630 - val_loss: 1.6719 - val_acc: 0.4225\n",
      "Epoch 71/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7892 - acc: 0.3599 - val_loss: 1.6727 - val_acc: 0.4237\n",
      "Epoch 72/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7916 - acc: 0.3611 - val_loss: 1.6722 - val_acc: 0.4265\n",
      "Epoch 73/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7913 - acc: 0.3629 - val_loss: 1.6718 - val_acc: 0.4218\n",
      "Epoch 74/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7929 - acc: 0.3623 - val_loss: 1.6669 - val_acc: 0.4243\n",
      "Epoch 75/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7911 - acc: 0.3603 - val_loss: 1.6661 - val_acc: 0.4265\n",
      "Epoch 76/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7889 - acc: 0.3653 - val_loss: 1.6665 - val_acc: 0.4240\n",
      "Epoch 77/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7876 - acc: 0.3619 - val_loss: 1.6698 - val_acc: 0.4247\n",
      "Epoch 78/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7899 - acc: 0.3588 - val_loss: 1.6689 - val_acc: 0.4226\n",
      "Epoch 79/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7894 - acc: 0.3630 - val_loss: 1.6674 - val_acc: 0.4223\n",
      "Epoch 80/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7911 - acc: 0.3585 - val_loss: 1.6674 - val_acc: 0.4237\n",
      "Epoch 81/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7881 - acc: 0.3614 - val_loss: 1.6650 - val_acc: 0.4239\n",
      "Epoch 82/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7860 - acc: 0.3622 - val_loss: 1.6660 - val_acc: 0.4238\n",
      "Epoch 83/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7845 - acc: 0.3636 - val_loss: 1.6647 - val_acc: 0.4258\n",
      "Epoch 84/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7848 - acc: 0.3633 - val_loss: 1.6660 - val_acc: 0.4236\n",
      "Epoch 85/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7803 - acc: 0.3628 - val_loss: 1.6626 - val_acc: 0.4277\n",
      "Epoch 86/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7838 - acc: 0.3644 - val_loss: 1.6628 - val_acc: 0.4259\n",
      "Epoch 87/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7843 - acc: 0.3627 - val_loss: 1.6626 - val_acc: 0.4203\n",
      "Epoch 88/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7838 - acc: 0.3649 - val_loss: 1.6616 - val_acc: 0.4262\n",
      "Epoch 89/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7801 - acc: 0.3662 - val_loss: 1.6595 - val_acc: 0.4245\n",
      "Epoch 90/100\n",
      "1094/1093 [==============================] - 10s 10ms/step - loss: 1.7830 - acc: 0.3639 - val_loss: 1.6590 - val_acc: 0.4247\n",
      "Epoch 91/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 1.7804 - acc: 0.3662 - val_loss: 1.6607 - val_acc: 0.4255\n",
      "Epoch 92/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 1.7767 - acc: 0.3648 - val_loss: 1.6619 - val_acc: 0.4232\n",
      "Epoch 93/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 1.7795 - acc: 0.3663 - val_loss: 1.6595 - val_acc: 0.4249\n",
      "Epoch 94/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 1.7809 - acc: 0.3660 - val_loss: 1.6603 - val_acc: 0.4231\n",
      "Epoch 95/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 1.7728 - acc: 0.3691 - val_loss: 1.6597 - val_acc: 0.4239\n",
      "Epoch 96/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 1.7817 - acc: 0.3669 - val_loss: 1.6588 - val_acc: 0.4265\n",
      "Epoch 97/100\n",
      "1094/1093 [==============================] - 9s 9ms/step - loss: 1.7791 - acc: 0.3642 - val_loss: 1.6543 - val_acc: 0.4274\n",
      "Epoch 98/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 1.7759 - acc: 0.3661 - val_loss: 1.6574 - val_acc: 0.4273\n",
      "Epoch 99/100\n",
      "1094/1093 [==============================] - 9s 8ms/step - loss: 1.7809 - acc: 0.3672 - val_loss: 1.6541 - val_acc: 0.4260\n",
      "Epoch 100/100\n",
      "1094/1093 [==============================] - 9s 9ms/step - loss: 1.7782 - acc: 0.3644 - val_loss: 1.6557 - val_acc: 0.4285\n"
     ]
    }
   ],
   "source": [
    "# Compile model and train it.\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr = 0.0001, momentum=0.9, nesterov=True), metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size_val), validation_data=datagen.flow(X_val, y_val, batch_size=batch_size_val), steps_per_epoch=len(X_train) / batch_size_val, epochs=100, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.6590082445780436, 0.42546666666666666]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation:\n",
    "# ...\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate_generator(datagen.flow(X_val, y_val, batch_size=batch_size_val), steps=len(X_val)/batch_size_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
