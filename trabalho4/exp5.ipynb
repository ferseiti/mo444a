{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tensorflow version: 1.12.0-rc0\n",
    "scikit-learn version: 0.17\n",
    "keras version: 2.2.4\n",
    "tensorboard version: 1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "In this assignment, we will use the weights of a network pre-trained in a particular problem as starting point to train our CNN to a different problem. As training a network from scratch is time-consuming and demands a lot of data, this is a frequent strategy, specially if both datasets (the one used for pre-training and the target) shares similar structures/elements/concepts. \n",
    "\n",
    "This is specially true when working with images. Most filters learned in initial convolutional layers will detect low-level elements, such as borders, corners and color blobs, which are common to most problems in the image domain. \n",
    "\n",
    "In this notebook, we will load the SqueezeNet architecture trained in the ImageNet dataset and fine-tune it to CIFAR-10.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from random import sample, seed\n",
    "seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.rcParams['figure.figsize'] = (15,15) # Make the figures a bit bigger\n",
    "\n",
    "# Keras imports\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Activation, concatenate, Dropout, GlobalAveragePooling2D, Flatten, Dense\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.datasets import cifar10\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "#Utility to plot\n",
    "def plotImages(imgList):\n",
    "    for i in range(len(imgList)):\n",
    "        plotImage(imgList[i])\n",
    "        \n",
    "        \n",
    "def plotImage(img):\n",
    "    fig = plt.figure(figsize=(3,3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.imshow(np.uint8(img), interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.callbacks as callbacks\n",
    "tbCallBack = callbacks.TensorBoard(log_dir = \"./tensorboard/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SqueezeNet definition\n",
    "These methods define our architecture and load the weights obtained using ImageNet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fire Module Definition\n",
    "sq1x1 = \"squeeze1x1\"\n",
    "exp1x1 = \"expand1x1\"\n",
    "exp3x3 = \"expand3x3\"\n",
    "relu = \"relu_\"\n",
    "\n",
    "def fire_module(x, fire_id, squeeze=16, expand=64):\n",
    "    s_id = 'fire' + str(fire_id) + '/'\n",
    "\n",
    "    channel_axis = 3\n",
    "    \n",
    "    x = Convolution2D(squeeze, (1, 1), padding='valid', name=s_id + sq1x1)(x)\n",
    "    x = Activation('relu', name=s_id + relu + sq1x1)(x)\n",
    "\n",
    "    left = Convolution2D(expand, (1, 1), padding='valid', name=s_id + exp1x1)(x)\n",
    "    left = Activation('relu', name=s_id + relu + exp1x1)(left)\n",
    "\n",
    "    right = Convolution2D(expand, (3, 3), padding='same', name=s_id + exp3x3)(x)\n",
    "    right = Activation('relu', name=s_id + relu + exp3x3)(right)\n",
    "\n",
    "    x = concatenate([left, right], axis=channel_axis, name=s_id + 'concat')\n",
    "    return x\n",
    "\n",
    "#SqueezeNet model definition\n",
    "def SqueezeNet(input_shape):\n",
    "    img_input = Input(shape=input_shape) #placeholder\n",
    "    \n",
    "    x = Convolution2D(64, (3, 3), strides=(2, 2), padding='valid', name='conv1')(img_input)\n",
    "    x = Activation('relu', name='relu_conv1')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool1')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=2, squeeze=16, expand=64)\n",
    "    x = fire_module(x, fire_id=3, squeeze=16, expand=64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool3')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=4, squeeze=32, expand=128)\n",
    "    x = fire_module(x, fire_id=5, squeeze=32, expand=128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), name='pool5')(x)\n",
    "\n",
    "    x = fire_module(x, fire_id=6, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=7, squeeze=48, expand=192)\n",
    "    x = fire_module(x, fire_id=8, squeeze=64, expand=256)\n",
    "    x = fire_module(x, fire_id=9, squeeze=64, expand=256)\n",
    "    \n",
    "    x = Dropout(0.5, name='drop9')(x)\n",
    "\n",
    "    x = Convolution2D(1000, (1, 1), padding='valid', name='conv10')(x)\n",
    "    x = Activation('relu', name='relu_conv10')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation('softmax', name='loss')(x)\n",
    "\n",
    "    model = Model(img_input, x, name='squeezenet')\n",
    "\n",
    "    # Download and load ImageNet weights\n",
    "    model.load_weights('./squeezenet_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR-10\n",
    "\n",
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. The class are **airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val data. X:  (50000, 32, 32, 3) , Y:  (50000, 1)\n",
      "Test data. X:  (10000, 32, 32, 3) , Y:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "(trainVal_data, trainVal_label), (X_test, y_test) = cifar10.load_data()\n",
    "print(\"Train/Val data. X: \", trainVal_data.shape, \", Y: \", trainVal_label.shape)\n",
    "print(\"Test data. X: \", X_test.shape, \", Y: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainVal_label = to_categorical(trainVal_label)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainVal_data, trainVal_label, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "## SqueezeNet with frozen layers\n",
    "Our initial attempt will be to remove SqueezeNet's top layers --- responsible for the classification into ImageNet classes --- and train a new set of layers to our CIFAR-10 classes. We will also freeze the layers before `drop9`. Our architecture will be like this:\n",
    "\n",
    "<img src=\"frozenSqueezeNet.png\" width=70% height=70%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "squeezeNetModel = SqueezeNet((32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add new classification layers\n",
    "x = squeezeNetModel.layers[-5].output\n",
    "x = Convolution2D(10, (1, 1), padding='valid', name='new_conv10')(x)\n",
    "x = Activation('relu', name='new_relu_conv10')(x)\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Activation('softmax', name='new_loss')(x)\n",
    "\n",
    "#new Model\n",
    "model = Model(squeezeNetModel.inputs, x, name='squeezenet_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 15, 15, 64)   1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "relu_conv1 (Activation)         (None, 15, 15, 64)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 7, 7, 64)     0           relu_conv1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fire2/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     1040        pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire2/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire2/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire2/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire2/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire2/concat (Concatenate)      (None, 7, 7, 128)    0           fire2/relu_expand1x1[0][0]       \n",
      "                                                                 fire2/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire3/squeeze1x1 (Conv2D)       (None, 7, 7, 16)     2064        fire2/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_squeeze1x1 (Activati (None, 7, 7, 16)     0           fire3/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand1x1 (Conv2D)        (None, 7, 7, 64)     1088        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/expand3x3 (Conv2D)        (None, 7, 7, 64)     9280        fire3/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand1x1 (Activatio (None, 7, 7, 64)     0           fire3/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/relu_expand3x3 (Activatio (None, 7, 7, 64)     0           fire3/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire3/concat (Concatenate)      (None, 7, 7, 128)    0           fire3/relu_expand1x1[0][0]       \n",
      "                                                                 fire3/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (MaxPooling2D)            (None, 3, 3, 128)    0           fire3/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire4/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     4128        pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire4/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire4/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire4/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire4/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire4/concat (Concatenate)      (None, 3, 3, 256)    0           fire4/relu_expand1x1[0][0]       \n",
      "                                                                 fire4/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire5/squeeze1x1 (Conv2D)       (None, 3, 3, 32)     8224        fire4/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_squeeze1x1 (Activati (None, 3, 3, 32)     0           fire5/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand1x1 (Conv2D)        (None, 3, 3, 128)    4224        fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/expand3x3 (Conv2D)        (None, 3, 3, 128)    36992       fire5/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand1x1 (Activatio (None, 3, 3, 128)    0           fire5/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/relu_expand3x3 (Activatio (None, 3, 3, 128)    0           fire5/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire5/concat (Concatenate)      (None, 3, 3, 256)    0           fire5/relu_expand1x1[0][0]       \n",
      "                                                                 fire5/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool5 (MaxPooling2D)            (None, 1, 1, 256)    0           fire5/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire6/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     12336       pool5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire6/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire6/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire6/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire6/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire6/concat (Concatenate)      (None, 1, 1, 384)    0           fire6/relu_expand1x1[0][0]       \n",
      "                                                                 fire6/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire7/squeeze1x1 (Conv2D)       (None, 1, 1, 48)     18480       fire6/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_squeeze1x1 (Activati (None, 1, 1, 48)     0           fire7/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand1x1 (Conv2D)        (None, 1, 1, 192)    9408        fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/expand3x3 (Conv2D)        (None, 1, 1, 192)    83136       fire7/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand1x1 (Activatio (None, 1, 1, 192)    0           fire7/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/relu_expand3x3 (Activatio (None, 1, 1, 192)    0           fire7/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire7/concat (Concatenate)      (None, 1, 1, 384)    0           fire7/relu_expand1x1[0][0]       \n",
      "                                                                 fire7/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire8/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     24640       fire7/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire8/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire8/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire8/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire8/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire8/concat (Concatenate)      (None, 1, 1, 512)    0           fire8/relu_expand1x1[0][0]       \n",
      "                                                                 fire8/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "fire9/squeeze1x1 (Conv2D)       (None, 1, 1, 64)     32832       fire8/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_squeeze1x1 (Activati (None, 1, 1, 64)     0           fire9/squeeze1x1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand1x1 (Conv2D)        (None, 1, 1, 256)    16640       fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/expand3x3 (Conv2D)        (None, 1, 1, 256)    147712      fire9/relu_squeeze1x1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand1x1 (Activatio (None, 1, 1, 256)    0           fire9/expand1x1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/relu_expand3x3 (Activatio (None, 1, 1, 256)    0           fire9/expand3x3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "fire9/concat (Concatenate)      (None, 1, 1, 512)    0           fire9/relu_expand1x1[0][0]       \n",
      "                                                                 fire9/relu_expand3x3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "drop9 (Dropout)                 (None, 1, 1, 512)    0           fire9/concat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "new_conv10 (Conv2D)             (None, 1, 1, 10)     5130        drop9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "new_relu_conv10 (Activation)    (None, 1, 1, 10)     0           new_conv10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 10)           0           new_relu_conv10[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "new_loss (Activation)           (None, 10)           0           global_average_pooling2d_2[0][0] \n",
      "==================================================================================================\n",
      "Total params: 727,626\n",
      "Trainable params: 727,626\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 False\n",
      "conv1 False\n",
      "relu_conv1 False\n",
      "pool1 False\n",
      "fire2/squeeze1x1 False\n",
      "fire2/relu_squeeze1x1 False\n",
      "fire2/expand1x1 False\n",
      "fire2/expand3x3 False\n",
      "fire2/relu_expand1x1 False\n",
      "fire2/relu_expand3x3 False\n",
      "fire2/concat False\n",
      "fire3/squeeze1x1 False\n",
      "fire3/relu_squeeze1x1 False\n",
      "fire3/expand1x1 False\n",
      "fire3/expand3x3 False\n",
      "fire3/relu_expand1x1 False\n",
      "fire3/relu_expand3x3 False\n",
      "fire3/concat False\n",
      "pool3 False\n",
      "fire4/squeeze1x1 False\n",
      "fire4/relu_squeeze1x1 False\n",
      "fire4/expand1x1 False\n",
      "fire4/expand3x3 False\n",
      "fire4/relu_expand1x1 False\n",
      "fire4/relu_expand3x3 False\n",
      "fire4/concat False\n",
      "fire5/squeeze1x1 False\n",
      "fire5/relu_squeeze1x1 False\n",
      "fire5/expand1x1 False\n",
      "fire5/expand3x3 False\n",
      "fire5/relu_expand1x1 False\n",
      "fire5/relu_expand3x3 False\n",
      "fire5/concat False\n",
      "pool5 False\n",
      "fire6/squeeze1x1 False\n",
      "fire6/relu_squeeze1x1 False\n",
      "fire6/expand1x1 False\n",
      "fire6/expand3x3 False\n",
      "fire6/relu_expand1x1 False\n",
      "fire6/relu_expand3x3 False\n",
      "fire6/concat False\n",
      "fire7/squeeze1x1 False\n",
      "fire7/relu_squeeze1x1 False\n",
      "fire7/expand1x1 False\n",
      "fire7/expand3x3 False\n",
      "fire7/relu_expand1x1 False\n",
      "fire7/relu_expand3x3 False\n",
      "fire7/concat False\n",
      "fire8/squeeze1x1 False\n",
      "fire8/relu_squeeze1x1 False\n",
      "fire8/expand1x1 False\n",
      "fire8/expand3x3 False\n",
      "fire8/relu_expand1x1 False\n",
      "fire8/relu_expand3x3 False\n",
      "fire8/concat False\n",
      "fire9/squeeze1x1 False\n",
      "fire9/relu_squeeze1x1 False\n",
      "fire9/expand1x1 False\n",
      "fire9/expand3x3 False\n",
      "fire9/relu_expand1x1 False\n",
      "fire9/relu_expand3x3 False\n",
      "fire9/concat False\n",
      "drop9 True\n",
      "conv10 True\n",
      "relu_conv10 True\n",
      "global_average_pooling2d_1 True\n",
      "loss True\n"
     ]
    }
   ],
   "source": [
    "#freeze layers\n",
    "for layer in model.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in squeezeNetModel.layers:\n",
    "    print(layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeezeNetModel.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])\n",
    "# squeezeNetModel.fit(trainVal_data, trainVal_label, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 1000)\n",
      "(?, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'drop9'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(squeezeNetModel.output.shape)\n",
    "print(model.output.shape)\n",
    "squeezeNetModel.layers[-5].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compile our model and train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[-4].trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1094/1093 [==============================] - 14s 13ms/step - loss: 2.0171 - acc: 0.2863 - val_loss: 1.7843 - val_acc: 0.3997\n",
      "Epoch 2/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8561 - acc: 0.3547 - val_loss: 1.7388 - val_acc: 0.4099\n",
      "Epoch 3/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8307 - acc: 0.3609 - val_loss: 1.7240 - val_acc: 0.4152\n",
      "Epoch 4/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.8230 - acc: 0.3638 - val_loss: 1.7164 - val_acc: 0.4093\n",
      "Epoch 5/100\n",
      "1094/1093 [==============================] - 13s 11ms/step - loss: 1.7855 - acc: 0.3675 - val_loss: 1.6165 - val_acc: 0.4325\n",
      "Epoch 6/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7343 - acc: 0.3812 - val_loss: 1.6086 - val_acc: 0.4342\n",
      "Epoch 7/100\n",
      "1094/1093 [==============================] - 13s 11ms/step - loss: 1.7322 - acc: 0.3800 - val_loss: 1.5956 - val_acc: 0.4431\n",
      "Epoch 8/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7280 - acc: 0.3827 - val_loss: 1.5937 - val_acc: 0.4400\n",
      "Epoch 9/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7232 - acc: 0.3814 - val_loss: 1.5877 - val_acc: 0.4421\n",
      "Epoch 10/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7240 - acc: 0.3803 - val_loss: 1.5920 - val_acc: 0.4358\n",
      "Epoch 11/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7211 - acc: 0.3841 - val_loss: 1.5895 - val_acc: 0.4401\n",
      "Epoch 12/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7248 - acc: 0.3765 - val_loss: 1.5878 - val_acc: 0.4405\n",
      "Epoch 13/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7200 - acc: 0.3800 - val_loss: 1.5958 - val_acc: 0.4290\n",
      "Epoch 14/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7253 - acc: 0.3832 - val_loss: 1.5865 - val_acc: 0.4438\n",
      "Epoch 15/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7146 - acc: 0.3823 - val_loss: 1.5808 - val_acc: 0.4466\n",
      "Epoch 16/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7152 - acc: 0.3833 - val_loss: 1.5856 - val_acc: 0.4388\n",
      "Epoch 17/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7120 - acc: 0.3864 - val_loss: 1.5867 - val_acc: 0.4429\n",
      "Epoch 18/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7145 - acc: 0.3854 - val_loss: 1.5825 - val_acc: 0.4405\n",
      "Epoch 19/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7136 - acc: 0.3809 - val_loss: 1.5834 - val_acc: 0.4421\n",
      "Epoch 20/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7138 - acc: 0.3859 - val_loss: 1.5817 - val_acc: 0.4417\n",
      "Epoch 21/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7146 - acc: 0.3844 - val_loss: 1.5835 - val_acc: 0.4357\n",
      "Epoch 22/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7161 - acc: 0.3841 - val_loss: 1.5760 - val_acc: 0.4481\n",
      "Epoch 23/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7148 - acc: 0.3842 - val_loss: 1.5847 - val_acc: 0.4401\n",
      "Epoch 24/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7145 - acc: 0.3854 - val_loss: 1.5754 - val_acc: 0.4450\n",
      "Epoch 25/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7156 - acc: 0.3861 - val_loss: 1.5826 - val_acc: 0.4431\n",
      "Epoch 26/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7117 - acc: 0.3864 - val_loss: 1.5826 - val_acc: 0.4398\n",
      "Epoch 27/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7141 - acc: 0.3864 - val_loss: 1.5814 - val_acc: 0.4400\n",
      "Epoch 28/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7123 - acc: 0.3883 - val_loss: 1.5797 - val_acc: 0.4382\n",
      "Epoch 29/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7126 - acc: 0.3848 - val_loss: 1.5871 - val_acc: 0.4376\n",
      "Epoch 30/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7143 - acc: 0.3823 - val_loss: 1.5818 - val_acc: 0.4393\n",
      "Epoch 31/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7149 - acc: 0.3848 - val_loss: 1.5803 - val_acc: 0.4439\n",
      "Epoch 32/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7207 - acc: 0.3801 - val_loss: 1.5856 - val_acc: 0.4419\n",
      "Epoch 33/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7108 - acc: 0.3864 - val_loss: 1.5788 - val_acc: 0.4441\n",
      "Epoch 34/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7042 - acc: 0.3916 - val_loss: 1.5754 - val_acc: 0.4445\n",
      "Epoch 35/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7078 - acc: 0.3862 - val_loss: 1.5781 - val_acc: 0.4451\n",
      "Epoch 36/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7088 - acc: 0.3878 - val_loss: 1.5754 - val_acc: 0.4504\n",
      "Epoch 37/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7091 - acc: 0.3863 - val_loss: 1.5769 - val_acc: 0.4449\n",
      "Epoch 38/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7102 - acc: 0.3872 - val_loss: 1.5781 - val_acc: 0.4410\n",
      "Epoch 39/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7158 - acc: 0.3842 - val_loss: 1.5793 - val_acc: 0.4480\n",
      "Epoch 40/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7112 - acc: 0.3860 - val_loss: 1.5837 - val_acc: 0.4423\n",
      "Epoch 41/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7104 - acc: 0.3857 - val_loss: 1.5804 - val_acc: 0.4418\n",
      "Epoch 42/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7104 - acc: 0.3830 - val_loss: 1.5759 - val_acc: 0.4443\n",
      "Epoch 43/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7066 - acc: 0.3863 - val_loss: 1.5777 - val_acc: 0.4445\n",
      "Epoch 44/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7045 - acc: 0.3892 - val_loss: 1.5835 - val_acc: 0.4410\n",
      "Epoch 45/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7117 - acc: 0.3856 - val_loss: 1.5786 - val_acc: 0.4471\n",
      "Epoch 46/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7106 - acc: 0.3841 - val_loss: 1.5793 - val_acc: 0.4453\n",
      "Epoch 47/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7067 - acc: 0.3874 - val_loss: 1.5761 - val_acc: 0.4472\n",
      "Epoch 48/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7074 - acc: 0.3880 - val_loss: 1.5837 - val_acc: 0.4413\n",
      "Epoch 49/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7088 - acc: 0.3829 - val_loss: 1.5754 - val_acc: 0.4475\n",
      "Epoch 50/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7067 - acc: 0.3878 - val_loss: 1.5755 - val_acc: 0.4443\n",
      "Epoch 51/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7167 - acc: 0.3834 - val_loss: 1.5829 - val_acc: 0.4426\n",
      "Epoch 52/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7097 - acc: 0.3882 - val_loss: 1.5786 - val_acc: 0.4469\n",
      "Epoch 53/100\n",
      "1094/1093 [==============================] - 18s 16ms/step - loss: 1.7122 - acc: 0.3879 - val_loss: 1.5794 - val_acc: 0.4451\n",
      "Epoch 54/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7105 - acc: 0.3848 - val_loss: 1.5818 - val_acc: 0.4433\n",
      "Epoch 55/100\n",
      "1094/1093 [==============================] - 14s 13ms/step - loss: 1.7128 - acc: 0.3856 - val_loss: 1.5761 - val_acc: 0.4442\n",
      "Epoch 56/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7119 - acc: 0.3862 - val_loss: 1.5813 - val_acc: 0.4457\n",
      "Epoch 57/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7122 - acc: 0.3847 - val_loss: 1.5777 - val_acc: 0.4477\n",
      "Epoch 58/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7096 - acc: 0.3863 - val_loss: 1.5756 - val_acc: 0.4453\n",
      "Epoch 59/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7099 - acc: 0.3832 - val_loss: 1.5818 - val_acc: 0.4431\n",
      "Epoch 60/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7109 - acc: 0.3826 - val_loss: 1.5782 - val_acc: 0.4443\n",
      "Epoch 61/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7079 - acc: 0.3877 - val_loss: 1.5780 - val_acc: 0.4463\n",
      "Epoch 62/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7063 - acc: 0.3839 - val_loss: 1.5788 - val_acc: 0.4391\n",
      "Epoch 63/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7059 - acc: 0.3854 - val_loss: 1.5728 - val_acc: 0.4443\n",
      "Epoch 64/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7084 - acc: 0.3853 - val_loss: 1.5750 - val_acc: 0.4511\n",
      "Epoch 65/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7039 - acc: 0.3892 - val_loss: 1.5772 - val_acc: 0.4449\n",
      "Epoch 66/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7114 - acc: 0.3884 - val_loss: 1.5770 - val_acc: 0.4435\n",
      "Epoch 67/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7073 - acc: 0.3841 - val_loss: 1.5730 - val_acc: 0.4439\n",
      "Epoch 68/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7098 - acc: 0.3861 - val_loss: 1.5786 - val_acc: 0.4441\n",
      "Epoch 69/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7066 - acc: 0.3844 - val_loss: 1.5787 - val_acc: 0.4483\n",
      "Epoch 70/100\n",
      "1094/1093 [==============================] - 13s 12ms/step - loss: 1.7074 - acc: 0.3849 - val_loss: 1.5786 - val_acc: 0.4469\n",
      "Epoch 71/100\n",
      "1094/1093 [==============================] - 16s 15ms/step - loss: 1.7067 - acc: 0.3864 - val_loss: 1.5804 - val_acc: 0.4397\n",
      "Epoch 72/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7044 - acc: 0.3886 - val_loss: 1.5786 - val_acc: 0.4420\n",
      "Epoch 73/100\n",
      "1094/1093 [==============================] - 17s 15ms/step - loss: 1.7080 - acc: 0.3886 - val_loss: 1.5789 - val_acc: 0.4401\n",
      "Epoch 74/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7143 - acc: 0.3832 - val_loss: 1.5846 - val_acc: 0.4394\n",
      "Epoch 75/100\n",
      "1094/1093 [==============================] - 17s 15ms/step - loss: 1.7095 - acc: 0.3828 - val_loss: 1.5751 - val_acc: 0.4433\n",
      "Epoch 76/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7093 - acc: 0.3840 - val_loss: 1.5787 - val_acc: 0.4445\n",
      "Epoch 77/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7090 - acc: 0.3867 - val_loss: 1.5770 - val_acc: 0.4449\n",
      "Epoch 78/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7106 - acc: 0.3821 - val_loss: 1.5783 - val_acc: 0.4429\n",
      "Epoch 79/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7083 - acc: 0.3876 - val_loss: 1.5793 - val_acc: 0.4429\n",
      "Epoch 80/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7085 - acc: 0.3858 - val_loss: 1.5728 - val_acc: 0.4476\n",
      "Epoch 81/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7152 - acc: 0.3831 - val_loss: 1.5849 - val_acc: 0.4430\n",
      "Epoch 82/100\n",
      "1094/1093 [==============================] - 17s 15ms/step - loss: 1.7109 - acc: 0.3829 - val_loss: 1.5859 - val_acc: 0.4383\n",
      "Epoch 83/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7043 - acc: 0.3900 - val_loss: 1.5796 - val_acc: 0.4455\n",
      "Epoch 84/100\n",
      "1094/1093 [==============================] - 17s 15ms/step - loss: 1.7064 - acc: 0.3873 - val_loss: 1.5825 - val_acc: 0.4428\n",
      "Epoch 85/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7113 - acc: 0.3841 - val_loss: 1.5778 - val_acc: 0.4423\n",
      "Epoch 86/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7085 - acc: 0.3895 - val_loss: 1.5801 - val_acc: 0.4420\n",
      "Epoch 87/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7097 - acc: 0.3852 - val_loss: 1.5763 - val_acc: 0.4447\n",
      "Epoch 88/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7069 - acc: 0.3857 - val_loss: 1.5788 - val_acc: 0.4458\n",
      "Epoch 89/100\n",
      "1094/1093 [==============================] - 17s 15ms/step - loss: 1.7108 - acc: 0.3834 - val_loss: 1.5850 - val_acc: 0.4426\n",
      "Epoch 90/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7050 - acc: 0.3878 - val_loss: 1.5822 - val_acc: 0.4483\n",
      "Epoch 91/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7102 - acc: 0.3868 - val_loss: 1.5779 - val_acc: 0.4495\n",
      "Epoch 92/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7104 - acc: 0.3846 - val_loss: 1.5850 - val_acc: 0.4412\n",
      "Epoch 93/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7074 - acc: 0.3847 - val_loss: 1.5769 - val_acc: 0.4469\n",
      "Epoch 94/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7058 - acc: 0.3866 - val_loss: 1.5789 - val_acc: 0.4411\n",
      "Epoch 95/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7103 - acc: 0.3864 - val_loss: 1.5822 - val_acc: 0.4440\n",
      "Epoch 96/100\n",
      "1094/1093 [==============================] - 17s 15ms/step - loss: 1.7051 - acc: 0.3887 - val_loss: 1.5825 - val_acc: 0.4395\n",
      "Epoch 97/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7096 - acc: 0.3860 - val_loss: 1.5805 - val_acc: 0.4490\n",
      "Epoch 98/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7110 - acc: 0.3857 - val_loss: 1.5788 - val_acc: 0.4387\n",
      "Epoch 99/100\n",
      "1094/1093 [==============================] - 17s 15ms/step - loss: 1.7004 - acc: 0.3892 - val_loss: 1.5795 - val_acc: 0.4441\n",
      "Epoch 100/100\n",
      "1094/1093 [==============================] - 17s 16ms/step - loss: 1.7101 - acc: 0.3880 - val_loss: 1.5808 - val_acc: 0.4374\n"
     ]
    }
   ],
   "source": [
    "# Compile model and train it.\n",
    "\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.Adam(lr = 0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size_val), validation_data=datagen.flow(X_val, y_val, batch_size=batch_size_val), steps_per_epoch=len(X_train) / batch_size_val, epochs=100, callbacks=[tbCallBack])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's evaluate on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "[1.5825523524602254, 0.43446666666666667]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation:\n",
    "# ...\n",
    "print(model.metrics_names)\n",
    "print(model.evaluate_generator(datagen.flow(X_val, y_val, batch_size=batch_size_val), steps=len(X_val)/batch_size_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
